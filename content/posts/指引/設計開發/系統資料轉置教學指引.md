+++
date = '2026-02-02T19:30:30+08:00'
draft = false
title = 'ç³»çµ±è³‡æ–™è½‰ç½®æ•™å­¸æŒ‡å¼•'
tags = ['æŒ‡å¼•', 'ç³»çµ±è³‡æ–™è½‰ç½®æ•™å­¸æŒ‡å¼•']
categories = ['æ•™å­¸']
+++

# ç³»çµ±è³‡æ–™è½‰ç½®æ•™å­¸æŒ‡å¼•

> **ç‰ˆæœ¬**ï¼š1.0  
> **æ›´æ–°æ—¥æœŸ**ï¼š2026-02-02  
> **é©ç”¨å°è±¡**ï¼šç³»çµ±åˆ†æå¸«ã€è³‡æ–™å·¥ç¨‹å¸«ã€å¾Œç«¯é–‹ç™¼äººå“¡  
> **æ–‡ä»¶æ€§è³ª**ï¼šå…§éƒ¨æ•™è‚²è¨“ç·´èˆ‡å°ˆæ¡ˆåŸ·è¡Œæ¨™æº–åƒè€ƒæ–‡ä»¶


## ç›®éŒ„

### ä¸»è¦ç« ç¯€

| ç« ç¯€ | å…§å®¹æ¦‚è¿° |
|------|---------|
| [ç¬¬ 1 ç« ](#ç¬¬-1-ç« è³‡æ–™è½‰ç½®æ•´é«”æ¦‚å¿µèˆ‡å¸¸è¦‹å¤±æ•—åŸå› ) | è³‡æ–™è½‰ç½®æ•´é«”æ¦‚å¿µèˆ‡å¸¸è¦‹å¤±æ•—åŸå›  |
| [ç¬¬ 2 ç« ](#ç¬¬-2-ç« èˆŠç³»çµ±åˆ†æas-is-analysis) | èˆŠç³»çµ±åˆ†æï¼ˆAs-Is Analysisï¼‰ |
| [ç¬¬ 3 ç« ](#ç¬¬-3-ç« æ–°ç³»çµ±è¨­è¨ˆto-be-design) | æ–°ç³»çµ±è¨­è¨ˆï¼ˆTo-Be Designï¼‰ |
| [ç¬¬ 4 ç« ](#ç¬¬-4-ç« è³‡æ–™è½‰ç½®ç­–ç•¥èˆ‡æ¶æ§‹è¨­è¨ˆ) | è³‡æ–™è½‰ç½®ç­–ç•¥èˆ‡æ¶æ§‹è¨­è¨ˆ |
| [ç¬¬ 5 ç« ](#ç¬¬-5-ç« è³‡æ–™è½‰ç½®æµç¨‹è¨­è¨ˆetl-flow) | è³‡æ–™è½‰ç½®æµç¨‹è¨­è¨ˆï¼ˆETL Flowï¼‰ |
| [ç¬¬ 6 ç« ](#ç¬¬-6-ç« è³‡æ–™é©—è­‰èˆ‡æ¯”å°æ©Ÿåˆ¶) | è³‡æ–™é©—è­‰èˆ‡æ¯”å°æ©Ÿåˆ¶ |
| [ç¬¬ 7 ç« ](#ç¬¬-7-ç« å·¥å…·èˆ‡æŠ€è¡“é¸å‹å»ºè­°) | å·¥å…·èˆ‡æŠ€è¡“é¸å‹å»ºè­° |
| [ç¬¬ 8 ç« ](#ç¬¬-8-ç« æ¸¬è©¦ç­–ç•¥èˆ‡ä¸Šç·šå‰æª¢æ ¸) | æ¸¬è©¦ç­–ç•¥èˆ‡ä¸Šç·šå‰æª¢æ ¸ |
| [ç¬¬ 9 ç« ](#ç¬¬-9-ç« å¯¦å‹™ç¶“é©—èˆ‡æœ€ä½³å¯¦è¸) | å¯¦å‹™ç¶“é©—èˆ‡æœ€ä½³å¯¦è¸ |
| [é™„éŒ„ A](#é™„éŒ„-aè³‡æ–™è½‰ç½®å°ˆæ¡ˆæª¢æŸ¥æ¸…å–®checklist) | è³‡æ–™è½‰ç½®å°ˆæ¡ˆæª¢æŸ¥æ¸…å–® |
| [é™„éŒ„ B](#é™„éŒ„-bå¸¸ç”¨-sql-ç¯„æœ¬) | å¸¸ç”¨ SQL ç¯„æœ¬ |
| [é™„éŒ„ C](#é™„éŒ„-cåè©è§£é‡‹) | åè©è§£é‡‹ |

### è©³ç´°ç›®éŒ„

- [ç¬¬ 1 ç« ï¼šè³‡æ–™è½‰ç½®æ•´é«”æ¦‚å¿µèˆ‡å¸¸è¦‹å¤±æ•—åŸå› ](#ç¬¬-1-ç« è³‡æ–™è½‰ç½®æ•´é«”æ¦‚å¿µèˆ‡å¸¸è¦‹å¤±æ•—åŸå› )
  - [1.1 Data Migration vs Data Transformation å·®ç•°](#11-data-migration-vs-data-transformation-å·®ç•°)
  - [1.2 ç‚ºä½•è³‡æ–™è½‰ç½®æ˜¯é«˜é¢¨éšªå°ˆæ¡ˆ](#12-ç‚ºä½•è³‡æ–™è½‰ç½®æ˜¯é«˜é¢¨éšªå°ˆæ¡ˆ)
  - [1.3 å¸¸è¦‹å¤±æ•—åŸå› èˆ‡é¢¨éšªåˆ†æ](#13-å¸¸è¦‹å¤±æ•—åŸå› èˆ‡é¢¨éšªåˆ†æ)
- [ç¬¬ 2 ç« ï¼šèˆŠç³»çµ±åˆ†æï¼ˆAs-Is Analysisï¼‰](#ç¬¬-2-ç« èˆŠç³»çµ±åˆ†æas-is-analysis)
  - [2.1 è³‡æ–™ä¾†æºç›¤é»](#21-è³‡æ–™ä¾†æºç›¤é»)
  - [2.2 è³‡æ–™çµæ§‹åˆ†æ](#22-è³‡æ–™çµæ§‹åˆ†æ)
  - [2.3 Key èˆ‡é‚è¼¯é—œè¯åˆ†æ](#23-key-èˆ‡é‚è¼¯é—œè¯åˆ†æ)
  - [2.4 è³‡æ–™å“è³ªæª¢æ¸¬](#24-è³‡æ–™å“è³ªæª¢æ¸¬)
- [ç¬¬ 3 ç« ï¼šæ–°ç³»çµ±è¨­è¨ˆï¼ˆTo-Be Designï¼‰](#ç¬¬-3-ç« æ–°ç³»çµ±è¨­è¨ˆto-be-design)
  - [3.1 æ–°ç³»çµ±è³‡æ–™æ¨¡å‹è¨­è¨ˆåŸå‰‡](#31-æ–°ç³»çµ±è³‡æ–™æ¨¡å‹è¨­è¨ˆåŸå‰‡)
  - [3.2 èˆŠæ¬„ä½åˆ°æ–°æ¬„ä½ Mapping è¦å‰‡](#32-èˆŠæ¬„ä½åˆ°æ–°æ¬„ä½-mapping-è¦å‰‡)
  - [3.3 Code / Enum / Reference Data å°æ‡‰ç­–ç•¥](#33-code--enum--reference-data-å°æ‡‰ç­–ç•¥)
  - [3.4 æ­·å²è³‡æ–™ä¿ç•™èˆ‡å¦çš„æ±ºç­–è€ƒé‡](#34-æ­·å²è³‡æ–™ä¿ç•™èˆ‡å¦çš„æ±ºç­–è€ƒé‡)
- [ç¬¬ 4 ç« ï¼šè³‡æ–™è½‰ç½®ç­–ç•¥èˆ‡æ¶æ§‹è¨­è¨ˆ](#ç¬¬-4-ç« è³‡æ–™è½‰ç½®ç­–ç•¥èˆ‡æ¶æ§‹è¨­è¨ˆ)
  - [4.1 ä¸€æ¬¡æ€§è½‰ç½® vs åˆ†æ‰¹è½‰ç½®](#41-ä¸€æ¬¡æ€§è½‰ç½®-vs-åˆ†æ‰¹è½‰ç½®)
  - [4.2 Online vs Batch](#42-online-vs-batch)
  - [4.3 Big Bang vs Parallel Run](#43-big-bang-vs-parallel-run)
  - [4.4 Rollback èˆ‡ Re-run è¨­è¨ˆ](#44-rollback-èˆ‡-re-run-è¨­è¨ˆ)
- [ç¬¬ 5 ç« ï¼šè³‡æ–™è½‰ç½®æµç¨‹è¨­è¨ˆï¼ˆETL Flowï¼‰](#ç¬¬-5-ç« è³‡æ–™è½‰ç½®æµç¨‹è¨­è¨ˆetl-flow)
  - [5.1 Extractï¼ˆè³‡æ–™æŠ½å–ï¼‰](#51-extractè³‡æ–™æŠ½å–)
  - [5.2 Transformï¼ˆè³‡æ–™è½‰æ›ï¼‰](#52-transformè³‡æ–™è½‰æ›)
  - [5.3 Loadï¼ˆè³‡æ–™è¼‰å…¥ï¼‰](#53-loadè³‡æ–™è¼‰å…¥)
  - [5.4 Staging Table è¨­è¨ˆ](#54-staging-table-è¨­è¨ˆ)
  - [5.5 Error Handling èˆ‡ Retry æ©Ÿåˆ¶](#55-error-handling-èˆ‡-retry-æ©Ÿåˆ¶)
- [ç¬¬ 6 ç« ï¼šè³‡æ–™é©—è­‰èˆ‡æ¯”å°æ©Ÿåˆ¶](#ç¬¬-6-ç« è³‡æ–™é©—è­‰èˆ‡æ¯”å°æ©Ÿåˆ¶)
  - [6.1 ç­†æ•¸é©—è­‰ï¼ˆRecord Countï¼‰](#61-ç­†æ•¸é©—è­‰record-count)
  - [6.2 é‡‘é¡ / æ•¸å€¼é©—è­‰ï¼ˆSum / Balance Checkï¼‰](#62-é‡‘é¡--æ•¸å€¼é©—è­‰sum--balance-check)
  - [6.3 Key-based è³‡æ–™æ¯”å°](#63-key-based-è³‡æ–™æ¯”å°)
  - [6.4 æŠ½æ¨£é©—è­‰ï¼ˆSamplingï¼‰](#64-æŠ½æ¨£é©—è­‰sampling)
  - [6.5 è‡ªå‹•åŒ–é©—è­‰å ±è¡¨è¨­è¨ˆ](#65-è‡ªå‹•åŒ–é©—è­‰å ±è¡¨è¨­è¨ˆ)
- [ç¬¬ 7 ç« ï¼šå·¥å…·èˆ‡æŠ€è¡“é¸å‹å»ºè­°](#ç¬¬-7-ç« å·¥å…·èˆ‡æŠ€è¡“é¸å‹å»ºè­°)
  - [7.1 SQL / Stored Procedure](#71-sql--stored-procedure)
  - [7.2 ETL å·¥å…·](#72-etl-å·¥å…·)
  - [7.3 ç¨‹å¼èªè¨€é¸æ“‡](#73-ç¨‹å¼èªè¨€é¸æ“‡)
  - [7.4 æª”æ¡ˆè™•ç†å·¥å…·](#74-æª”æ¡ˆè™•ç†å·¥å…·)
  - [7.5 é©—è­‰èˆ‡æ¸¬è©¦è¼”åŠ©å·¥å…·](#75-é©—è­‰èˆ‡æ¸¬è©¦è¼”åŠ©å·¥å…·)
- [ç¬¬ 8 ç« ï¼šæ¸¬è©¦ç­–ç•¥èˆ‡ä¸Šç·šå‰æª¢æ ¸](#ç¬¬-8-ç« æ¸¬è©¦ç­–ç•¥èˆ‡ä¸Šç·šå‰æª¢æ ¸)
  - [8.1 Unit Testï¼ˆè½‰æ›é‚è¼¯ï¼‰](#81-unit-testè½‰æ›é‚è¼¯)
  - [8.2 Integration Testï¼ˆæµç¨‹é©—è­‰ï¼‰](#82-integration-testæµç¨‹é©—è­‰)
  - [8.3 UAT é©—è­‰æ¨¡å¼](#83-uat-é©—è­‰æ¨¡å¼)
  - [8.4 ä¸Šç·šå‰ Checklist](#84-ä¸Šç·šå‰-checklist)
- [ç¬¬ 9 ç« ï¼šå¯¦å‹™ç¶“é©—èˆ‡æœ€ä½³å¯¦è¸](#ç¬¬-9-ç« å¯¦å‹™ç¶“é©—èˆ‡æœ€ä½³å¯¦è¸)
  - [9.1 å¸¸è¦‹è¸©é›·æ¡ˆä¾‹](#91-å¸¸è¦‹è¸©é›·æ¡ˆä¾‹)
  - [9.2 èˆ‡æ¥­å‹™å–®ä½çš„è³‡æ–™é©—è­‰åˆä½œæ–¹å¼](#92-èˆ‡æ¥­å‹™å–®ä½çš„è³‡æ–™é©—è­‰åˆä½œæ–¹å¼)
  - [9.3 æ–‡ä»¶åŒ–ã€ç¨½æ ¸èˆ‡å¯è¿½æº¯æ€§è¨­è¨ˆ](#93-æ–‡ä»¶åŒ–ç¨½æ ¸èˆ‡å¯è¿½æº¯æ€§è¨­è¨ˆ)
  - [9.4 é‡‘èèˆ‡æ ¸å¿ƒç³»çµ±å¸¸è¦‹åˆè¦è€ƒé‡](#94-é‡‘èèˆ‡æ ¸å¿ƒç³»çµ±å¸¸è¦‹åˆè¦è€ƒé‡)
- [é™„éŒ„ Aï¼šè³‡æ–™è½‰ç½®å°ˆæ¡ˆæª¢æŸ¥æ¸…å–®ï¼ˆChecklistï¼‰](#é™„éŒ„-aè³‡æ–™è½‰ç½®å°ˆæ¡ˆæª¢æŸ¥æ¸…å–®checklist)
  - [A.1 å°ˆæ¡ˆå•Ÿå‹•éšæ®µ](#a1-å°ˆæ¡ˆå•Ÿå‹•éšæ®µ)
  - [A.2 åˆ†æè¨­è¨ˆéšæ®µ](#a2-åˆ†æè¨­è¨ˆéšæ®µ)
  - [A.3 é–‹ç™¼æ¸¬è©¦éšæ®µ](#a3-é–‹ç™¼æ¸¬è©¦éšæ®µ)
  - [A.4 UAT éšæ®µ](#a4-uat-éšæ®µ)
  - [A.5 ä¸Šç·šéšæ®µ](#a5-ä¸Šç·šéšæ®µ)
- [é™„éŒ„ Bï¼šå¸¸ç”¨ SQL ç¯„æœ¬](#é™„éŒ„-bå¸¸ç”¨-sql-ç¯„æœ¬)
  - [B.1 è³‡æ–™å“è³ªæª¢æ¸¬](#b1-è³‡æ–™å“è³ªæª¢æ¸¬)
  - [B.2 è³‡æ–™æ¯”å°](#b2-è³‡æ–™æ¯”å°)
  - [B.3 è½‰ç½®é€²åº¦è¿½è¹¤](#b3-è½‰ç½®é€²åº¦è¿½è¹¤)
- [é™„éŒ„ Cï¼šåè©è§£é‡‹](#é™„éŒ„-cåè©è§£é‡‹)

---

## ç¬¬ 1 ç« ï¼šè³‡æ–™è½‰ç½®æ•´é«”æ¦‚å¿µèˆ‡å¸¸è¦‹å¤±æ•—åŸå› 

### 1.1 Data Migration vs Data Transformation å·®ç•°

åœ¨é–‹å§‹è³‡æ–™è½‰ç½®å°ˆæ¡ˆå‰ï¼Œå¿…é ˆå…ˆé‡æ¸…å…©å€‹æ ¸å¿ƒæ¦‚å¿µçš„å·®ç•°ï¼š

| é …ç›® | Data Migrationï¼ˆè³‡æ–™é·ç§»ï¼‰ | Data Transformationï¼ˆè³‡æ–™è½‰æ›ï¼‰ |
|------|---------------------------|--------------------------------|
| **å®šç¾©** | å°‡è³‡æ–™å¾ä¸€å€‹ç³»çµ±æ¬ç§»åˆ°å¦ä¸€å€‹ç³»çµ± | å°‡è³‡æ–™æ ¼å¼ã€çµæ§‹æˆ–èªæ„é€²è¡Œè½‰æ› |
| **é‡é»** | ä½ç½®æ”¹è®Šã€å¹³å°æ”¹è®Š | å…§å®¹æ”¹è®Šã€çµæ§‹æ”¹è®Š |
| **ç¯„ä¾‹** | Oracle â†’ PostgreSQL | æ—¥æœŸæ ¼å¼ YYYYMMDD â†’ YYYY-MM-DD |
| **é¢¨éšª** | è³‡æ–™éºå¤±ã€é€£ç·šå•é¡Œ | èªæ„éŒ¯èª¤ã€é‚è¼¯éŒ¯èª¤ |

> **âš ï¸ å¯¦å‹™ç¶“é©—**ï¼šå¤§å¤šæ•¸å°ˆæ¡ˆåŒæ™‚æ¶‰åŠ Migration èˆ‡ Transformationï¼Œå› æ­¤çµ±ç¨±ç‚ºã€Œè³‡æ–™è½‰ç½®ã€ã€‚

#### è³‡æ–™è½‰ç½®æ•´é«”æµç¨‹åœ–

```mermaid
flowchart LR
    subgraph èˆŠç³»çµ±
        A[(èˆŠè³‡æ–™åº«)] 
        B[æª”æ¡ˆç³»çµ±]
        C[å¤–éƒ¨ä»‹é¢]
    end
    
    subgraph è½‰ç½®å±¤
        D[Extract<br/>è³‡æ–™æŠ½å–]
        E[Transform<br/>è³‡æ–™è½‰æ›]
        F[Load<br/>è³‡æ–™è¼‰å…¥]
    end
    
    subgraph æ–°ç³»çµ±
        G[(æ–°è³‡æ–™åº«)]
        H[å¿«å–å±¤]
        I[æ‡‰ç”¨ç¨‹å¼]
    end
    
    A --> D
    B --> D
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    H --> I
```

### 1.2 ç‚ºä½•è³‡æ–™è½‰ç½®æ˜¯é«˜é¢¨éšªå°ˆæ¡ˆ

è³‡æ–™è½‰ç½®è¢«è¦–ç‚ºé«˜é¢¨éšªå°ˆæ¡ˆçš„åŸå› åŒ…æ‹¬ï¼š

#### 1.2.1 æŠ€è¡“é¢é¢¨éšª

| é¢¨éšªé¡å‹ | èªªæ˜ | å½±éŸ¿ç¨‹åº¦ |
|---------|------|---------|
| **è³‡æ–™éºå¤±** | è½‰ç½®éç¨‹ä¸­è³‡æ–™æœªå®Œæ•´æ¬ç§» | ğŸ”´ æ¥µé«˜ |
| **è³‡æ–™éŒ¯èª¤** | è½‰æ›é‚è¼¯éŒ¯èª¤å°è‡´è³‡æ–™èªæ„æ”¹è®Š | ğŸ”´ æ¥µé«˜ |
| **æ•ˆèƒ½å•é¡Œ** | å¤§é‡è³‡æ–™è™•ç†æ™‚é–“éé•· | ğŸŸ¡ ä¸­ |
| **ç›¸å®¹æ€§å•é¡Œ** | æ–°èˆŠç³»çµ±è³‡æ–™å‹æ…‹ä¸ç›¸å®¹ | ğŸŸ  é«˜ |

#### 1.2.2 ç®¡ç†é¢é¢¨éšª

- **æ™‚ç¨‹å£“åŠ›**ï¼šé€šå¸¸é…åˆç³»çµ±ä¸Šç·šï¼Œæ™‚é–“çª—å£æœ‰é™
- **è·¨åœ˜éšŠå”ä½œ**ï¼šéœ€è¦èˆŠç³»çµ±ã€æ–°ç³»çµ±ã€æ¥­å‹™å–®ä½å…±åŒåƒèˆ‡
- **çŸ¥è­˜æ–·å±¤**ï¼šèˆŠç³»çµ±æ–‡ä»¶ä¸å®Œæ•´æˆ–äººå“¡å·²é›¢è·
- **å›æ»¾å›°é›£**ï¼šä¸€æ—¦ä¸Šç·šï¼Œå›å¾©æˆæœ¬æ¥µé«˜

#### 1.2.3 æ¥­å‹™é¢é¢¨éšª

```mermaid
pie title è³‡æ–™è½‰ç½®å¤±æ•—çš„æ¥­å‹™å½±éŸ¿
    "ç‡Ÿé‹ä¸­æ–·" : 35
    "å®¢æˆ¶æŠ•è¨´" : 25
    "æ³•è¦é•è¦" : 20
    "è²¡å‹™æå¤±" : 15
    "å•†è­½æå®³" : 5
```

### 1.3 å¸¸è¦‹å¤±æ•—åŸå› èˆ‡é¢¨éšªåˆ†æ

#### 1.3.1 å¤±æ•—åŸå› åˆ†é¡

| åˆ†é¡ | å¸¸è¦‹åŸå›  | é é˜²æªæ–½ |
|------|---------|---------|
| **è¦åŠƒéšæ®µ** | æœªå®Œæ•´ç›¤é»èˆŠç³»çµ±è³‡æ–™ | å»ºç«‹è³‡æ–™æ¸…å†Šä¸¦ç°½æ ¸ |
| **è¦åŠƒéšæ®µ** | Mapping è¦å‰‡ä¸æ˜ç¢º | èˆ‡æ¥­å‹™å–®ä½ç¢ºèªæ¯å€‹æ¬„ä½èªæ„ |
| **é–‹ç™¼éšæ®µ** | è½‰æ›é‚è¼¯æœªç¶“å……åˆ†æ¸¬è©¦ | å»ºç«‹å®Œæ•´æ¸¬è©¦æ¡ˆä¾‹ |
| **é–‹ç™¼éšæ®µ** | æœªè€ƒæ…®ä¾‹å¤–è³‡æ–™è™•ç† | å®šç¾© Error Handling æ©Ÿåˆ¶ |
| **åŸ·è¡Œéšæ®µ** | æ™‚é–“ä¼°ç®—éæ–¼æ¨‚è§€ | é€²è¡Œå¤šæ¬¡æ¼”ç·´ä¸¦è¨ˆæ™‚ |
| **åŸ·è¡Œéšæ®µ** | æœªå»ºç«‹å›æ»¾æ©Ÿåˆ¶ | è¨­è¨ˆå®Œæ•´çš„ Rollback è¨ˆç•« |
| **é©—è­‰éšæ®µ** | é©—è­‰ä¸å®Œæ•´ | å¤šå±¤æ¬¡é©—è­‰ï¼ˆæŠ€è¡“ + æ¥­å‹™ï¼‰ |

#### 1.3.2 é¢¨éšªçŸ©é™£

```mermaid
quadrantChart
    title Data Migration Risk Matrix
    x-axis Low Probability --> High Probability
    y-axis Low Impact --> High Impact
    quadrant-1 Immediate Action
    quadrant-2 Monitor Closely
    quadrant-3 Regular Review
    quadrant-4 Keep Watching
    Data Loss: [0.3, 0.95]
    Transform Error: [0.6, 0.85]
    Performance Issue: [0.5, 0.5]
    Format Compatibility: [0.7, 0.4]
    Permission Error: [0.4, 0.6]
```

> **åœ–è¡¨èªªæ˜**ï¼š
> | è‹±æ–‡æ¨™ç±¤ | ä¸­æ–‡èªªæ˜ |
> |---------|---------|
> | Data Loss | è³‡æ–™éºå¤± |
> | Transform Error | è½‰æ›é‚è¼¯éŒ¯èª¤ |
> | Performance Issue | æ•ˆèƒ½ä¸è¶³ |
> | Format Compatibility | æ ¼å¼ç›¸å®¹å•é¡Œ |
> | Permission Error | æ¬Šé™è¨­å®šéŒ¯èª¤ |

#### 1.3.3 å¯¦å‹™æ¡ˆä¾‹ï¼šæŸéŠ€è¡Œæ ¸å¿ƒç³»çµ±è½‰ç½®å¤±æ•—

**èƒŒæ™¯**ï¼šæŸéŠ€è¡Œé€²è¡Œæ ¸å¿ƒç³»çµ±æ›´æ›ï¼Œè³‡æ–™è½‰ç½®æœŸé–“ç™¼ç”Ÿåš´é‡å•é¡Œ

**å¤±æ•—åŸå› **ï¼š
1. èˆŠç³»çµ±æ¬„ä½ `CUST_TYPE` æœ‰ 5 ç¨®å€¼ï¼Œä½†æ–‡ä»¶åªè¨˜è¼‰ 3 ç¨®
2. è½‰ç½®æ™‚é‡åˆ°æœªå®šç¾©çš„å€¼ï¼Œç¨‹å¼ç›´æ¥ç•¥é
3. å°è‡´æ•¸åƒç­†å®¢æˆ¶è³‡æ–™æœªè¢«è½‰ç½®

**æ•™è¨“**ï¼š
- âœ… å¿…é ˆé€²è¡Œå®Œæ•´çš„è³‡æ–™ Profiling
- âœ… æ‰€æœ‰æ¬„ä½å€¼éƒ½å¿…é ˆæœ‰æ˜ç¢ºçš„å°æ‡‰è¦å‰‡
- âœ… æœªå°æ‡‰çš„è³‡æ–™æ‡‰é€²å…¥ Error Table è€Œéç•¥é

---

## ç¬¬ 2 ç« ï¼šèˆŠç³»çµ±åˆ†æï¼ˆAs-Is Analysisï¼‰

### 2.1 è³‡æ–™ä¾†æºç›¤é»

#### 2.1.1 ç›¤é»é …ç›®æ¸…å–®

è³‡æ–™ä¾†æºç›¤é»æ˜¯è½‰ç½®å°ˆæ¡ˆçš„ç¬¬ä¸€æ­¥ï¼Œå¿…é ˆå®Œæ•´è­˜åˆ¥æ‰€æœ‰è³‡æ–™ä¾†æºï¼š

| ç›¤é»é …ç›® | èªªæ˜ | è² è²¬å–®ä½ |
|---------|------|---------|
| **è³‡æ–™åº«** | è­˜åˆ¥æ‰€æœ‰ç›¸é—œçš„ Schemaã€Table | DBA / é–‹ç™¼åœ˜éšŠ |
| **æª”æ¡ˆç³»çµ±** | CSVã€TXTã€XML ç­‰æª”æ¡ˆ | ç³»çµ±ç¶­é‹ |
| **å¤–éƒ¨ä»‹é¢** | APIã€MQã€FTP ç­‰ä¾†æº | æ•´åˆåœ˜éšŠ |
| **æ‰‹å‹•ç¶­è­·** | Excelã€äººå·¥è¼¸å…¥è³‡æ–™ | æ¥­å‹™å–®ä½ |

#### 2.1.2 è³‡æ–™æ¸…å†Šç¯„æœ¬

```markdown
## è³‡æ–™æ¸…å†Šç¯„æœ¬

| åºè™Ÿ | è³‡æ–™ä¾†æºåç¨± | é¡å‹ | ä½ç½® | æ“æœ‰è€… | ç­†æ•¸ï¼ˆä¼°è¨ˆï¼‰ | æ›´æ–°é »ç‡ | å‚™è¨» |
|------|-------------|------|------|--------|-------------|---------|------|
| 1 | CUSTOMER_MASTER | Table | Oracle/PROD | å®¢æˆ¶éƒ¨ | 500è¬ | å³æ™‚ | ä¸»æª” |
| 2 | TRANSACTION_LOG | Table | Oracle/PROD | äº¤æ˜“éƒ¨ | 2å„„ | å³æ™‚ | éœ€æ­¸æª” |
| 3 | daily_report.csv | File | /data/reports | ç‡Ÿé‹éƒ¨ | æ¯æ—¥1åƒ | æ¯æ—¥ | T+1 |
```

#### 2.1.3 è³‡æ–™ä¾†æºé—œè¯åœ–

```mermaid
erDiagram
    CUSTOMER_MASTER ||--o{ ACCOUNT : has
    CUSTOMER_MASTER ||--o{ CONTACT_INFO : has
    ACCOUNT ||--o{ TRANSACTION : contains
    ACCOUNT ||--o{ BALANCE : has
    PRODUCT_MASTER ||--o{ ACCOUNT : references
    
    CUSTOMER_MASTER {
        string CUST_ID PK
        string CUST_NAME
        string CUST_TYPE
        date CREATE_DATE
    }
    
    ACCOUNT {
        string ACCT_NO PK
        string CUST_ID FK
        string PROD_CODE FK
        string STATUS
    }
    
    TRANSACTION {
        string TXN_ID PK
        string ACCT_NO FK
        decimal AMOUNT
        datetime TXN_TIME
    }
```

### 2.2 è³‡æ–™çµæ§‹åˆ†æ

#### 2.2.1 Table çµæ§‹åˆ†æ

é‡å°æ¯å€‹ Table é€²è¡Œä»¥ä¸‹åˆ†æï¼š

```sql
-- å–å¾— Table çµæ§‹è³‡è¨Šï¼ˆOracle ç¯„ä¾‹ï¼‰
SELECT 
    column_name,
    data_type,
    data_length,
    nullable,
    data_default
FROM all_tab_columns
WHERE table_name = 'CUSTOMER_MASTER'
ORDER BY column_id;

-- å–å¾— Table çµ±è¨ˆè³‡è¨Š
SELECT 
    table_name,
    num_rows,
    avg_row_len,
    last_analyzed
FROM all_tables
WHERE table_name = 'CUSTOMER_MASTER';
```

#### 2.2.2 File Layout åˆ†æ

å°æ–¼å›ºå®šé•·åº¦æª”æ¡ˆï¼Œéœ€å»ºç«‹å®Œæ•´çš„ Layout æ–‡ä»¶ï¼š

```plaintext
# å®¢æˆ¶ä¸»æª” File Layout (customer_master.dat)
# ç·¨ç¢¼: Big5
# è¨˜éŒ„é•·åº¦: 200 bytes

æ¬„ä½åç¨±        èµ·å§‹ä½ç½®  é•·åº¦  é¡å‹      èªªæ˜
-----------    --------  ----  ------    ----------------
CUST_ID        1         10    AN        å®¢æˆ¶ç·¨è™Ÿ
CUST_NAME      11        40    AN        å®¢æˆ¶å§“å
CUST_TYPE      51        2     N         å®¢æˆ¶é¡å‹
ID_NO          53        10    AN        èº«åˆ†è­‰å­—è™Ÿ
BIRTH_DATE     63        8     N         ç”Ÿæ—¥(YYYYMMDD)
CREATE_DATE    71        8     N         å»ºç«‹æ—¥æœŸ
FILLER         79        122   AN        ä¿ç•™æ¬„ä½
```

#### 2.2.3 çµæ§‹åˆ†æå·¥ä½œè¡¨

| æ¬„ä½åç¨± | èˆŠç³»çµ±å‹æ…‹ | é•·åº¦ | Nullable | é è¨­å€¼ | æ¥­å‹™èªªæ˜ | ç‰¹æ®Šè™•ç† |
|---------|-----------|------|----------|--------|---------|---------|
| CUST_ID | VARCHAR2 | 10 | N | - | å®¢æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼ | ç„¡ |
| CUST_NAME | VARCHAR2 | 40 | N | - | å®¢æˆ¶å§“å | éœ€è™•ç†å…¨åŠå½¢ |
| STATUS | CHAR | 1 | N | 'A' | ç‹€æ…‹ç¢¼ | éœ€ Code å°æ‡‰ |

### 2.3 Key èˆ‡é‚è¼¯é—œè¯åˆ†æ

#### 2.3.1 è­˜åˆ¥ Primary Key èˆ‡ Foreign Key

```sql
-- æŸ¥è©¢ Primary Keyï¼ˆOracleï¼‰
SELECT 
    cols.column_name,
    cons.constraint_name
FROM all_constraints cons
JOIN all_cons_columns cols 
    ON cons.constraint_name = cols.constraint_name
WHERE cons.constraint_type = 'P'
    AND cons.table_name = 'CUSTOMER_MASTER';

-- æŸ¥è©¢ Foreign Key é—œè¯
SELECT 
    a.table_name AS child_table,
    a.column_name AS child_column,
    c_pk.table_name AS parent_table,
    b.column_name AS parent_column
FROM all_cons_columns a
JOIN all_constraints c 
    ON a.constraint_name = c.constraint_name
JOIN all_constraints c_pk 
    ON c.r_constraint_name = c_pk.constraint_name
JOIN all_cons_columns b 
    ON c_pk.constraint_name = b.constraint_name
WHERE c.constraint_type = 'R'
    AND a.table_name = 'ACCOUNT';
```

#### 2.3.2 é‚è¼¯é—œè¯çŸ©é™£

| ä¸»æª” Table | é—œè¯ Table | é—œè¯é¡å‹ | é—œè¯æ¬„ä½ | å‚™è¨» |
|-----------|-----------|---------|---------|------|
| CUSTOMER_MASTER | ACCOUNT | 1:N | CUST_ID | ä¸€å®¢æˆ¶å¤šå¸³æˆ¶ |
| ACCOUNT | TRANSACTION | 1:N | ACCT_NO | ä¸€å¸³æˆ¶å¤šäº¤æ˜“ |
| PRODUCT_MASTER | ACCOUNT | 1:N | PROD_CODE | ç”¢å“å°æ‡‰å¸³æˆ¶ |

#### 2.3.3 è³‡æ–™ç›¸ä¾æ€§åˆ†æ

```mermaid
flowchart TD
    subgraph ç¬¬ä¸€å±¤[ç¬¬ä¸€å±¤ï¼šåŸºç¤ä¸»æª”]
        A[PRODUCT_MASTER]
        B[CODE_MASTER]
        C[BRANCH_MASTER]
    end
    
    subgraph ç¬¬äºŒå±¤[ç¬¬äºŒå±¤ï¼šæ ¸å¿ƒä¸»æª”]
        D[CUSTOMER_MASTER]
        E[EMPLOYEE_MASTER]
    end
    
    subgraph ç¬¬ä¸‰å±¤[ç¬¬ä¸‰å±¤ï¼šäº¤æ˜“ä¸»æª”]
        F[ACCOUNT]
        G[CONTRACT]
    end
    
    subgraph ç¬¬å››å±¤[ç¬¬å››å±¤ï¼šæ˜ç´°è³‡æ–™]
        H[TRANSACTION]
        I[BALANCE_HISTORY]
    end
    
    A --> F
    B --> D
    C --> E
    D --> F
    D --> G
    E --> F
    F --> H
    F --> I
    
    style ç¬¬ä¸€å±¤ fill:#e1f5fe
    style ç¬¬äºŒå±¤ fill:#fff3e0
    style ç¬¬ä¸‰å±¤ fill:#f3e5f5
    style ç¬¬å››å±¤ fill:#e8f5e9
```

> **âš ï¸ é‡è¦**ï¼šè³‡æ–™è½‰ç½®å¿…é ˆæŒ‰ç…§ç›¸ä¾æ€§é †åºåŸ·è¡Œï¼Œå…ˆè½‰ä¸»æª”å†è½‰æ˜ç´°ã€‚

### 2.4 è³‡æ–™å“è³ªæª¢æ¸¬

#### 2.4.1 è³‡æ–™å“è³ªæª¢æ¸¬é …ç›®

| æª¢æ¸¬é …ç›® | SQL ç¯„ä¾‹ | èªªæ˜ |
|---------|---------|------|
| **Null å€¼æª¢æ¸¬** | `WHERE column IS NULL` | è­˜åˆ¥ç©ºå€¼æ¬„ä½ |
| **é‡è¤‡å€¼æª¢æ¸¬** | `GROUP BY ... HAVING COUNT(*) > 1` | è­˜åˆ¥é‡è¤‡ Key |
| **æ ¼å¼ç•°å¸¸** | `WHERE NOT REGEXP_LIKE(...)` | è­˜åˆ¥æ ¼å¼éŒ¯èª¤ |
| **ç¯„åœç•°å¸¸** | `WHERE amount < 0` | è­˜åˆ¥ç•°å¸¸æ•¸å€¼ |
| **åƒç…§å®Œæ•´æ€§** | `LEFT JOIN ... WHERE ... IS NULL` | è­˜åˆ¥å­¤ç«‹è³‡æ–™ |

#### 2.4.2 è³‡æ–™ Profiling è…³æœ¬

```sql
-- è³‡æ–™ Profiling å®Œæ•´è…³æœ¬ç¯„ä¾‹
-- 1. åŸºæœ¬çµ±è¨ˆ
SELECT 
    'CUSTOMER_MASTER' AS table_name,
    COUNT(*) AS total_rows,
    COUNT(DISTINCT cust_id) AS unique_cust_id,
    COUNT(*) - COUNT(cust_name) AS null_cust_name,
    MIN(create_date) AS min_create_date,
    MAX(create_date) AS max_create_date
FROM customer_master;

-- 2. æ¬„ä½å€¼åˆ†å¸ƒ
SELECT 
    cust_type,
    COUNT(*) AS cnt,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) AS pct
FROM customer_master
GROUP BY cust_type
ORDER BY cnt DESC;

-- 3. é‡è¤‡ Key æª¢æ¸¬
SELECT cust_id, COUNT(*) AS dup_count
FROM customer_master
GROUP BY cust_id
HAVING COUNT(*) > 1;

-- 4. åƒç…§å®Œæ•´æ€§æª¢æ¸¬
SELECT a.acct_no, a.cust_id
FROM account a
LEFT JOIN customer_master c ON a.cust_id = c.cust_id
WHERE c.cust_id IS NULL;
```

#### 2.4.3 è³‡æ–™å“è³ªå ±å‘Šç¯„æœ¬

```markdown
## è³‡æ–™å“è³ªæª¢æ¸¬å ±å‘Š

### æª¢æ¸¬æ—¥æœŸï¼š2026-02-02
### æª¢æ¸¬ç¯„åœï¼šCUSTOMER_MASTER

| æª¢æ¸¬é …ç›® | çµæœ | ç­†æ•¸ | æ¯”ä¾‹ | åš´é‡åº¦ |
|---------|------|------|------|--------|
| ç¸½ç­†æ•¸ | - | 5,234,567 | 100% | - |
| CUST_ID ç©ºå€¼ | âœ… PASS | 0 | 0% | - |
| CUST_NAME ç©ºå€¼ | âš ï¸ WARN | 123 | 0.002% | ä¸­ |
| CUST_TYPE ç•°å¸¸å€¼ | ğŸ”´ FAIL | 45 | 0.001% | é«˜ |
| é‡è¤‡ CUST_ID | âœ… PASS | 0 | 0% | - |

### éœ€è™•ç†é …ç›®
1. CUST_NAME ç©ºå€¼ 123 ç­† â†’ å»ºè­°è£œå€¼æˆ–è¨­é è¨­å€¼
2. CUST_TYPE å€¼ 'X' æœªåœ¨ä»£ç¢¼è¡¨ä¸­å®šç¾© â†’ éœ€ç¢ºèªå°æ‡‰è¦å‰‡
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - è³‡æ–™å“è³ªæª¢æ¸¬æ‡‰åœ¨å°ˆæ¡ˆåˆæœŸå®Œæˆï¼Œé¿å…å¾ŒæœŸç™¼ç¾å•é¡Œå½±éŸ¿æ™‚ç¨‹
> - æª¢æ¸¬çµæœæ‡‰èˆ‡æ¥­å‹™å–®ä½å…±åŒç¢ºèªè™•ç†æ–¹å¼
> - å»ºç«‹ç•°å¸¸è³‡æ–™æ¸…å–®ï¼Œè¿½è¹¤è™•ç†é€²åº¦

---

## ç¬¬ 3 ç« ï¼šæ–°ç³»çµ±è¨­è¨ˆï¼ˆTo-Be Designï¼‰

### 3.1 æ–°ç³»çµ±è³‡æ–™æ¨¡å‹è¨­è¨ˆåŸå‰‡

#### 3.1.1 è¨­è¨ˆåŸå‰‡

| åŸå‰‡ | èªªæ˜ | ç¯„ä¾‹ |
|------|------|------|
| **æ­£è¦åŒ–** | æ¸›å°‘è³‡æ–™é‡è¤‡ï¼Œç¢ºä¿ä¸€è‡´æ€§ | åœ°å€è³‡æ–™ç¨ç«‹ç‚º ADDRESS Table |
| **é©åº¦åæ­£è¦åŒ–** | ç‚ºæ•ˆèƒ½è€ƒé‡é©åº¦å†—é¤˜ | å¸¸ç”¨æŸ¥è©¢æ¬„ä½å¯å†—é¤˜ |
| **æ“´å……æ€§** | é ç•™æœªä¾†æ“´å……ç©ºé–“ | ä½¿ç”¨ VARCHAR è€Œé CHAR |
| **ä¸€è‡´æ€§** | å‘½åèˆ‡å‹æ…‹ä¿æŒä¸€è‡´ | æ—¥æœŸçµ±ä¸€ç”¨ TIMESTAMP |

#### 3.1.2 è³‡æ–™æ¨¡å‹è¨­è¨ˆæµç¨‹

```mermaid
flowchart TD
    A[åˆ†æèˆŠç³»çµ±æ¨¡å‹] --> B[è­˜åˆ¥æ ¸å¿ƒå¯¦é«”]
    B --> C[å®šç¾©å¯¦é«”é—œè¯]
    C --> D[è¨­è¨ˆé‚è¼¯æ¨¡å‹]
    D --> E[è½‰æ›å¯¦é«”æ¨¡å‹]
    E --> F[æ•ˆèƒ½èª¿æ ¡]
    F --> G[å»ºç«‹ Mapping æ–‡ä»¶]
    
    style A fill:#e3f2fd
    style G fill:#e8f5e9
```

#### 3.1.3 æ–°èˆŠç³»çµ±æ¨¡å‹å°ç…§

```mermaid
erDiagram
    %% èˆŠç³»çµ±
    OLD_CUSTOMER {
        varchar CUST_ID PK "å®¢æˆ¶ç·¨è™Ÿ"
        varchar CUST_NAME "å§“å"
        char CUST_TYPE "é¡å‹"
        varchar ADDR "åœ°å€(æ··åˆ)"
        varchar TEL "é›»è©±(æ··åˆ)"
    }
    
    %% æ–°ç³»çµ±
    NEW_CUSTOMER {
        bigint id PK "ç³»çµ±æµæ°´è™Ÿ"
        varchar customer_no UK "å®¢æˆ¶ç·¨è™Ÿ"
        varchar name "å§“å"
        varchar customer_type "é¡å‹"
        timestamp created_at "å»ºç«‹æ™‚é–“"
    }
    
    NEW_ADDRESS {
        bigint id PK "ç³»çµ±æµæ°´è™Ÿ"
        bigint customer_id FK "å®¢æˆ¶ID"
        varchar address_type "åœ°å€é¡å‹"
        varchar city "ç¸£å¸‚"
        varchar district "å€åŸŸ"
        varchar street "è¡—é“"
    }
    
    NEW_CONTACT {
        bigint id PK "ç³»çµ±æµæ°´è™Ÿ"
        bigint customer_id FK "å®¢æˆ¶ID"
        varchar contact_type "è¯çµ¡é¡å‹"
        varchar contact_value "è¯çµ¡è³‡è¨Š"
    }
    
    NEW_CUSTOMER ||--o{ NEW_ADDRESS : has
    NEW_CUSTOMER ||--o{ NEW_CONTACT : has
```

### 3.2 èˆŠæ¬„ä½åˆ°æ–°æ¬„ä½ Mapping è¦å‰‡

#### 3.2.1 Mapping æ–‡ä»¶çµæ§‹

| èˆŠ Table | èˆŠæ¬„ä½ | æ–° Table | æ–°æ¬„ä½ | è½‰æ›è¦å‰‡ | èªªæ˜ |
|---------|--------|---------|--------|---------|------|
| CUSTOMER | CUST_ID | customer | customer_no | ç›´æ¥å°æ‡‰ | - |
| CUSTOMER | CUST_NAME | customer | name | TRIM è™•ç† | å»é™¤å‰å¾Œç©ºç™½ |
| CUSTOMER | CUST_TYPE | customer | customer_type | Code å°æ‡‰ | è¦‹ä»£ç¢¼å°æ‡‰è¡¨ |
| CUSTOMER | ADDR | address | city, district, street | åœ°å€æ‹†åˆ† | éœ€è§£æåœ°å€ |
| CUSTOMER | CREATE_DT | customer | created_at | æ—¥æœŸè½‰æ› | YYYYMMDD â†’ TIMESTAMP |

#### 3.2.2 Mapping è¦å‰‡åˆ†é¡

```mermaid
mindmap
  root((Mapping è¦å‰‡))
    ç›´æ¥å°æ‡‰
      ç„¡è½‰æ›
      å‹æ…‹è½‰æ›
    è¨ˆç®—è½‰æ›
      å…¬å¼è¨ˆç®—
      å‡½æ•¸è™•ç†
    é‚è¼¯å°æ‡‰
      Code å°æ‡‰
      æ¢ä»¶åˆ¤æ–·
    çµæ§‹è®Šæ›´
      æ¬„ä½æ‹†åˆ†
      æ¬„ä½åˆä½µ
      Table æ‹†åˆ†
      Table åˆä½µ
```

#### 3.2.3 å¸¸è¦‹è½‰æ›è¦å‰‡ç¯„ä¾‹

```sql
-- 1. ç›´æ¥å°æ‡‰ï¼ˆå‹æ…‹è½‰æ›ï¼‰
-- èˆŠï¼šVARCHAR2(10) â†’ æ–°ï¼šBIGINT
SELECT CAST(cust_id AS BIGINT) AS id FROM old_customer;

-- 2. æ—¥æœŸæ ¼å¼è½‰æ›
-- èˆŠï¼šYYYYMMDD (CHAR) â†’ æ–°ï¼šTIMESTAMP
SELECT 
    TO_TIMESTAMP(create_dt, 'YYYYMMDD') AS created_at
FROM old_customer;

-- 3. Code å°æ‡‰è½‰æ›
SELECT 
    CASE cust_type
        WHEN '1' THEN 'INDIVIDUAL'
        WHEN '2' THEN 'CORPORATE'
        WHEN '3' THEN 'VIP'
        ELSE 'UNKNOWN'
    END AS customer_type
FROM old_customer;

-- 4. åœ°å€æ‹†åˆ†ï¼ˆä½¿ç”¨ REGEXPï¼‰
SELECT 
    REGEXP_SUBSTR(addr, '^(.{2}[å¸‚ç¸£])', 1, 1) AS city,
    REGEXP_SUBSTR(addr, '[å¸‚ç¸£](.+?[å€é„‰é®å¸‚])', 1, 1, NULL, 1) AS district,
    REGEXP_SUBSTR(addr, '[å€é„‰é®å¸‚](.+)$', 1, 1, NULL, 1) AS street
FROM old_customer;

-- 5. æ¬„ä½åˆä½µ
SELECT 
    CONCAT(last_name, first_name) AS full_name
FROM old_employee;
```

### 3.3 Code / Enum / Reference Data å°æ‡‰ç­–ç•¥

#### 3.3.1 ä»£ç¢¼å°æ‡‰è¡¨è¨­è¨ˆ

```sql
-- å»ºç«‹ä»£ç¢¼å°æ‡‰è¡¨
CREATE TABLE migration_code_mapping (
    id              BIGINT PRIMARY KEY AUTO_INCREMENT,
    category        VARCHAR(50) NOT NULL,    -- ä»£ç¢¼é¡åˆ¥
    source_code     VARCHAR(20) NOT NULL,    -- èˆŠç³»çµ±ä»£ç¢¼
    target_code     VARCHAR(50) NOT NULL,    -- æ–°ç³»çµ±ä»£ç¢¼
    description     VARCHAR(200),            -- èªªæ˜
    effective_date  DATE DEFAULT CURRENT_DATE,
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY uk_mapping (category, source_code)
);

-- ç¯„ä¾‹è³‡æ–™
INSERT INTO migration_code_mapping (category, source_code, target_code, description) VALUES
('CUST_TYPE', '1', 'INDIVIDUAL', 'å€‹äººå®¢æˆ¶'),
('CUST_TYPE', '2', 'CORPORATE', 'æ³•äººå®¢æˆ¶'),
('CUST_TYPE', '3', 'VIP', 'VIPå®¢æˆ¶'),
('ACCT_STATUS', 'A', 'ACTIVE', 'æœ‰æ•ˆ'),
('ACCT_STATUS', 'C', 'CLOSED', 'å·²çµæ¸…'),
('ACCT_STATUS', 'F', 'FROZEN', 'å‡çµ');
```

#### 3.3.2 ä»£ç¢¼å°æ‡‰æŸ¥è©¢å‡½æ•¸

```sql
-- å»ºç«‹å°æ‡‰æŸ¥è©¢å‡½æ•¸
CREATE FUNCTION fn_get_target_code(
    p_category VARCHAR(50),
    p_source_code VARCHAR(20)
) RETURNS VARCHAR(50)
BEGIN
    DECLARE v_target_code VARCHAR(50);
    
    SELECT target_code INTO v_target_code
    FROM migration_code_mapping
    WHERE category = p_category 
      AND source_code = p_source_code;
    
    IF v_target_code IS NULL THEN
        RETURN CONCAT('UNMAPPED_', p_source_code);
    END IF;
    
    RETURN v_target_code;
END;
```

#### 3.3.3 ä»£ç¢¼å°æ‡‰é©—è­‰

```sql
-- æª¢æŸ¥æ˜¯å¦æœ‰æœªå°æ‡‰çš„ä»£ç¢¼
SELECT DISTINCT 
    'CUST_TYPE' AS category,
    c.cust_type AS source_code,
    COUNT(*) AS affected_rows
FROM old_customer c
LEFT JOIN migration_code_mapping m 
    ON m.category = 'CUST_TYPE' 
    AND m.source_code = c.cust_type
WHERE m.id IS NULL
GROUP BY c.cust_type;
```

### 3.4 æ­·å²è³‡æ–™ä¿ç•™èˆ‡å¦çš„æ±ºç­–è€ƒé‡

#### 3.4.1 æ±ºç­–è©•ä¼°çŸ©é™£

| è€ƒé‡å› ç´  | ä¿ç•™ | ä¸ä¿ç•™ | è©•ä¼°å•é¡Œ |
|---------|------|--------|---------|
| **æ³•è¦è¦æ±‚** | âœ… | - | æ³•è¦è¦æ±‚ä¿å­˜å¤šä¹…ï¼Ÿ |
| **æ¥­å‹™æŸ¥è©¢** | âœ… | - | æ¥­å‹™æ˜¯å¦éœ€è¦æŸ¥è©¢æ­·å²ï¼Ÿ |
| **ç¨½æ ¸éœ€æ±‚** | âœ… | - | æ˜¯å¦éœ€è¦è¿½æº¯æ­·å²è»Œè·¡ï¼Ÿ |
| **å„²å­˜æˆæœ¬** | - | âœ… | å„²å­˜æˆæœ¬æ˜¯å¦å¯æ¥å—ï¼Ÿ |
| **æ•ˆèƒ½å½±éŸ¿** | - | âœ… | å¤§é‡æ­·å²æ˜¯å¦å½±éŸ¿æ•ˆèƒ½ï¼Ÿ |
| **è½‰ç½®è¤‡é›œåº¦** | - | âœ… | æ­·å²è³‡æ–™è½‰ç½®æ˜¯å¦å¯è¡Œï¼Ÿ |

#### 3.4.2 æ­·å²è³‡æ–™è™•ç†ç­–ç•¥

```mermaid
flowchart TD
    A[æ­·å²è³‡æ–™] --> B{æ³•è¦è¦æ±‚?}
    B -->|æ˜¯| C[å¿…é ˆä¿ç•™]
    B -->|å¦| D{æ¥­å‹™éœ€æ±‚?}
    D -->|æ˜¯| E{æŸ¥è©¢é »ç‡?}
    D -->|å¦| F[å¯æ­¸æª”/åˆªé™¤]
    E -->|é«˜| G[è½‰ç½®åˆ°ç·šä¸Šç³»çµ±]
    E -->|ä½| H[è½‰ç½®åˆ°æ­¸æª”ç³»çµ±]
    
    C --> I{è³‡æ–™é‡?}
    I -->|å¤§| J[åˆ†å€å„²å­˜]
    I -->|å°| G
    
    style C fill:#ffcdd2
    style G fill:#c8e6c9
    style H fill:#fff9c4
    style F fill:#e1f5fe
```

#### 3.4.3 æ­·å²è³‡æ–™åˆ†å±¤è¨­è¨ˆ

| å±¤ç´š | è³‡æ–™ç¯„åœ | å„²å­˜ä½ç½® | å­˜å–æ–¹å¼ | æ•ˆèƒ½ |
|------|---------|---------|---------|------|
| **Hot** | è¿‘ 3 å€‹æœˆ | ä¸»è³‡æ–™åº« | ç·šä¸ŠæŸ¥è©¢ | âš¡ å¿« |
| **Warm** | 3 å€‹æœˆ ~ 2 å¹´ | æ­¸æª”è³‡æ–™åº« | API æŸ¥è©¢ | ğŸ”„ ä¸­ |
| **Cold** | 2 å¹´ä»¥ä¸Š | ç‰©ä»¶å„²å­˜ | ç”³è«‹èª¿é–± | ğŸ¢ æ…¢ |

```sql
-- æ­·å²è³‡æ–™åˆ†å€è¡¨è¨­è¨ˆç¯„ä¾‹
CREATE TABLE transaction_history (
    txn_id          BIGINT NOT NULL,
    acct_no         VARCHAR(20) NOT NULL,
    txn_date        DATE NOT NULL,
    amount          DECIMAL(18,2),
    -- ... å…¶ä»–æ¬„ä½
    PRIMARY KEY (txn_id, txn_date)
) PARTITION BY RANGE (txn_date) (
    PARTITION p_2024 VALUES LESS THAN ('2025-01-01'),
    PARTITION p_2025 VALUES LESS THAN ('2026-01-01'),
    PARTITION p_2026 VALUES LESS THAN ('2027-01-01'),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - æ­·å²è³‡æ–™ä¿ç•™æ±ºç­–å¿…é ˆèˆ‡æ³•å‹™ã€ç¨½æ ¸ã€æ¥­å‹™å–®ä½å…±åŒç¢ºèª
> - å»ºè­°è£½ä½œã€Œè³‡æ–™ä¿ç•™æ”¿ç­–æ–‡ä»¶ã€ä¸¦å–å¾—æ­£å¼ç°½æ ¸
> - é ç•™æ­·å²è³‡æ–™èª¿é–±æ©Ÿåˆ¶ï¼Œé¿å…æœªä¾†éœ€æ±‚è®Šæ›´æ™‚ç„¡æ³•å› æ‡‰

---

## ç¬¬ 4 ç« ï¼šè³‡æ–™è½‰ç½®ç­–ç•¥èˆ‡æ¶æ§‹è¨­è¨ˆ

### 4.1 ä¸€æ¬¡æ€§è½‰ç½® vs åˆ†æ‰¹è½‰ç½®

#### 4.1.1 ç­–ç•¥æ¯”è¼ƒ

| ç­–ç•¥ | ä¸€æ¬¡æ€§è½‰ç½®ï¼ˆFull Loadï¼‰ | åˆ†æ‰¹è½‰ç½®ï¼ˆIncrementalï¼‰ |
|------|------------------------|------------------------|
| **é©ç”¨æƒ…å¢ƒ** | è³‡æ–™é‡å°ã€åœæ©Ÿæ™‚é–“å……è£• | è³‡æ–™é‡å¤§ã€éœ€æŒçºŒç‡Ÿé‹ |
| **å„ªé»** | é‚è¼¯ç°¡å–®ã€ä¸€è‡´æ€§é«˜ | é¢¨éšªåˆ†æ•£ã€å¯é€æ­¥é©—è­‰ |
| **ç¼ºé»** | åœæ©Ÿæ™‚é–“é•·ã€é¢¨éšªé›†ä¸­ | é‚è¼¯è¤‡é›œã€éœ€è™•ç†å¢é‡ |
| **å»ºè­°è³‡æ–™é‡** | < 1000 è¬ç­† | > 1000 è¬ç­† |

#### 4.1.2 åˆ†æ‰¹è½‰ç½®ç­–ç•¥è¨­è¨ˆ

```mermaid
flowchart TD
    subgraph ç¬¬ä¸€éšæ®µ[ç¬¬ä¸€éšæ®µï¼šåŸºç¤è³‡æ–™]
        A[ä¸»æª”è³‡æ–™] --> B[ä»£ç¢¼è¡¨]
        B --> C[åƒæ•¸æª”]
    end
    
    subgraph ç¬¬äºŒéšæ®µ[ç¬¬äºŒéšæ®µï¼šæ ¸å¿ƒè³‡æ–™]
        D[å®¢æˆ¶ä¸»æª”] --> E[å¸³æˆ¶ä¸»æª”]
        E --> F[ç”¢å“è³‡æ–™]
    end
    
    subgraph ç¬¬ä¸‰éšæ®µ[ç¬¬ä¸‰éšæ®µï¼šäº¤æ˜“è³‡æ–™]
        G[æ­·å²äº¤æ˜“ - æ‰¹æ¬¡1]
        H[æ­·å²äº¤æ˜“ - æ‰¹æ¬¡2]
        I[æ­·å²äº¤æ˜“ - æ‰¹æ¬¡N]
    end
    
    subgraph ç¬¬å››éšæ®µ[ç¬¬å››éšæ®µï¼šå¢é‡åŒæ­¥]
        J[Delta åŒæ­¥æ©Ÿåˆ¶]
        K[å³æ™‚å¢é‡]
    end
    
    ç¬¬ä¸€éšæ®µ --> ç¬¬äºŒéšæ®µ
    ç¬¬äºŒéšæ®µ --> ç¬¬ä¸‰éšæ®µ
    ç¬¬ä¸‰éšæ®µ --> ç¬¬å››éšæ®µ
```

#### 4.1.3 åˆ†æ‰¹ç­–ç•¥å¯¦ä½œç¯„ä¾‹

```sql
-- åˆ†æ‰¹è½‰ç½®æ§åˆ¶è¡¨
CREATE TABLE migration_batch_control (
    batch_id        VARCHAR(20) PRIMARY KEY,
    table_name      VARCHAR(100) NOT NULL,
    batch_seq       INT NOT NULL,
    start_key       VARCHAR(100),
    end_key         VARCHAR(100),
    total_rows      BIGINT DEFAULT 0,
    processed_rows  BIGINT DEFAULT 0,
    status          VARCHAR(20) DEFAULT 'PENDING',
    start_time      TIMESTAMP,
    end_time        TIMESTAMP,
    error_message   TEXT,
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å»ºç«‹åˆ†æ‰¹ï¼ˆä¾ CUST_ID ç¯„åœï¼‰
INSERT INTO migration_batch_control (batch_id, table_name, batch_seq, start_key, end_key)
SELECT 
    CONCAT('CUST_', LPAD(ROW_NUMBER() OVER(), 3, '0')),
    'CUSTOMER_MASTER',
    ROW_NUMBER() OVER(),
    MIN(cust_id),
    MAX(cust_id)
FROM (
    SELECT 
        cust_id,
        NTILE(10) OVER (ORDER BY cust_id) AS batch_group
    FROM old_customer
) t
GROUP BY batch_group;
```

### 4.2 Online vs Batch

#### 4.2.1 è™•ç†æ¨¡å¼æ¯”è¼ƒ

| é …ç›® | Onlineï¼ˆå³æ™‚ï¼‰ | Batchï¼ˆæ‰¹æ¬¡ï¼‰ |
|------|---------------|---------------|
| **è™•ç†æ™‚æ©Ÿ** | äº‹ä»¶è§¸ç™¼æ™‚ç«‹å³è™•ç† | æ’ç¨‹æˆ–æ‰‹å‹•è§¸ç™¼ |
| **è³‡æ–™é‡** | å–®ç­†æˆ–å°‘é‡ | å¤§é‡è³‡æ–™ |
| **å›æ‡‰æ™‚é–“** | æ¯«ç§’è‡³ç§’ç´š | åˆ†é˜è‡³å°æ™‚ç´š |
| **æŠ€è¡“å¯¦ä½œ** | APIã€CDCã€MQ | ETLã€Stored Procedure |
| **é©ç”¨æƒ…å¢ƒ** | å¢é‡åŒæ­¥ã€å³æ™‚è½‰ç½® | åˆå§‹è½‰ç½®ã€æ­·å²è³‡æ–™ |

#### 4.2.2 æ··åˆæ¨¡å¼æ¶æ§‹

```mermaid
flowchart LR
    subgraph èˆŠç³»çµ±
        A[(èˆŠè³‡æ–™åº«)]
        B[æ‡‰ç”¨ç¨‹å¼]
    end
    
    subgraph è½‰ç½®å±¤
        C[CDC æ•ç²]
        D[Message Queue]
        E[Batch ETL]
        F[Staging Area]
    end
    
    subgraph æ–°ç³»çµ±
        G[(æ–°è³‡æ–™åº«)]
        H[æ‡‰ç”¨ç¨‹å¼]
    end
    
    A -->|åˆå§‹è¼‰å…¥| E
    A -->|è®Šæ›´æ•ç²| C
    B -->|äº¤æ˜“äº‹ä»¶| D
    C --> D
    D -->|å³æ™‚åŒæ­¥| G
    E --> F
    F -->|æ‰¹æ¬¡è¼‰å…¥| G
    G --> H
```

#### 4.2.3 CDCï¼ˆChange Data Captureï¼‰å¯¦ä½œæ¦‚å¿µ

```java
// CDC ç›£è½å™¨æ¦‚å¿µç¯„ä¾‹ï¼ˆä½¿ç”¨ Debezium æ¦‚å¿µï¼‰
public class CustomerCdcHandler {
    
    @KafkaListener(topics = "dbserver.schema.customer")
    public void handleCustomerChange(ChangeEvent event) {
        switch (event.getOperation()) {
            case CREATE:
                migrateNewCustomer(event.getAfter());
                break;
            case UPDATE:
                updateMigratedCustomer(event.getBefore(), event.getAfter());
                break;
            case DELETE:
                markCustomerDeleted(event.getBefore());
                break;
        }
    }
    
    private void migrateNewCustomer(CustomerRecord record) {
        // è½‰æ›ä¸¦å¯«å…¥æ–°ç³»çµ±
        NewCustomer newCustomer = transform(record);
        newCustomerRepository.save(newCustomer);
        
        // è¨˜éŒ„è½‰ç½®æ—¥èªŒ
        migrationLogRepository.save(new MigrationLog(
            record.getCustId(), 
            "CREATE", 
            LocalDateTime.now()
        ));
    }
}
```

### 4.3 Big Bang vs Parallel Run

#### 4.3.1 ç­–ç•¥èªªæ˜

| ç­–ç•¥ | Big Bang | Parallel Run |
|------|----------|--------------|
| **å®šç¾©** | ç‰¹å®šæ™‚é–“é»ä¸€æ¬¡æ€§åˆ‡æ› | æ–°èˆŠç³»çµ±ä¸¦è¡Œé‹ä½œä¸€æ®µæ™‚é–“ |
| **åˆ‡æ›æ–¹å¼** | åœæ©Ÿ â†’ è½‰ç½® â†’ ä¸Šç·š | é›™å¯« â†’ æ¯”å° â†’ åˆ‡æ› |
| **é¢¨éšª** | é«˜ï¼ˆç„¡å›é ­è·¯ï¼‰ | ä½ï¼ˆå¯éš¨æ™‚åˆ‡å›ï¼‰ |
| **æˆæœ¬** | ä½ï¼ˆå–®æ¬¡ä½œæ¥­ï¼‰ | é«˜ï¼ˆé›™ç³»çµ±ç¶­è­·ï¼‰ |
| **é©ç”¨æƒ…å¢ƒ** | ç¨ç«‹ç³»çµ±ã€é¢¨éšªå¯æ§ | æ ¸å¿ƒç³»çµ±ã€é«˜å¯ç”¨è¦æ±‚ |

#### 4.3.2 Big Bang æµç¨‹

```mermaid
gantt
    title Big Bang è½‰ç½®æ™‚ç¨‹
    dateFormat  HH:mm
    axisFormat  %H:%M
    
    section æº–å‚™éšæ®µ
    ç³»çµ±å…¬å‘Šåœæ©Ÿ        :a1, 18:00, 30m
    åœæ­¢äº¤æ˜“æœå‹™        :a2, after a1, 15m
    
    section è½‰ç½®éšæ®µ
    è³‡æ–™æŠ½å–           :b1, after a2, 60m
    è³‡æ–™è½‰æ›           :b2, after b1, 90m
    è³‡æ–™è¼‰å…¥           :b3, after b2, 60m
    
    section é©—è­‰éšæ®µ
    ç­†æ•¸é©—è­‰           :c1, after b3, 30m
    é‡‘é¡é©—è­‰           :c2, after c1, 30m
    æŠ½æ¨£é©—è­‰           :c3, after c2, 30m
    
    section ä¸Šç·šéšæ®µ
    ç³»çµ±åˆ‡æ›           :d1, after c3, 15m
    æœå‹™æ¢å¾©           :d2, after d1, 15m
    ç›£æ§è§€å¯Ÿ           :d3, after d2, 60m
```

#### 4.3.3 Parallel Run æ¶æ§‹

```mermaid
flowchart TD
    subgraph ä¸¦è¡Œéšæ®µ
        A[ä½¿ç”¨è€…è«‹æ±‚] --> B[API Gateway]
        B --> C[è·¯ç”±æ§åˆ¶]
        C -->|å¯«å…¥| D[èˆŠç³»çµ±]
        C -->|å¯«å…¥| E[æ–°ç³»çµ±]
        D --> F[èˆŠ DB]
        E --> G[æ–° DB]
        
        H[æ¯”å°æœå‹™] --> F
        H --> G
        H --> I[æ¯”å°å ±å‘Š]
    end
    
    subgraph åˆ‡æ›éšæ®µ
        J{æ¯”å°çµæœ} -->|é€šé| K[åˆ‡æ›è‡³æ–°ç³»çµ±]
        J -->|ç•°å¸¸| L[å•é¡Œä¿®å¾©]
        L --> H
    end
    
    I --> J
```

#### 4.3.4 é›™å¯«ï¼ˆDual Writeï¼‰ç¨‹å¼ç¯„ä¾‹

```java
@Service
@Transactional
public class DualWriteService {
    
    @Autowired
    private OldCustomerRepository oldRepo;
    
    @Autowired
    private NewCustomerRepository newRepo;
    
    @Autowired
    private ComparisonService comparisonService;
    
    public void createCustomer(CustomerRequest request) {
        // 1. å¯«å…¥èˆŠç³»çµ±
        OldCustomer oldCustomer = oldRepo.save(
            mapToOldCustomer(request)
        );
        
        // 2. å¯«å…¥æ–°ç³»çµ±
        NewCustomer newCustomer = newRepo.save(
            mapToNewCustomer(request)
        );
        
        // 3. è¨˜éŒ„æ¯”å°è³‡è¨Š
        comparisonService.recordForComparison(
            oldCustomer.getId(),
            newCustomer.getId(),
            "CREATE"
        );
    }
}
```

### 4.4 Rollback èˆ‡ Re-run è¨­è¨ˆ

#### 4.4.1 Rollback ç­–ç•¥

| ç­–ç•¥ | èªªæ˜ | é©ç”¨æ™‚æ©Ÿ |
|------|------|---------|
| **å‚™ä»½é‚„åŸ** | è½‰ç½®å‰å®Œæ•´å‚™ä»½ï¼Œå¤±æ•—æ™‚é‚„åŸ | è³‡æ–™é‡å°ã€å¯æ¥å—å…¨é‡é‚„åŸ |
| **åå‘è½‰ç½®** | è¨­è¨ˆåå‘è½‰æ›ç¨‹å¼ | éƒ¨åˆ†è³‡æ–™éœ€å›å¾© |
| **æ¨™è¨˜æ¸…é™¤** | æ–°è³‡æ–™åŠ è¨»æ¨™è¨˜ï¼Œå¤±æ•—æ™‚åˆªé™¤ | å¢é‡è½‰ç½®å ´æ™¯ |
| **ç‰ˆæœ¬æ§åˆ¶** | ä¿ç•™å¤šç‰ˆæœ¬è³‡æ–™ | éœ€è¦è¿½æº¯æ­·å² |

#### 4.4.2 Rollback æµç¨‹è¨­è¨ˆ

```mermaid
flowchart TD
    A[è½‰ç½®é–‹å§‹] --> B[å»ºç«‹ Checkpoint]
    B --> C[åŸ·è¡Œè½‰ç½®]
    C --> D{é©—è­‰çµæœ}
    D -->|é€šé| E[Commit]
    D -->|å¤±æ•—| F{éŒ¯èª¤é¡å‹}
    F -->|å¯ä¿®å¾©| G[ä¿®å¾©è³‡æ–™]
    F -->|ä¸å¯ä¿®å¾©| H[Rollback]
    G --> C
    H --> I[é‚„åŸå‚™ä»½]
    I --> J[æ¸…ç†æš«å­˜]
    J --> K[è¨˜éŒ„å¤±æ•—åŸå› ]
    E --> L[æ¸…ç†æš«å­˜]
    L --> M[å®Œæˆ]
    
    style D fill:#fff9c4
    style H fill:#ffcdd2
    style E fill:#c8e6c9
```

#### 4.4.3 Re-run æ©Ÿåˆ¶è¨­è¨ˆ

```sql
-- è½‰ç½®åŸ·è¡Œè¨˜éŒ„è¡¨
CREATE TABLE migration_execution_log (
    execution_id    VARCHAR(36) PRIMARY KEY,
    batch_id        VARCHAR(20),
    table_name      VARCHAR(100),
    start_key       VARCHAR(100),
    end_key         VARCHAR(100),
    status          VARCHAR(20),  -- RUNNING, SUCCESS, FAILED, ROLLBACK
    processed_count BIGINT,
    error_count     BIGINT,
    start_time      TIMESTAMP,
    end_time        TIMESTAMP,
    error_detail    TEXT,
    can_rerun       BOOLEAN DEFAULT TRUE,
    rerun_count     INT DEFAULT 0
);

-- Re-run æŸ¥è©¢ï¼šæ‰¾å‡ºéœ€è¦é‡è·‘çš„æ‰¹æ¬¡
SELECT 
    batch_id,
    table_name,
    start_key,
    end_key,
    rerun_count
FROM migration_execution_log
WHERE status = 'FAILED'
  AND can_rerun = TRUE
  AND rerun_count < 3  -- æœ€å¤šé‡è·‘ 3 æ¬¡
ORDER BY batch_id;
```

#### 4.4.4 Checkpoint æ©Ÿåˆ¶

```java
@Service
public class MigrationCheckpointService {
    
    @Autowired
    private CheckpointRepository checkpointRepo;
    
    /**
     * å»ºç«‹æª¢æŸ¥é»
     */
    public String createCheckpoint(String batchId, String tableName) {
        Checkpoint checkpoint = new Checkpoint();
        checkpoint.setCheckpointId(UUID.randomUUID().toString());
        checkpoint.setBatchId(batchId);
        checkpoint.setTableName(tableName);
        checkpoint.setCreatedAt(LocalDateTime.now());
        checkpoint.setStatus("CREATED");
        
        // è¨˜éŒ„ç•¶å‰é€²åº¦
        checkpoint.setLastProcessedKey(
            getLastProcessedKey(tableName)
        );
        
        return checkpointRepo.save(checkpoint).getCheckpointId();
    }
    
    /**
     * å¾æª¢æŸ¥é»æ¢å¾©
     */
    public void resumeFromCheckpoint(String checkpointId) {
        Checkpoint checkpoint = checkpointRepo.findById(checkpointId)
            .orElseThrow(() -> new RuntimeException("Checkpoint not found"));
        
        log.info("Resume from checkpoint: {}, lastKey: {}", 
            checkpointId, checkpoint.getLastProcessedKey());
        
        // å¾ä¸Šæ¬¡ä½ç½®ç¹¼çºŒ
        migrationService.migrateFrom(
            checkpoint.getTableName(),
            checkpoint.getLastProcessedKey()
        );
    }
}
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - æ¯å€‹æ‰¹æ¬¡è½‰ç½®å‰å¿…é ˆå»ºç«‹ Checkpoint
> - Rollback è…³æœ¬å¿…é ˆäº‹å…ˆæº–å‚™ä¸¦æ¸¬è©¦
> - å»ºè­°è¨­å®šæœ€å¤§ Re-run æ¬¡æ•¸ï¼Œé¿å…ç„¡é™é‡è©¦

---

## ç¬¬ 5 ç« ï¼šè³‡æ–™è½‰ç½®æµç¨‹è¨­è¨ˆï¼ˆETL Flowï¼‰

### 5.1 Extractï¼ˆè³‡æ–™æŠ½å–ï¼‰

#### 5.1.1 æŠ½å–ç­–ç•¥

| ç­–ç•¥ | èªªæ˜ | å„ªé» | ç¼ºé» |
|------|------|------|------|
| **Full Extract** | æŠ½å–å…¨éƒ¨è³‡æ–™ | é‚è¼¯ç°¡å–® | è³‡æ–™é‡å¤§ã€æ™‚é–“é•· |
| **Incremental** | åªæŠ½å–ç•°å‹•è³‡æ–™ | æ•ˆç‡é«˜ | éœ€è¿½è¹¤ç•°å‹• |
| **CDC** | æ•ç²è³‡æ–™è®Šæ›´ | å³æ™‚æ€§é«˜ | æ¶æ§‹è¤‡é›œ |

#### 5.1.2 æŠ½å–æµç¨‹åœ–

```mermaid
flowchart TD
    A[é–‹å§‹æŠ½å–] --> B{æŠ½å–æ¨¡å¼}
    B -->|Full| C[å…¨é‡æŠ½å–]
    B -->|Incremental| D[å¢é‡æŠ½å–]
    B -->|CDC| E[è®Šæ›´æ•ç²]
    
    C --> F[SELECT * FROM table]
    D --> G[SELECT WHERE modified_date > last_run]
    E --> H[è®€å– Change Log]
    
    F --> I[å¯«å…¥ Staging]
    G --> I
    H --> I
    
    I --> J[è¨˜éŒ„æŠ½å–çµ±è¨ˆ]
    J --> K[çµæŸ]
    
    subgraph çµ±è¨ˆé …ç›®
        L[æŠ½å–ç­†æ•¸]
        M[æŠ½å–æ™‚é–“]
        N[è³‡æ–™å¤§å°]
    end
    
    J --> L
    J --> M
    J --> N
```

#### 5.1.3 æŠ½å–ç¨‹å¼ç¯„ä¾‹

```java
@Service
@Slf4j
public class DataExtractService {
    
    @Autowired
    private JdbcTemplate sourceJdbc;
    
    @Autowired
    private StagingRepository stagingRepo;
    
    /**
     * åˆ†é æŠ½å–å¤§é‡è³‡æ–™
     */
    public ExtractResult extractCustomers(String batchId, int pageSize) {
        ExtractResult result = new ExtractResult(batchId);
        result.setStartTime(LocalDateTime.now());
        
        int offset = 0;
        int totalExtracted = 0;
        
        try {
            while (true) {
                // åˆ†é æŸ¥è©¢
                String sql = """
                    SELECT cust_id, cust_name, cust_type, 
                           create_date, modify_date
                    FROM customer_master
                    ORDER BY cust_id
                    OFFSET ? ROWS FETCH NEXT ? ROWS ONLY
                    """;
                
                List<Map<String, Object>> rows = sourceJdbc.queryForList(
                    sql, offset, pageSize
                );
                
                if (rows.isEmpty()) {
                    break;
                }
                
                // å¯«å…¥ Staging
                List<StagingCustomer> stagingData = rows.stream()
                    .map(this::mapToStaging)
                    .collect(Collectors.toList());
                
                stagingRepo.batchInsert(stagingData);
                
                totalExtracted += rows.size();
                offset += pageSize;
                
                log.info("Extracted {} records, total: {}", 
                    rows.size(), totalExtracted);
            }
            
            result.setStatus("SUCCESS");
            result.setExtractedCount(totalExtracted);
            
        } catch (Exception e) {
            log.error("Extract failed at offset {}", offset, e);
            result.setStatus("FAILED");
            result.setErrorMessage(e.getMessage());
        }
        
        result.setEndTime(LocalDateTime.now());
        return result;
    }
    
    private StagingCustomer mapToStaging(Map<String, Object> row) {
        StagingCustomer staging = new StagingCustomer();
        staging.setSourceCustId((String) row.get("CUST_ID"));
        staging.setSourceCustName((String) row.get("CUST_NAME"));
        staging.setSourceCustType((String) row.get("CUST_TYPE"));
        staging.setSourceCreateDate((Date) row.get("CREATE_DATE"));
        staging.setExtractTime(LocalDateTime.now());
        staging.setProcessStatus("PENDING");
        return staging;
    }
}
```

### 5.2 Transformï¼ˆè³‡æ–™è½‰æ›ï¼‰

#### 5.2.1 è½‰æ›é¡å‹

```mermaid
mindmap
  root((è³‡æ–™è½‰æ›))
    æ ¼å¼è½‰æ›
      æ—¥æœŸæ ¼å¼
      æ•¸å­—æ ¼å¼
      ç·¨ç¢¼è½‰æ›
    çµæ§‹è½‰æ›
      æ¬„ä½æ‹†åˆ†
      æ¬„ä½åˆä½µ
      Table é‡çµ„
    èªæ„è½‰æ›
      ä»£ç¢¼å°æ‡‰
      å–®ä½æ›ç®—
      ç©ºå€¼è™•ç†
    æ¸…ç†è½‰æ›
      å»é™¤ç©ºç™½
      å¤§å°å¯«çµ±ä¸€
      ç‰¹æ®Šå­—å…ƒè™•ç†
    è¡ç”Ÿè¨ˆç®—
      å…¬å¼è¨ˆç®—
      èšåˆè¨ˆç®—
      é—œè¯è¨ˆç®—
```

#### 5.2.2 è½‰æ›è¦å‰‡å¼•æ“

```java
/**
 * è½‰æ›è¦å‰‡ä»‹é¢
 */
public interface TransformRule<S, T> {
    T transform(S source);
    boolean validate(S source);
    String getRuleName();
}

/**
 * æ—¥æœŸè½‰æ›è¦å‰‡
 */
@Component
public class DateTransformRule implements TransformRule<String, LocalDate> {
    
    private static final DateTimeFormatter SOURCE_FORMAT = 
        DateTimeFormatter.ofPattern("yyyyMMdd");
    
    @Override
    public LocalDate transform(String source) {
        if (source == null || source.trim().isEmpty()) {
            return null;
        }
        return LocalDate.parse(source.trim(), SOURCE_FORMAT);
    }
    
    @Override
    public boolean validate(String source) {
        if (source == null || source.trim().isEmpty()) {
            return true; // å…è¨±ç©ºå€¼
        }
        try {
            transform(source);
            return true;
        } catch (DateTimeParseException e) {
            return false;
        }
    }
    
    @Override
    public String getRuleName() {
        return "DATE_YYYYMMDD_TO_LOCALDATE";
    }
}

/**
 * ä»£ç¢¼å°æ‡‰è½‰æ›è¦å‰‡
 */
@Component
public class CodeMappingRule implements TransformRule<String, String> {
    
    @Autowired
    private CodeMappingRepository codeRepo;
    
    private String category;
    
    public CodeMappingRule category(String category) {
        this.category = category;
        return this;
    }
    
    @Override
    public String transform(String source) {
        return codeRepo.findTargetCode(category, source)
            .orElse("UNMAPPED_" + source);
    }
    
    @Override
    public boolean validate(String source) {
        return codeRepo.existsMapping(category, source);
    }
    
    @Override
    public String getRuleName() {
        return "CODE_MAPPING_" + category;
    }
}
```

#### 5.2.3 è½‰æ›æµç¨‹å¯¦ä½œ

```java
@Service
@Slf4j
public class DataTransformService {
    
    @Autowired
    private StagingRepository stagingRepo;
    
    @Autowired
    private TransformRuleEngine ruleEngine;
    
    @Autowired
    private ErrorRepository errorRepo;
    
    @Transactional
    public TransformResult transformCustomers(String batchId) {
        TransformResult result = new TransformResult(batchId);
        result.setStartTime(LocalDateTime.now());
        
        int successCount = 0;
        int errorCount = 0;
        
        // å–å¾—å¾…è½‰æ›è³‡æ–™
        List<StagingCustomer> stagingData = stagingRepo
            .findByBatchIdAndStatus(batchId, "PENDING");
        
        for (StagingCustomer staging : stagingData) {
            try {
                // åŸ·è¡Œè½‰æ›
                NewCustomer newCustomer = transformSingleRecord(staging);
                
                // æ›´æ–° Staging ç‹€æ…‹
                staging.setProcessStatus("TRANSFORMED");
                staging.setTransformedData(toJson(newCustomer));
                stagingRepo.save(staging);
                
                successCount++;
                
            } catch (TransformException e) {
                // è¨˜éŒ„éŒ¯èª¤
                staging.setProcessStatus("ERROR");
                staging.setErrorMessage(e.getMessage());
                stagingRepo.save(staging);
                
                errorRepo.save(new TransformError(
                    batchId,
                    staging.getSourceCustId(),
                    e.getRuleName(),
                    e.getMessage()
                ));
                
                errorCount++;
            }
        }
        
        result.setSuccessCount(successCount);
        result.setErrorCount(errorCount);
        result.setEndTime(LocalDateTime.now());
        
        log.info("Transform completed: success={}, error={}", 
            successCount, errorCount);
        
        return result;
    }
    
    private NewCustomer transformSingleRecord(StagingCustomer staging) {
        NewCustomer target = new NewCustomer();
        
        // 1. ç›´æ¥å°æ‡‰
        target.setCustomerNo(staging.getSourceCustId().trim());
        
        // 2. æ¸…ç†è½‰æ›
        target.setName(cleanName(staging.getSourceCustName()));
        
        // 3. ä»£ç¢¼å°æ‡‰
        target.setCustomerType(
            ruleEngine.transform("CUST_TYPE", staging.getSourceCustType())
        );
        
        // 4. æ—¥æœŸè½‰æ›
        target.setCreatedAt(
            ruleEngine.transform("DATE", staging.getSourceCreateDate())
        );
        
        // 5. ç³»çµ±æ¬„ä½
        target.setMigrationBatchId(staging.getBatchId());
        target.setMigrationTime(LocalDateTime.now());
        
        return target;
    }
    
    private String cleanName(String name) {
        if (name == null) return null;
        // å…¨å½¢è½‰åŠå½¢ã€å»é™¤å¤šé¤˜ç©ºç™½
        return StringUtils.normalizeSpace(
            CharUtils.toHalfWidth(name)
        );
    }
}
```

### 5.3 Loadï¼ˆè³‡æ–™è¼‰å…¥ï¼‰

#### 5.3.1 è¼‰å…¥ç­–ç•¥

| ç­–ç•¥ | èªªæ˜ | é©ç”¨æƒ…å¢ƒ |
|------|------|---------|
| **Insert** | ç›´æ¥æ’å…¥æ–°è³‡æ–™ | åˆå§‹è½‰ç½®ã€æ–°å¢è³‡æ–™ |
| **Upsert** | å­˜åœ¨å‰‡æ›´æ–°ï¼Œå¦å‰‡æ’å…¥ | å¢é‡åŒæ­¥ |
| **Merge** | åˆä½µæ“ä½œ | è¤‡é›œçš„æ›´æ–°é‚è¼¯ |
| **Bulk Load** | æ‰¹æ¬¡å¤§é‡è¼‰å…¥ | å¤§é‡è³‡æ–™å¿«é€Ÿè¼‰å…¥ |

#### 5.3.2 è¼‰å…¥æµç¨‹

```mermaid
sequenceDiagram
    participant S as Staging Table
    participant V as é©—è­‰æœå‹™
    participant T as Target Table
    participant L as Log Table
    
    S->>V: è®€å–è½‰æ›å¾Œè³‡æ–™
    V->>V: è³‡æ–™é©—è­‰
    alt é©—è­‰é€šé
        V->>T: æ‰¹æ¬¡è¼‰å…¥
        T-->>V: è¼‰å…¥çµæœ
        V->>L: è¨˜éŒ„æˆåŠŸ
        V->>S: æ›´æ–°ç‹€æ…‹ç‚º LOADED
    else é©—è­‰å¤±æ•—
        V->>L: è¨˜éŒ„éŒ¯èª¤
        V->>S: æ›´æ–°ç‹€æ…‹ç‚º ERROR
    end
```

#### 5.3.3 æ‰¹æ¬¡è¼‰å…¥å¯¦ä½œ

```java
@Service
@Slf4j
public class DataLoadService {
    
    @Autowired
    private StagingRepository stagingRepo;
    
    @Autowired
    private NewCustomerRepository targetRepo;
    
    @PersistenceContext
    private EntityManager entityManager;
    
    private static final int BATCH_SIZE = 1000;
    
    @Transactional
    public LoadResult loadCustomers(String batchId) {
        LoadResult result = new LoadResult(batchId);
        result.setStartTime(LocalDateTime.now());
        
        List<StagingCustomer> stagingData = stagingRepo
            .findByBatchIdAndStatus(batchId, "TRANSFORMED");
        
        int loadedCount = 0;
        int errorCount = 0;
        
        for (int i = 0; i < stagingData.size(); i++) {
            StagingCustomer staging = stagingData.get(i);
            
            try {
                // è§£æè½‰æ›å¾Œè³‡æ–™
                NewCustomer customer = fromJson(
                    staging.getTransformedData(), 
                    NewCustomer.class
                );
                
                // åŸ·è¡Œ Upsert
                upsertCustomer(customer);
                
                staging.setProcessStatus("LOADED");
                staging.setLoadTime(LocalDateTime.now());
                loadedCount++;
                
            } catch (Exception e) {
                staging.setProcessStatus("LOAD_ERROR");
                staging.setErrorMessage(e.getMessage());
                errorCount++;
                log.error("Load error for {}", staging.getSourceCustId(), e);
            }
            
            stagingRepo.save(staging);
            
            // æ‰¹æ¬¡æäº¤
            if ((i + 1) % BATCH_SIZE == 0) {
                entityManager.flush();
                entityManager.clear();
                log.info("Committed batch at index {}", i + 1);
            }
        }
        
        // æœ€å¾Œä¸€æ‰¹æäº¤
        entityManager.flush();
        
        result.setLoadedCount(loadedCount);
        result.setErrorCount(errorCount);
        result.setEndTime(LocalDateTime.now());
        
        return result;
    }
    
    private void upsertCustomer(NewCustomer customer) {
        Optional<NewCustomer> existing = targetRepo
            .findByCustomerNo(customer.getCustomerNo());
        
        if (existing.isPresent()) {
            // Update
            NewCustomer target = existing.get();
            target.setName(customer.getName());
            target.setCustomerType(customer.getCustomerType());
            target.setUpdatedAt(LocalDateTime.now());
            targetRepo.save(target);
        } else {
            // Insert
            customer.setCreatedAt(LocalDateTime.now());
            targetRepo.save(customer);
        }
    }
}
```

### 5.4 Staging Table è¨­è¨ˆ

#### 5.4.1 Staging Table çµæ§‹

```sql
-- Staging Table è¨­è¨ˆç¯„ä¾‹
CREATE TABLE stg_customer (
    -- Staging æ§åˆ¶æ¬„ä½
    stg_id              BIGINT AUTO_INCREMENT PRIMARY KEY,
    batch_id            VARCHAR(20) NOT NULL,
    extract_time        TIMESTAMP NOT NULL,
    process_status      VARCHAR(20) DEFAULT 'PENDING',
    
    -- ä¾†æºè³‡æ–™æ¬„ä½ï¼ˆåŸå§‹æ ¼å¼ä¿ç•™ï¼‰
    src_cust_id         VARCHAR(20),
    src_cust_name       VARCHAR(100),
    src_cust_type       VARCHAR(10),
    src_create_date     VARCHAR(20),
    src_raw_data        TEXT,           -- åŸå§‹è³‡æ–™ JSON
    
    -- è½‰æ›å¾Œè³‡æ–™æ¬„ä½
    tgt_customer_no     VARCHAR(20),
    tgt_name            VARCHAR(100),
    tgt_customer_type   VARCHAR(50),
    tgt_created_at      TIMESTAMP,
    tgt_transformed_data TEXT,          -- è½‰æ›å¾Œè³‡æ–™ JSON
    
    -- è™•ç†è¿½è¹¤æ¬„ä½
    transform_time      TIMESTAMP,
    load_time           TIMESTAMP,
    error_code          VARCHAR(20),
    error_message       TEXT,
    retry_count         INT DEFAULT 0,
    
    -- ç´¢å¼•
    INDEX idx_batch_status (batch_id, process_status),
    INDEX idx_src_cust_id (src_cust_id)
);
```

#### 5.4.2 Staging ç‹€æ…‹æµè½‰

```mermaid
stateDiagram-v2
    [*] --> PENDING: æŠ½å–å®Œæˆ
    PENDING --> TRANSFORMING: é–‹å§‹è½‰æ›
    TRANSFORMING --> TRANSFORMED: è½‰æ›æˆåŠŸ
    TRANSFORMING --> TRANSFORM_ERROR: è½‰æ›å¤±æ•—
    TRANSFORMED --> LOADING: é–‹å§‹è¼‰å…¥
    LOADING --> LOADED: è¼‰å…¥æˆåŠŸ
    LOADING --> LOAD_ERROR: è¼‰å…¥å¤±æ•—
    TRANSFORM_ERROR --> PENDING: é‡è©¦
    LOAD_ERROR --> TRANSFORMED: é‡è©¦
    LOADED --> [*]
    
    note right of TRANSFORM_ERROR
        è¨˜éŒ„éŒ¯èª¤åŸå› 
        äººå·¥ä»‹å…¥è™•ç†
    end note
```

### 5.5 Error Handling èˆ‡ Retry æ©Ÿåˆ¶

#### 5.5.1 éŒ¯èª¤åˆ†é¡

| éŒ¯èª¤é¡å‹ | èªªæ˜ | è™•ç†æ–¹å¼ |
|---------|------|---------|
| **å¯é‡è©¦éŒ¯èª¤** | æš«æ™‚æ€§å•é¡Œï¼ˆé€£ç·šé€¾æ™‚ã€é–å®šï¼‰ | è‡ªå‹•é‡è©¦ |
| **è³‡æ–™éŒ¯èª¤** | è³‡æ–™æ ¼å¼æˆ–å…§å®¹å•é¡Œ | è¨˜éŒ„ä¸¦è·³éï¼Œäººå·¥è™•ç† |
| **ç³»çµ±éŒ¯èª¤** | ç¨‹å¼é‚è¼¯æˆ–ç’°å¢ƒå•é¡Œ | åœæ­¢è™•ç†ï¼Œä¿®å¾©å¾Œé‡è·‘ |
| **æ¥­å‹™éŒ¯èª¤** | é•åæ¥­å‹™è¦å‰‡ | è½‰è‡³äººå·¥å¯©æ ¸ |

#### 5.5.2 éŒ¯èª¤è™•ç†æµç¨‹

```mermaid
flowchart TD
    A[è™•ç†è³‡æ–™] --> B{ç™¼ç”ŸéŒ¯èª¤?}
    B -->|å¦| C[è™•ç†ä¸‹ä¸€ç­†]
    B -->|æ˜¯| D{éŒ¯èª¤é¡å‹}
    
    D -->|å¯é‡è©¦| E{é‡è©¦æ¬¡æ•¸?}
    E -->|< 3| F[ç­‰å¾…å¾Œé‡è©¦]
    E -->|>= 3| G[è¨˜éŒ„ç‚ºå¤±æ•—]
    F --> A
    
    D -->|è³‡æ–™éŒ¯èª¤| H[è¨˜éŒ„éŒ¯èª¤]
    H --> I[å¯«å…¥ Error Table]
    I --> C
    
    D -->|ç³»çµ±éŒ¯èª¤| J[åœæ­¢è™•ç†]
    J --> K[ç™¼é€å‘Šè­¦]
    
    G --> I
```

#### 5.5.3 Retry æ©Ÿåˆ¶å¯¦ä½œ

```java
@Service
@Slf4j
public class RetryableTransformService {
    
    private static final int MAX_RETRY = 3;
    private static final long RETRY_DELAY_MS = 1000;
    
    @Autowired
    private TransformService transformService;
    
    @Autowired
    private ErrorRepository errorRepo;
    
    public TransformResult transformWithRetry(StagingCustomer staging) {
        int retryCount = 0;
        Exception lastException = null;
        
        while (retryCount < MAX_RETRY) {
            try {
                return transformService.transform(staging);
                
            } catch (RetryableException e) {
                retryCount++;
                lastException = e;
                log.warn("Retryable error, attempt {}/{}: {}", 
                    retryCount, MAX_RETRY, e.getMessage());
                
                if (retryCount < MAX_RETRY) {
                    sleep(RETRY_DELAY_MS * retryCount); // æŒ‡æ•¸é€€é¿
                }
                
            } catch (DataException e) {
                // è³‡æ–™éŒ¯èª¤ï¼Œä¸é‡è©¦
                log.error("Data error for {}: {}", 
                    staging.getSourceCustId(), e.getMessage());
                return handleDataError(staging, e);
                
            } catch (Exception e) {
                // ç³»çµ±éŒ¯èª¤ï¼Œä¸é‡è©¦
                log.error("System error for {}", staging.getSourceCustId(), e);
                throw new MigrationException("System error", e);
            }
        }
        
        // é‡è©¦æ¬¡æ•¸ç”¨ç›¡
        return handleRetryExhausted(staging, lastException);
    }
    
    private TransformResult handleDataError(
            StagingCustomer staging, DataException e) {
        
        errorRepo.save(new TransformError(
            staging.getBatchId(),
            staging.getSourceCustId(),
            "DATA_ERROR",
            e.getMessage(),
            e.getFieldName(),
            e.getFieldValue()
        ));
        
        return TransformResult.error(staging.getSourceCustId(), e.getMessage());
    }
    
    private TransformResult handleRetryExhausted(
            StagingCustomer staging, Exception e) {
        
        errorRepo.save(new TransformError(
            staging.getBatchId(),
            staging.getSourceCustId(),
            "RETRY_EXHAUSTED",
            "Max retry reached: " + e.getMessage()
        ));
        
        return TransformResult.error(staging.getSourceCustId(), 
            "Retry exhausted");
    }
    
    private void sleep(long ms) {
        try {
            Thread.sleep(ms);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}
```

#### 5.5.4 Error Table è¨­è¨ˆ

```sql
-- è½‰ç½®éŒ¯èª¤è¨˜éŒ„è¡¨
CREATE TABLE migration_error_log (
    error_id        BIGINT AUTO_INCREMENT PRIMARY KEY,
    batch_id        VARCHAR(20) NOT NULL,
    source_table    VARCHAR(100),
    source_key      VARCHAR(100),
    error_phase     VARCHAR(20),    -- EXTRACT, TRANSFORM, LOAD
    error_type      VARCHAR(50),    -- DATA_ERROR, RETRY_EXHAUSTED, etc.
    error_code      VARCHAR(20),
    error_message   TEXT,
    field_name      VARCHAR(100),
    field_value     TEXT,
    raw_data        TEXT,
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at     TIMESTAMP,
    resolved_by     VARCHAR(50),
    resolution_note TEXT,
    
    INDEX idx_batch_phase (batch_id, error_phase),
    INDEX idx_error_type (error_type)
);

-- æŸ¥è©¢æœªè§£æ±ºçš„éŒ¯èª¤
SELECT 
    error_phase,
    error_type,
    COUNT(*) AS error_count
FROM migration_error_log
WHERE batch_id = 'BATCH_001'
  AND resolved_at IS NULL
GROUP BY error_phase, error_type
ORDER BY error_count DESC;
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - Error Handling æ©Ÿåˆ¶å¿…é ˆåœ¨è¨­è¨ˆéšæ®µå°±è¦åŠƒå®Œæ•´
> - æ‰€æœ‰éŒ¯èª¤éƒ½å¿…é ˆè¨˜éŒ„ï¼Œä¸èƒ½éœé»˜ç•¥é
> - å»ºç«‹éŒ¯èª¤è™•ç† SOPï¼Œæ˜ç¢ºå®šç¾©å„é¡éŒ¯èª¤çš„è™•ç†æ–¹å¼
> - å®šæœŸæª¢è¦– Error Logï¼Œæ‰¾å‡ºç³»çµ±æ€§å•é¡Œ

---

## ç¬¬ 6 ç« ï¼šè³‡æ–™é©—è­‰èˆ‡æ¯”å°æ©Ÿåˆ¶

### 6.1 ç­†æ•¸é©—è­‰ï¼ˆRecord Countï¼‰

#### 6.1.1 é©—è­‰å±¤ç´š

| å±¤ç´š | èªªæ˜ | å…¬å¼ |
|------|------|------|
| **ç¸½ç­†æ•¸** | ä¾†æºèˆ‡ç›®æ¨™ç¸½ç­†æ•¸æ¯”å° | Source Count = Target Count |
| **æ‰¹æ¬¡ç­†æ•¸** | æ¯æ‰¹æ¬¡çš„ç­†æ•¸æ¯”å° | Batch Source = Batch Target |
| **ç‹€æ…‹ç­†æ•¸** | å„ç‹€æ…‹çš„ç­†æ•¸çµ±è¨ˆ | Success + Error = Total |

#### 6.1.2 ç­†æ•¸é©—è­‰ SQL

```sql
-- 1. ç¸½ç­†æ•¸æ¯”å°
SELECT 
    'SOURCE' AS system,
    COUNT(*) AS record_count
FROM old_customer
UNION ALL
SELECT 
    'TARGET' AS system,
    COUNT(*) AS record_count
FROM new_customer
WHERE migration_batch_id IS NOT NULL;

-- 2. æ‰¹æ¬¡ç­†æ•¸æ¯”å°
SELECT 
    s.batch_id,
    s.source_count,
    t.target_count,
    e.error_count,
    CASE 
        WHEN s.source_count = t.target_count + e.error_count 
        THEN 'PASS' 
        ELSE 'FAIL' 
    END AS validation_result
FROM (
    SELECT batch_id, COUNT(*) AS source_count
    FROM stg_customer
    GROUP BY batch_id
) s
LEFT JOIN (
    SELECT migration_batch_id, COUNT(*) AS target_count
    FROM new_customer
    GROUP BY migration_batch_id
) t ON s.batch_id = t.migration_batch_id
LEFT JOIN (
    SELECT batch_id, COUNT(*) AS error_count
    FROM migration_error_log
    WHERE error_phase = 'LOAD'
    GROUP BY batch_id
) e ON s.batch_id = e.batch_id;
```

#### 6.1.3 ç­†æ•¸é©—è­‰å ±å‘Šç¯„æœ¬

```markdown
## ç­†æ•¸é©—è­‰å ±å‘Š

### åŸ·è¡Œæ—¥æœŸï¼š2026-02-02
### æ‰¹æ¬¡ç·¨è™Ÿï¼šBATCH_001

| é …ç›® | ä¾†æºç­†æ•¸ | ç›®æ¨™ç­†æ•¸ | éŒ¯èª¤ç­†æ•¸ | å·®ç•° | çµæœ |
|------|---------|---------|---------|------|------|
| CUSTOMER | 1,234,567 | 1,234,500 | 67 | 0 | âœ… PASS |
| ACCOUNT | 3,456,789 | 3,456,789 | 0 | 0 | âœ… PASS |
| TRANSACTION | 50,000,000 | 49,999,985 | 10 | 5 | âš ï¸ WARN |

### å·®ç•°èªªæ˜
- TRANSACTION å·®ç•° 5 ç­†ï¼šç¶“ç¢ºèªç‚ºé‡è¤‡è³‡æ–™ï¼Œå·²éæ¿¾
```

### 6.2 é‡‘é¡ / æ•¸å€¼é©—è­‰ï¼ˆSum / Balance Checkï¼‰

#### 6.2.1 æ•¸å€¼é©—è­‰é …ç›®

| é©—è­‰é …ç›® | èªªæ˜ | é‡è¦æ€§ |
|---------|------|--------|
| **é‡‘é¡ç¸½å’Œ** | äº¤æ˜“é‡‘é¡ã€é¤˜é¡ç¸½å’Œ | ğŸ”´ æ¥µé«˜ |
| **æ•¸é‡çµ±è¨ˆ** | å¸³æˆ¶æ•¸ã€äº¤æ˜“ç­†æ•¸ | ğŸŸ  é«˜ |
| **å¹³å‡å€¼** | å¹³å‡é‡‘é¡ã€å¹³å‡ç­†æ•¸ | ğŸŸ¡ ä¸­ |
| **æ¥µå€¼** | æœ€å¤§å€¼ã€æœ€å°å€¼ | ğŸŸ¡ ä¸­ |

#### 6.2.2 é‡‘é¡é©—è­‰ SQL

```sql
-- é‡‘é¡é©—è­‰æŸ¥è©¢
WITH source_sum AS (
    SELECT 
        'SOURCE' AS system,
        SUM(balance) AS total_balance,
        SUM(txn_amount) AS total_txn_amount,
        COUNT(DISTINCT acct_no) AS account_count
    FROM old_account
),
target_sum AS (
    SELECT 
        'TARGET' AS system,
        SUM(balance) AS total_balance,
        SUM(txn_amount) AS total_txn_amount,
        COUNT(DISTINCT account_no) AS account_count
    FROM new_account
    WHERE migration_batch_id IS NOT NULL
)
SELECT 
    s.total_balance AS source_balance,
    t.total_balance AS target_balance,
    s.total_balance - t.total_balance AS balance_diff,
    CASE 
        WHEN ABS(s.total_balance - t.total_balance) < 0.01 
        THEN 'PASS' 
        ELSE 'FAIL' 
    END AS balance_check,
    s.total_txn_amount AS source_txn,
    t.total_txn_amount AS target_txn,
    s.total_txn_amount - t.total_txn_amount AS txn_diff
FROM source_sum s
CROSS JOIN target_sum t;
```

#### 6.2.3 åˆ†ç¾¤é‡‘é¡é©—è­‰

```sql
-- ä¾å®¢æˆ¶é¡å‹åˆ†ç¾¤é©—è­‰
SELECT 
    COALESCE(s.cust_type, t.customer_type) AS customer_type,
    s.source_balance,
    t.target_balance,
    s.source_balance - COALESCE(t.target_balance, 0) AS diff,
    CASE 
        WHEN ABS(s.source_balance - COALESCE(t.target_balance, 0)) < 0.01 
        THEN 'âœ… PASS' 
        ELSE 'âŒ FAIL' 
    END AS result
FROM (
    SELECT 
        cust_type,
        SUM(balance) AS source_balance
    FROM old_account oa
    JOIN old_customer oc ON oa.cust_id = oc.cust_id
    GROUP BY cust_type
) s
FULL OUTER JOIN (
    SELECT 
        customer_type,
        SUM(balance) AS target_balance
    FROM new_account na
    JOIN new_customer nc ON na.customer_id = nc.id
    WHERE na.migration_batch_id IS NOT NULL
    GROUP BY customer_type
) t ON s.cust_type = (
    SELECT source_code 
    FROM migration_code_mapping 
    WHERE category = 'CUST_TYPE' 
      AND target_code = t.customer_type
);
```

### 6.3 Key-based è³‡æ–™æ¯”å°

#### 6.3.1 æ¯”å°ç­–ç•¥

```mermaid
flowchart TD
    A[é–‹å§‹æ¯”å°] --> B[å–å¾—ä¾†æº Key æ¸…å–®]
    B --> C[å–å¾—ç›®æ¨™ Key æ¸…å–®]
    C --> D{æ¯”å°é¡å‹}
    
    D -->|å­˜åœ¨æ€§| E[æª¢æŸ¥ Key æ˜¯å¦éƒ½å­˜åœ¨]
    D -->|å®Œæ•´æ€§| F[æª¢æŸ¥æ‰€æœ‰æ¬„ä½æ˜¯å¦ä¸€è‡´]
    D -->|ä¸€è‡´æ€§| G[æª¢æŸ¥é—œéµæ¬„ä½æ˜¯å¦ä¸€è‡´]
    
    E --> H[ç”¢å‡ºéºå¤±æ¸…å–®]
    F --> I[ç”¢å‡ºå·®ç•°æ¸…å–®]
    G --> J[ç”¢å‡ºä¸ä¸€è‡´æ¸…å–®]
    
    H --> K[å½™æ•´å ±å‘Š]
    I --> K
    J --> K
```

#### 6.3.2 Key æ¯”å° SQL

```sql
-- 1. æ‰¾å‡ºä¾†æºæœ‰ä½†ç›®æ¨™æ²’æœ‰çš„è³‡æ–™ï¼ˆéºå¤±ï¼‰
SELECT s.cust_id AS missing_key
FROM old_customer s
LEFT JOIN new_customer t 
    ON s.cust_id = t.customer_no
WHERE t.id IS NULL
  AND s.status = 'A';  -- åªæª¢æŸ¥æœ‰æ•ˆè³‡æ–™

-- 2. æ‰¾å‡ºç›®æ¨™æœ‰ä½†ä¾†æºæ²’æœ‰çš„è³‡æ–™ï¼ˆå¤šé¤˜ï¼‰
SELECT t.customer_no AS extra_key
FROM new_customer t
LEFT JOIN old_customer s 
    ON t.customer_no = s.cust_id
WHERE s.cust_id IS NULL
  AND t.migration_batch_id IS NOT NULL;

-- 3. é—œéµæ¬„ä½æ¯”å°ï¼ˆæ‰¾å‡ºä¸ä¸€è‡´ï¼‰
SELECT 
    s.cust_id,
    s.cust_name AS source_name,
    t.name AS target_name,
    s.balance AS source_balance,
    t.balance AS target_balance
FROM old_customer s
JOIN new_customer t 
    ON s.cust_id = t.customer_no
WHERE s.cust_name <> t.name
   OR ABS(s.balance - t.balance) > 0.01;
```

#### 6.3.3 æ¯”å°çµæœçµ±è¨ˆ

```sql
-- æ¯”å°çµæœçµ±è¨ˆ
WITH comparison AS (
    SELECT 
        s.cust_id,
        CASE 
            WHEN t.id IS NULL THEN 'MISSING'
            WHEN s.cust_name <> t.name THEN 'NAME_MISMATCH'
            WHEN ABS(s.balance - t.balance) > 0.01 THEN 'BALANCE_MISMATCH'
            ELSE 'MATCH'
        END AS compare_result
    FROM old_customer s
    LEFT JOIN new_customer t 
        ON s.cust_id = t.customer_no
)
SELECT 
    compare_result,
    COUNT(*) AS count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) AS percentage
FROM comparison
GROUP BY compare_result
ORDER BY count DESC;
```

### 6.4 æŠ½æ¨£é©—è­‰ï¼ˆSamplingï¼‰

#### 6.4.1 æŠ½æ¨£ç­–ç•¥

| ç­–ç•¥ | èªªæ˜ | é©ç”¨æƒ…å¢ƒ |
|------|------|---------|
| **éš¨æ©ŸæŠ½æ¨£** | éš¨æ©Ÿé¸å– N ç­† | ä¸€èˆ¬è³‡æ–™é©—è­‰ |
| **åˆ†å±¤æŠ½æ¨£** | å„é¡å‹å„æŠ½ N ç­† | ç¢ºä¿å„é¡å‹éƒ½è¢«é©—è­‰ |
| **é‚Šç•ŒæŠ½æ¨£** | æŠ½å–æ¥µå€¼è³‡æ–™ | é©—è­‰é‚Šç•Œæ¢ä»¶ |
| **é¢¨éšªæŠ½æ¨£** | é‡å°é«˜é¢¨éšªè³‡æ–™ | é‡‘é¡å¤§ã€ç‹€æ…‹ç‰¹æ®Š |

#### 6.4.2 æŠ½æ¨£ SQL

```sql
-- 1. éš¨æ©ŸæŠ½æ¨£ 100 ç­†
SELECT *
FROM new_customer
WHERE migration_batch_id = 'BATCH_001'
ORDER BY RANDOM()
LIMIT 100;

-- 2. åˆ†å±¤æŠ½æ¨£ï¼ˆæ¯ç¨®é¡å‹å„ 20 ç­†ï¼‰
WITH ranked AS (
    SELECT 
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_type 
            ORDER BY RANDOM()
        ) AS rn
    FROM new_customer
    WHERE migration_batch_id = 'BATCH_001'
)
SELECT *
FROM ranked
WHERE rn <= 20;

-- 3. é¢¨éšªæŠ½æ¨£ï¼ˆé«˜é‡‘é¡ï¼‰
SELECT *
FROM new_account
WHERE migration_batch_id = 'BATCH_001'
  AND balance > 1000000
ORDER BY balance DESC
LIMIT 50;
```

#### 6.4.3 æŠ½æ¨£é©—è­‰è¡¨å–®

```markdown
## æŠ½æ¨£é©—è­‰è¡¨å–®

### æŠ½æ¨£æ¢ä»¶
- æ‰¹æ¬¡ï¼šBATCH_001
- æŠ½æ¨£æ•¸é‡ï¼š100 ç­†
- æŠ½æ¨£æ–¹å¼ï¼šåˆ†å±¤éš¨æ©ŸæŠ½æ¨£

### é©—è­‰çµæœ

| åºè™Ÿ | å®¢æˆ¶ç·¨è™Ÿ | ä¾†æºå§“å | ç›®æ¨™å§“å | ä¾†æºé¤˜é¡ | ç›®æ¨™é¤˜é¡ | é©—è­‰çµæœ | å‚™è¨» |
|------|---------|---------|---------|---------|---------|---------|------|
| 1 | C001 | ç‹å°æ˜ | ç‹å°æ˜ | 50,000 | 50,000 | âœ… | - |
| 2 | C002 | æå¤§è¯ | æå¤§è¯ | 120,000 | 120,000 | âœ… | - |
| 3 | C003 | å¼µä¸‰ã€€ | å¼µä¸‰ | 30,000 | 30,000 | âš ï¸ | å…¨å½¢ç©ºç™½å·²è™•ç† |

### é©—è­‰äººå“¡ï¼š_______________
### é©—è­‰æ—¥æœŸï¼š_______________
### ç°½æ ¸ï¼š_______________
```

### 6.5 è‡ªå‹•åŒ–é©—è­‰å ±è¡¨è¨­è¨ˆ

#### 6.5.1 é©—è­‰å ±è¡¨æ¶æ§‹

```mermaid
flowchart TD
    subgraph è³‡æ–™ä¾†æº
        A[(Source DB)]
        B[(Target DB)]
        C[(Staging DB)]
    end
    
    subgraph é©—è­‰å¼•æ“
        D[ç­†æ•¸é©—è­‰]
        E[é‡‘é¡é©—è­‰]
        F[Key æ¯”å°]
        G[æŠ½æ¨£é©—è­‰]
    end
    
    subgraph å ±è¡¨è¼¸å‡º
        H[é©—è­‰æ‘˜è¦]
        I[å·®ç•°æ˜ç´°]
        J[éŒ¯èª¤æ¸…å–®]
        K[è¶¨å‹¢åˆ†æ]
    end
    
    A --> D
    B --> D
    A --> E
    B --> E
    A --> F
    B --> F
    C --> G
    
    D --> H
    E --> H
    F --> I
    G --> J
    
    H --> L[Dashboard]
    I --> L
    J --> L
    K --> L
```

#### 6.5.2 é©—è­‰å ±è¡¨ç”¢ç”Ÿç¨‹å¼

```java
@Service
@Slf4j
public class ValidationReportService {
    
    @Autowired
    private ValidationRepository validationRepo;
    
    public ValidationReport generateReport(String batchId) {
        ValidationReport report = new ValidationReport();
        report.setBatchId(batchId);
        report.setGeneratedAt(LocalDateTime.now());
        
        // 1. ç­†æ•¸é©—è­‰
        RecordCountResult countResult = validateRecordCount(batchId);
        report.setRecordCountResult(countResult);
        
        // 2. é‡‘é¡é©—è­‰
        AmountCheckResult amountResult = validateAmount(batchId);
        report.setAmountCheckResult(amountResult);
        
        // 3. Key æ¯”å°
        KeyCompareResult keyResult = compareKeys(batchId);
        report.setKeyCompareResult(keyResult);
        
        // 4. è¨ˆç®—æ•´é«”ç‹€æ…‹
        report.setOverallStatus(calculateOverallStatus(
            countResult, amountResult, keyResult
        ));
        
        // 5. å„²å­˜å ±è¡¨
        validationRepo.saveReport(report);
        
        // 6. ç”¢ç”Ÿ Markdown æª”æ¡ˆ
        generateMarkdownReport(report);
        
        return report;
    }
    
    private void generateMarkdownReport(ValidationReport report) {
        StringBuilder md = new StringBuilder();
        
        md.append("# è³‡æ–™è½‰ç½®é©—è­‰å ±å‘Š\n\n");
        md.append(String.format("- **æ‰¹æ¬¡ç·¨è™Ÿ**ï¼š%s\n", report.getBatchId()));
        md.append(String.format("- **ç”¢ç”Ÿæ™‚é–“**ï¼š%s\n", report.getGeneratedAt()));
        md.append(String.format("- **æ•´é«”ç‹€æ…‹**ï¼š%s\n\n", 
            report.getOverallStatus().getDisplayName()));
        
        // ç­†æ•¸é©—è­‰å€å¡Š
        md.append("## 1. ç­†æ•¸é©—è­‰\n\n");
        md.append("| é …ç›® | ä¾†æº | ç›®æ¨™ | å·®ç•° | çµæœ |\n");
        md.append("|------|------|------|------|------|\n");
        for (RecordCountItem item : report.getRecordCountResult().getItems()) {
            md.append(String.format("| %s | %,d | %,d | %,d | %s |\n",
                item.getTableName(),
                item.getSourceCount(),
                item.getTargetCount(),
                item.getDifference(),
                item.isPassed() ? "âœ…" : "âŒ"
            ));
        }
        
        // é‡‘é¡é©—è­‰å€å¡Š
        md.append("\n## 2. é‡‘é¡é©—è­‰\n\n");
        // ... é¡ä¼¼æ ¼å¼
        
        // è¼¸å‡ºæª”æ¡ˆ
        String fileName = String.format("validation_report_%s.md", 
            report.getBatchId());
        writeToFile(fileName, md.toString());
    }
    
    private ValidationStatus calculateOverallStatus(
            RecordCountResult count, 
            AmountCheckResult amount,
            KeyCompareResult key) {
        
        if (!count.isPassed() || !amount.isPassed()) {
            return ValidationStatus.FAILED;
        }
        
        if (key.getMismatchCount() > 0) {
            return ValidationStatus.WARNING;
        }
        
        return ValidationStatus.PASSED;
    }
}
```

#### 6.5.3 é©—è­‰ Dashboard è¨­è¨ˆ

```sql
-- Dashboard ç”¨å½™ç¸½æŸ¥è©¢
CREATE VIEW v_migration_dashboard AS
SELECT 
    batch_id,
    -- ç­†æ•¸ç‹€æ…‹
    SUM(CASE WHEN record_count_passed THEN 1 ELSE 0 END) AS count_pass,
    SUM(CASE WHEN NOT record_count_passed THEN 1 ELSE 0 END) AS count_fail,
    
    -- é‡‘é¡ç‹€æ…‹
    SUM(CASE WHEN amount_check_passed THEN 1 ELSE 0 END) AS amount_pass,
    SUM(CASE WHEN NOT amount_check_passed THEN 1 ELSE 0 END) AS amount_fail,
    
    -- éŒ¯èª¤çµ±è¨ˆ
    SUM(error_count) AS total_errors,
    
    -- é€²åº¦
    ROUND(
        SUM(CASE WHEN status = 'LOADED' THEN 1 ELSE 0 END) * 100.0 / 
        COUNT(*), 2
    ) AS completion_pct,
    
    -- æ™‚é–“
    MIN(start_time) AS start_time,
    MAX(end_time) AS end_time,
    TIMESTAMPDIFF(MINUTE, MIN(start_time), MAX(end_time)) AS duration_min
    
FROM migration_batch_control
GROUP BY batch_id;
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - é©—è­‰å ±è¡¨æ‡‰è‡ªå‹•ç”¢ç”Ÿï¼Œä¸ä¾è³´äººå·¥è£½ä½œ
> - é—œéµé©—è­‰é …ç›®ï¼ˆç­†æ•¸ã€é‡‘é¡ï¼‰å¿…é ˆ 100% é€šéæ‰èƒ½ä¸Šç·š
> - å»ºç«‹é©—è­‰åŸºæº–ç·šï¼ˆBaselineï¼‰ï¼Œæ¯æ¬¡åŸ·è¡Œå¾Œæ¯”å°
> - é©—è­‰å ±è¡¨éœ€ä¿ç•™å­˜æª”ï¼Œä½œç‚ºä¸Šç·šç°½æ ¸ä¾æ“š

---

## ç¬¬ 7 ç« ï¼šå·¥å…·èˆ‡æŠ€è¡“é¸å‹å»ºè­°

### 7.1 SQL / Stored Procedure

#### 7.1.1 é©ç”¨æƒ…å¢ƒ

| æƒ…å¢ƒ | é©åˆåº¦ | èªªæ˜ |
|------|--------|------|
| åŒè³‡æ–™åº«è½‰ç½® | â­â­â­â­â­ | æœ€ä½³é¸æ“‡ï¼Œæ•ˆèƒ½æœ€å¥½ |
| ç°¡å–®è½‰æ›é‚è¼¯ | â­â­â­â­â­ | SQL åŸç”Ÿæ”¯æ´ |
| è·¨è³‡æ–™åº«è½‰ç½® | â­â­ | éœ€é€é DB Link |
| è¤‡é›œæ¥­å‹™é‚è¼¯ | â­â­ | ç¶­è­·å›°é›£ |
| æª”æ¡ˆè™•ç† | â­ | ä¸é©åˆ |

#### 7.1.2 Stored Procedure ç¯„ä¾‹

```sql
-- å®¢æˆ¶è³‡æ–™è½‰ç½® Stored Procedure
CREATE OR REPLACE PROCEDURE sp_migrate_customer(
    p_batch_id IN VARCHAR2,
    p_start_key IN VARCHAR2,
    p_end_key IN VARCHAR2,
    p_result OUT VARCHAR2
)
AS
    v_count NUMBER := 0;
    v_error_count NUMBER := 0;
    v_start_time TIMESTAMP := SYSTIMESTAMP;
BEGIN
    -- è¨˜éŒ„é–‹å§‹
    UPDATE migration_batch_control
    SET status = 'RUNNING', start_time = v_start_time
    WHERE batch_id = p_batch_id;
    COMMIT;
    
    -- åŸ·è¡Œè½‰ç½®ï¼ˆä½¿ç”¨ MERGEï¼‰
    MERGE INTO new_customer t
    USING (
        SELECT 
            cust_id AS customer_no,
            TRIM(cust_name) AS name,
            CASE cust_type
                WHEN '1' THEN 'INDIVIDUAL'
                WHEN '2' THEN 'CORPORATE'
                ELSE 'UNKNOWN'
            END AS customer_type,
            TO_TIMESTAMP(create_dt, 'YYYYMMDD') AS created_at,
            p_batch_id AS migration_batch_id
        FROM old_customer
        WHERE cust_id BETWEEN p_start_key AND p_end_key
          AND status = 'A'
    ) s
    ON (t.customer_no = s.customer_no)
    WHEN MATCHED THEN
        UPDATE SET 
            t.name = s.name,
            t.customer_type = s.customer_type,
            t.updated_at = SYSTIMESTAMP
    WHEN NOT MATCHED THEN
        INSERT (customer_no, name, customer_type, created_at, migration_batch_id)
        VALUES (s.customer_no, s.name, s.customer_type, s.created_at, s.migration_batch_id);
    
    v_count := SQL%ROWCOUNT;
    COMMIT;
    
    -- æ›´æ–°æ‰¹æ¬¡ç‹€æ…‹
    UPDATE migration_batch_control
    SET status = 'SUCCESS',
        processed_rows = v_count,
        end_time = SYSTIMESTAMP
    WHERE batch_id = p_batch_id;
    COMMIT;
    
    p_result := 'SUCCESS: ' || v_count || ' rows processed';
    
EXCEPTION
    WHEN OTHERS THEN
        ROLLBACK;
        UPDATE migration_batch_control
        SET status = 'FAILED',
            error_message = SQLERRM,
            end_time = SYSTIMESTAMP
        WHERE batch_id = p_batch_id;
        COMMIT;
        
        p_result := 'FAILED: ' || SQLERRM;
END;
/
```

#### 7.1.3 SQL æ•ˆèƒ½å„ªåŒ–æŠ€å·§

```sql
-- 1. ä½¿ç”¨ Hint å„ªåŒ–å¤§é‡è³‡æ–™è™•ç†
INSERT /*+ APPEND PARALLEL(4) */ INTO new_customer
SELECT /*+ PARALLEL(4) */
    cust_id, cust_name, cust_type, create_dt
FROM old_customer;

-- 2. åˆ†æ‰¹è™•ç†é¿å… Undo çˆ†æ»¿
DECLARE
    v_batch_size NUMBER := 10000;
BEGIN
    LOOP
        INSERT INTO new_customer
        SELECT * FROM old_customer
        WHERE ROWNUM <= v_batch_size
          AND cust_id NOT IN (SELECT customer_no FROM new_customer);
        
        EXIT WHEN SQL%ROWCOUNT = 0;
        COMMIT;
    END LOOP;
END;

-- 3. åœç”¨ Index åŠ é€Ÿè¼‰å…¥
ALTER INDEX idx_customer_name UNUSABLE;
-- åŸ·è¡Œå¤§é‡ INSERT
ALTER INDEX idx_customer_name REBUILD;

-- 4. ä½¿ç”¨ NOLOGGING åŠ é€Ÿï¼ˆéœ€è¬¹æ…ï¼‰
ALTER TABLE new_customer NOLOGGING;
INSERT /*+ APPEND */ INTO new_customer ...;
ALTER TABLE new_customer LOGGING;
```

### 7.2 ETL å·¥å…·

#### 7.2.1 å·¥å…·æ¯”è¼ƒ

| å·¥å…· | é¡å‹ | å„ªé» | ç¼ºé» | é©ç”¨æƒ…å¢ƒ |
|------|------|------|------|---------|
| **Talend** | å•†æ¥­/é–‹æº | åœ–å½¢åŒ–ã€åŠŸèƒ½å®Œæ•´ | å­¸ç¿’æ›²ç·šé™¡ | ä¼æ¥­ç´š ETL |
| **Informatica** | å•†æ¥­ | ä¼æ¥­ç´šã€ç©©å®š | åƒ¹æ ¼é«˜ | å¤§å‹ä¼æ¥­ |
| **Apache Airflow** | é–‹æº | å½ˆæ€§é«˜ã€å¯ç¨‹å¼åŒ– | éœ€å¯« Python | æŠ€è¡“åœ˜éšŠ |
| **Spring Batch** | é–‹æº | Java ç”Ÿæ…‹ç³»æ•´åˆ | éœ€é–‹ç™¼ | Java å°ˆæ¡ˆ |
| **SSIS** | å•†æ¥­ | èˆ‡ SQL Server æ•´åˆ | é™ MS å¹³å° | Windows ç’°å¢ƒ |

#### 7.2.2 Apache Airflow DAG ç¯„ä¾‹

```python
# migration_dag.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.sql import SQLCheckOperator
from airflow.utils.dates import days_ago
from datetime import timedelta

default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'email_on_failure': True,
    'email': ['admin@company.com'],
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'customer_migration',
    default_args=default_args,
    description='Customer data migration pipeline',
    schedule_interval=None,  # Manual trigger
    start_date=days_ago(1),
    tags=['migration'],
)

def extract_customers(**context):
    """Extract customers from source system"""
    from migration.extract import CustomerExtractor
    
    batch_id = context['params']['batch_id']
    extractor = CustomerExtractor()
    result = extractor.extract(batch_id)
    
    context['ti'].xcom_push(key='extract_count', value=result.count)
    return result

def transform_customers(**context):
    """Transform customer data"""
    from migration.transform import CustomerTransformer
    
    batch_id = context['params']['batch_id']
    transformer = CustomerTransformer()
    result = transformer.transform(batch_id)
    
    context['ti'].xcom_push(key='transform_count', value=result.count)
    return result

def load_customers(**context):
    """Load customers to target system"""
    from migration.load import CustomerLoader
    
    batch_id = context['params']['batch_id']
    loader = CustomerLoader()
    result = loader.load(batch_id)
    
    context['ti'].xcom_push(key='load_count', value=result.count)
    return result

# Task definitions
extract_task = PythonOperator(
    task_id='extract_customers',
    python_callable=extract_customers,
    dag=dag,
)

transform_task = PythonOperator(
    task_id='transform_customers',
    python_callable=transform_customers,
    dag=dag,
)

load_task = PythonOperator(
    task_id='load_customers',
    python_callable=load_customers,
    dag=dag,
)

validate_count = SQLCheckOperator(
    task_id='validate_count',
    conn_id='target_db',
    sql="""
        SELECT CASE 
            WHEN source_count = target_count THEN 1 
            ELSE 0 
        END
        FROM migration_summary
        WHERE batch_id = '{{ params.batch_id }}'
    """,
    dag=dag,
)

# Task dependencies
extract_task >> transform_task >> load_task >> validate_count
```

### 7.3 ç¨‹å¼èªè¨€é¸æ“‡

#### 7.3.1 èªè¨€æ¯”è¼ƒ

| èªè¨€ | é–‹ç™¼æ•ˆç‡ | åŸ·è¡Œæ•ˆèƒ½ | é©ç”¨æƒ…å¢ƒ | å„ªé» | ç¼ºé» |
|------|---------|---------|---------|------|------|
| **SQL** | â­â­â­ | â­â­â­â­â­ | åŒè³‡æ–™åº«è½‰ç½® | æ•ˆèƒ½æœ€ä½³ã€åŸç”Ÿæ”¯æ´ | è¤‡é›œé‚è¼¯é›£ç¶­è­· |
| **Java** | â­â­â­ | â­â­â­â­ | ä¼æ¥­ç´šå°ˆæ¡ˆ | ç”Ÿæ…‹ç³»å®Œæ•´ã€ç©©å®š | é–‹ç™¼æ™‚é–“è¼ƒé•· |
| **Python** | â­â­â­â­â­ | â­â­ | å¿«é€Ÿé–‹ç™¼ | èªæ³•ç°¡æ½”ã€å¥—ä»¶è±å¯Œ | å¤§é‡è³‡æ–™æ•ˆèƒ½å·® |
| **Shell** | â­â­â­â­ | â­â­ | ç°¡å–®æª”æ¡ˆè™•ç† | å¿«é€Ÿç·¨å¯«è…³æœ¬ | éŒ¯èª¤è™•ç†å›°é›£ |

**é¸å‹å»ºè­°**ï¼š
- **å¤§é‡è³‡æ–™ï¼ˆåƒè¬ç­†ä»¥ä¸Šï¼‰**ï¼šå„ªå…ˆè€ƒæ…® SQL æˆ– Java
- **éœ€è¦è¤‡é›œè½‰æ›é‚è¼¯**ï¼šJava æˆ– Python
- **å¿«é€ŸåŸå‹é–‹ç™¼**ï¼šPython
- **åŒè³‡æ–™åº«å…§è½‰ç½®**ï¼šSQLï¼ˆæ•ˆèƒ½æœ€ä½³ï¼‰

#### 7.3.2 Spring Batch æ¶æ§‹

```mermaid
flowchart TD
    subgraph Spring Batch
        A[Job] --> B[Step 1: Extract]
        B --> C[Step 2: Transform]
        C --> D[Step 3: Load]
        
        B --> E[ItemReader]
        B --> F[ItemProcessor]
        B --> G[ItemWriter]
    end
    
    subgraph è³‡æ–™æµ
        H[(Source DB)] --> E
        F --> I[Transform Logic]
        G --> J[(Target DB)]
    end
```

#### 7.3.3 Spring Batch ç¨‹å¼ç¯„ä¾‹

```java
@Configuration
@EnableBatchProcessing
public class CustomerMigrationBatchConfig {
    
    @Autowired
    private JobBuilderFactory jobBuilderFactory;
    
    @Autowired
    private StepBuilderFactory stepBuilderFactory;
    
    @Autowired
    private DataSource sourceDataSource;
    
    @Autowired
    private DataSource targetDataSource;
    
    @Bean
    public Job customerMigrationJob() {
        return jobBuilderFactory.get("customerMigrationJob")
            .incrementer(new RunIdIncrementer())
            .listener(new JobCompletionListener())
            .flow(customerMigrationStep())
            .end()
            .build();
    }
    
    @Bean
    public Step customerMigrationStep() {
        return stepBuilderFactory.get("customerMigrationStep")
            .<OldCustomer, NewCustomer>chunk(1000)
            .reader(customerReader())
            .processor(customerProcessor())
            .writer(customerWriter())
            .faultTolerant()
            .skipLimit(100)
            .skip(DataIntegrityViolationException.class)
            .retryLimit(3)
            .retry(DeadlockLoserDataAccessException.class)
            .listener(new ChunkListener())
            .build();
    }
    
    @Bean
    @StepScope
    public JdbcPagingItemReader<OldCustomer> customerReader() {
        JdbcPagingItemReader<OldCustomer> reader = new JdbcPagingItemReader<>();
        reader.setDataSource(sourceDataSource);
        reader.setFetchSize(1000);
        reader.setPageSize(1000);
        
        Map<String, Order> sortKeys = new HashMap<>();
        sortKeys.put("cust_id", Order.ASCENDING);
        
        OraclePagingQueryProvider queryProvider = new OraclePagingQueryProvider();
        queryProvider.setSelectClause("cust_id, cust_name, cust_type, create_dt");
        queryProvider.setFromClause("old_customer");
        queryProvider.setWhereClause("status = 'A'");
        queryProvider.setSortKeys(sortKeys);
        
        reader.setQueryProvider(queryProvider);
        reader.setRowMapper(new OldCustomerRowMapper());
        
        return reader;
    }
    
    @Bean
    public ItemProcessor<OldCustomer, NewCustomer> customerProcessor() {
        return new CustomerTransformProcessor();
    }
    
    @Bean
    public JdbcBatchItemWriter<NewCustomer> customerWriter() {
        JdbcBatchItemWriter<NewCustomer> writer = new JdbcBatchItemWriter<>();
        writer.setDataSource(targetDataSource);
        writer.setSql("""
            INSERT INTO new_customer 
                (customer_no, name, customer_type, created_at, migration_batch_id)
            VALUES 
                (:customerNo, :name, :customerType, :createdAt, :migrationBatchId)
            """);
        writer.setItemSqlParameterSourceProvider(
            new BeanPropertyItemSqlParameterSourceProvider<>()
        );
        return writer;
    }
}

/**
 * è½‰æ›è™•ç†å™¨
 */
@Component
public class CustomerTransformProcessor 
        implements ItemProcessor<OldCustomer, NewCustomer> {
    
    @Autowired
    private CodeMappingService codeMappingService;
    
    @Value("#{jobParameters['batchId']}")
    private String batchId;
    
    @Override
    public NewCustomer process(OldCustomer source) throws Exception {
        NewCustomer target = new NewCustomer();
        
        // è½‰æ›é‚è¼¯
        target.setCustomerNo(source.getCustId().trim());
        target.setName(cleanName(source.getCustName()));
        target.setCustomerType(
            codeMappingService.map("CUST_TYPE", source.getCustType())
        );
        target.setCreatedAt(parseDate(source.getCreateDt()));
        target.setMigrationBatchId(batchId);
        
        return target;
    }
    
    private String cleanName(String name) {
        if (name == null) return null;
        return StringUtils.normalizeSpace(name);
    }
    
    private LocalDateTime parseDate(String dateStr) {
        if (dateStr == null || dateStr.isEmpty()) return null;
        return LocalDate.parse(dateStr, 
            DateTimeFormatter.ofPattern("yyyyMMdd"))
            .atStartOfDay();
    }
}
```

### 7.4 æª”æ¡ˆè™•ç†å·¥å…·

#### 7.4.1 æª”æ¡ˆé¡å‹è™•ç†

| æª”æ¡ˆé¡å‹ | è™•ç†å·¥å…· | æ³¨æ„äº‹é … |
|---------|---------|---------|
| CSV | Apache Commons CSV, OpenCSV | ç·¨ç¢¼ã€åˆ†éš”ç¬¦è™Ÿ |
| å›ºå®šé•·åº¦ | Java IO, FlatFileItemReader | Layout å®šç¾© |
| Excel | Apache POI, EasyExcel | è¨˜æ†¶é«”æ§åˆ¶ |
| XML | JAXB, StAX | å¤§æª”æ¡ˆç”¨ StAX |
| JSON | Jackson, Gson | ä¸²æµè™•ç† |

#### 7.4.2 å›ºå®šé•·åº¦æª”æ¡ˆè™•ç†

```java
/**
 * å›ºå®šé•·åº¦æª”æ¡ˆè§£æå™¨
 */
@Component
public class FixedLengthFileParser {
    
    /**
     * Layout å®šç¾©
     */
    private static final FieldLayout[] CUSTOMER_LAYOUT = {
        new FieldLayout("custId", 0, 10),
        new FieldLayout("custName", 10, 40),
        new FieldLayout("custType", 50, 2),
        new FieldLayout("idNo", 52, 10),
        new FieldLayout("birthDate", 62, 8),
        new FieldLayout("createDate", 70, 8)
    };
    
    public List<Map<String, String>> parseFile(Path filePath, Charset charset) 
            throws IOException {
        
        List<Map<String, String>> records = new ArrayList<>();
        
        try (BufferedReader reader = Files.newBufferedReader(filePath, charset)) {
            String line;
            int lineNum = 0;
            
            while ((line = reader.readLine()) != null) {
                lineNum++;
                try {
                    Map<String, String> record = parseLine(line);
                    record.put("_lineNum", String.valueOf(lineNum));
                    records.add(record);
                } catch (Exception e) {
                    log.error("Parse error at line {}: {}", lineNum, e.getMessage());
                    // è¨˜éŒ„éŒ¯èª¤ä½†ç¹¼çºŒè™•ç†
                }
            }
        }
        
        return records;
    }
    
    private Map<String, String> parseLine(String line) {
        Map<String, String> record = new LinkedHashMap<>();
        
        for (FieldLayout field : CUSTOMER_LAYOUT) {
            int endPos = Math.min(field.start + field.length, line.length());
            String value = "";
            
            if (field.start < line.length()) {
                value = line.substring(field.start, endPos).trim();
            }
            
            record.put(field.name, value);
        }
        
        return record;
    }
    
    @Data
    @AllArgsConstructor
    private static class FieldLayout {
        private String name;
        private int start;
        private int length;
    }
}
```

#### 7.4.3 å¤§æª”æ¡ˆä¸²æµè™•ç†

```java
/**
 * å¤§æª”æ¡ˆä¸²æµè™•ç†ï¼ˆé¿å… OOMï¼‰
 */
@Service
public class LargeFileProcessor {
    
    private static final int BATCH_SIZE = 10000;
    
    public void processLargeFile(Path filePath, Consumer<List<String>> batchHandler) 
            throws IOException {
        
        try (Stream<String> lines = Files.lines(filePath, Charset.forName("Big5"))) {
            
            List<String> batch = new ArrayList<>(BATCH_SIZE);
            
            lines.forEach(line -> {
                batch.add(line);
                
                if (batch.size() >= BATCH_SIZE) {
                    batchHandler.accept(new ArrayList<>(batch));
                    batch.clear();
                }
            });
            
            // è™•ç†æœ€å¾Œä¸€æ‰¹
            if (!batch.isEmpty()) {
                batchHandler.accept(batch);
            }
        }
    }
    
    /**
     * ä½¿ç”¨ç¯„ä¾‹
     */
    public void example() throws IOException {
        processLargeFile(Path.of("/data/large_file.txt"), batch -> {
            log.info("Processing batch of {} records", batch.size());
            // è™•ç†é‚è¼¯
        });
    }
}
```

### 7.5 é©—è­‰èˆ‡æ¸¬è©¦è¼”åŠ©å·¥å…·

#### 7.5.1 å·¥å…·æ¸…å–®

| å·¥å…·é¡å‹ | å·¥å…·åç¨± | ç”¨é€” |
|---------|---------|------|
| **è³‡æ–™æ¯”å°** | Beyond Compare, DiffKit | è³‡æ–™å·®ç•°æ¯”å° |
| **è³‡æ–™ç”¢ç”Ÿ** | Faker, DbUnit | æ¸¬è©¦è³‡æ–™ç”¢ç”Ÿ |
| **æ•ˆèƒ½æ¸¬è©¦** | JMeter, Gatling | è½‰ç½®æ•ˆèƒ½æ¸¬è©¦ |
| **è³‡æ–™å“è³ª** | Great Expectations, Deequ | è³‡æ–™å“è³ªæª¢æ¸¬ |
| **SQL åˆ†æ** | SQL Developer, DBeaver | SQL é–‹ç™¼èˆ‡åˆ†æ |

#### 7.5.2 è‡ªè£½é©—è­‰å·¥å…·ç¯„ä¾‹

```java
/**
 * è³‡æ–™æ¯”å°å·¥å…·
 */
@Component
public class DataComparisonTool {
    
    @Autowired
    private JdbcTemplate sourceJdbc;
    
    @Autowired
    private JdbcTemplate targetJdbc;
    
    /**
     * æ¯”å°å…©å€‹æŸ¥è©¢çµæœ
     */
    public ComparisonResult compare(
            String sourceQuery, 
            String targetQuery,
            List<String> keyColumns,
            List<String> compareColumns) {
        
        ComparisonResult result = new ComparisonResult();
        
        // å–å¾—ä¾†æºè³‡æ–™
        Map<String, Map<String, Object>> sourceData = executeQuery(
            sourceJdbc, sourceQuery, keyColumns
        );
        
        // å–å¾—ç›®æ¨™è³‡æ–™
        Map<String, Map<String, Object>> targetData = executeQuery(
            targetJdbc, targetQuery, keyColumns
        );
        
        // æ‰¾å‡ºéºå¤±çš„ Key
        Set<String> missingKeys = new HashSet<>(sourceData.keySet());
        missingKeys.removeAll(targetData.keySet());
        result.setMissingKeys(missingKeys);
        
        // æ‰¾å‡ºå¤šé¤˜çš„ Key
        Set<String> extraKeys = new HashSet<>(targetData.keySet());
        extraKeys.removeAll(sourceData.keySet());
        result.setExtraKeys(extraKeys);
        
        // æ¯”å°æ¬„ä½å€¼
        List<FieldMismatch> mismatches = new ArrayList<>();
        for (String key : sourceData.keySet()) {
            if (targetData.containsKey(key)) {
                Map<String, Object> sourceRow = sourceData.get(key);
                Map<String, Object> targetRow = targetData.get(key);
                
                for (String col : compareColumns) {
                    Object sourceVal = sourceRow.get(col);
                    Object targetVal = targetRow.get(col);
                    
                    if (!Objects.equals(sourceVal, targetVal)) {
                        mismatches.add(new FieldMismatch(
                            key, col, sourceVal, targetVal
                        ));
                    }
                }
            }
        }
        result.setMismatches(mismatches);
        
        return result;
    }
    
    private Map<String, Map<String, Object>> executeQuery(
            JdbcTemplate jdbc, 
            String query, 
            List<String> keyColumns) {
        
        Map<String, Map<String, Object>> result = new LinkedHashMap<>();
        
        jdbc.query(query, rs -> {
            Map<String, Object> row = new HashMap<>();
            ResultSetMetaData meta = rs.getMetaData();
            
            for (int i = 1; i <= meta.getColumnCount(); i++) {
                row.put(meta.getColumnName(i), rs.getObject(i));
            }
            
            // çµ„åˆ Key
            String key = keyColumns.stream()
                .map(col -> String.valueOf(row.get(col)))
                .collect(Collectors.joining("|"));
            
            result.put(key, row);
        });
        
        return result;
    }
}
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - å·¥å…·é¸å‹æ‡‰è€ƒé‡åœ˜éšŠæŠ€è¡“èƒ½åŠ›èˆ‡ç¶­è­·æˆæœ¬
> - å„ªå…ˆé¸ç”¨åœ˜éšŠç†Ÿæ‚‰çš„å·¥å…·ï¼Œé™ä½å­¸ç¿’æ›²ç·š
> - å•†æ¥­å·¥å…·éœ€è©•ä¼°æˆæ¬Šæˆæœ¬èˆ‡é•·æœŸæ”¯æ´
> - è‡ªè£½å·¥å…·éœ€è€ƒé‡æ–‡ä»¶åŒ–èˆ‡äº¤æ¥å•é¡Œ

---

## ç¬¬ 8 ç« ï¼šæ¸¬è©¦ç­–ç•¥èˆ‡ä¸Šç·šå‰æª¢æ ¸

### 8.1 Unit Testï¼ˆè½‰æ›é‚è¼¯ï¼‰

#### 8.1.1 æ¸¬è©¦ç¯„åœ

| æ¸¬è©¦é …ç›® | èªªæ˜ | é‡è¦æ€§ |
|---------|------|--------|
| **æ ¼å¼è½‰æ›** | æ—¥æœŸã€æ•¸å­—æ ¼å¼è½‰æ›æ­£ç¢ºæ€§ | ğŸ”´ é«˜ |
| **ä»£ç¢¼å°æ‡‰** | ä»£ç¢¼ Mapping æ­£ç¢ºæ€§ | ğŸ”´ é«˜ |
| **ç©ºå€¼è™•ç†** | Null å€¼è™•ç†é‚è¼¯ | ğŸŸ  ä¸­ |
| **é‚Šç•Œæ¢ä»¶** | æ¥µå€¼ã€ç‰¹æ®Šå­—å…ƒè™•ç† | ğŸŸ  ä¸­ |
| **æ¥­å‹™è¦å‰‡** | è¤‡é›œæ¥­å‹™é‚è¼¯ | ğŸ”´ é«˜ |

#### 8.1.2 Unit Test ç¯„ä¾‹

```java
@ExtendWith(MockitoExtension.class)
class CustomerTransformProcessorTest {
    
    @Mock
    private CodeMappingService codeMappingService;
    
    @InjectMocks
    private CustomerTransformProcessor processor;
    
    @BeforeEach
    void setUp() {
        // è¨­å®š Mock è¡Œç‚º
        when(codeMappingService.map("CUST_TYPE", "1"))
            .thenReturn("INDIVIDUAL");
        when(codeMappingService.map("CUST_TYPE", "2"))
            .thenReturn("CORPORATE");
        when(codeMappingService.map("CUST_TYPE", "X"))
            .thenReturn("UNMAPPED_X");
    }
    
    @Test
    @DisplayName("æ­£å¸¸è³‡æ–™è½‰æ›")
    void testNormalTransform() throws Exception {
        // Given
        OldCustomer source = new OldCustomer();
        source.setCustId("C0001     ");  // å«ç©ºç™½
        source.setCustName("  ç‹å°æ˜  ");
        source.setCustType("1");
        source.setCreateDt("20240101");
        
        // When
        NewCustomer result = processor.process(source);
        
        // Then
        assertThat(result.getCustomerNo()).isEqualTo("C0001");
        assertThat(result.getName()).isEqualTo("ç‹å°æ˜");
        assertThat(result.getCustomerType()).isEqualTo("INDIVIDUAL");
        assertThat(result.getCreatedAt())
            .isEqualTo(LocalDateTime.of(2024, 1, 1, 0, 0));
    }
    
    @Test
    @DisplayName("æ—¥æœŸæ ¼å¼ç•°å¸¸è™•ç†")
    void testInvalidDateFormat() {
        // Given
        OldCustomer source = new OldCustomer();
        source.setCustId("C0002");
        source.setCustName("æå¤§è¯");
        source.setCustType("1");
        source.setCreateDt("2024/01/01");  // éŒ¯èª¤æ ¼å¼
        
        // When & Then
        assertThatThrownBy(() -> processor.process(source))
            .isInstanceOf(DateTimeParseException.class);
    }
    
    @Test
    @DisplayName("ç©ºå€¼è™•ç†")
    void testNullValues() throws Exception {
        // Given
        OldCustomer source = new OldCustomer();
        source.setCustId("C0003");
        source.setCustName(null);
        source.setCustType("2");
        source.setCreateDt("");
        
        // When
        NewCustomer result = processor.process(source);
        
        // Then
        assertThat(result.getCustomerNo()).isEqualTo("C0003");
        assertThat(result.getName()).isNull();
        assertThat(result.getCustomerType()).isEqualTo("CORPORATE");
        assertThat(result.getCreatedAt()).isNull();
    }
    
    @Test
    @DisplayName("æœªå®šç¾©ä»£ç¢¼è™•ç†")
    void testUnmappedCode() throws Exception {
        // Given
        OldCustomer source = new OldCustomer();
        source.setCustId("C0004");
        source.setCustName("å¼µä¸‰");
        source.setCustType("X");  // æœªå®šç¾©ä»£ç¢¼
        source.setCreateDt("20240101");
        
        // When
        NewCustomer result = processor.process(source);
        
        // Then
        assertThat(result.getCustomerType()).isEqualTo("UNMAPPED_X");
    }
    
    @ParameterizedTest
    @DisplayName("å„ç¨®æ—¥æœŸæ ¼å¼æ¸¬è©¦")
    @CsvSource({
        "20240101, 2024-01-01",
        "20241231, 2024-12-31",
        "20200229, 2020-02-29"  // é–å¹´
    })
    void testDateFormats(String input, String expected) throws Exception {
        OldCustomer source = new OldCustomer();
        source.setCustId("C0005");
        source.setCustName("Test");
        source.setCustType("1");
        source.setCreateDt(input);
        
        NewCustomer result = processor.process(source);
        
        assertThat(result.getCreatedAt().toLocalDate())
            .isEqualTo(LocalDate.parse(expected));
    }
}
```

### 8.2 Integration Testï¼ˆæµç¨‹é©—è­‰ï¼‰

#### 8.2.1 æ•´åˆæ¸¬è©¦ç¯„åœ

```mermaid
flowchart LR
    subgraph æ•´åˆæ¸¬è©¦ç¯„åœ
        A[Source DB] --> B[Extract]
        B --> C[Transform]
        C --> D[Load]
        D --> E[Target DB]
        
        F[Error Handling]
        G[Checkpoint]
        H[Validation]
    end
    
    B --> F
    C --> F
    D --> F
    
    B --> G
    C --> G
    D --> G
    
    E --> H
```

#### 8.2.2 æ•´åˆæ¸¬è©¦ç¨‹å¼

```java
@SpringBootTest
@Testcontainers
@ActiveProfiles("test")
class CustomerMigrationIntegrationTest {
    
    @Container
    static OracleContainer sourceDb = new OracleContainer("oracle:19c")
        .withInitScript("sql/source-init.sql");
    
    @Container
    static PostgreSQLContainer targetDb = new PostgreSQLContainer("postgres:15")
        .withInitScript("sql/target-init.sql");
    
    @Autowired
    private JobLauncherTestUtils jobLauncherTestUtils;
    
    @Autowired
    private JdbcTemplate targetJdbc;
    
    @Test
    @DisplayName("å®Œæ•´è½‰ç½®æµç¨‹æ¸¬è©¦")
    void testFullMigrationFlow() throws Exception {
        // Given: æº–å‚™æ¸¬è©¦è³‡æ–™
        setupTestData();
        
        // When: åŸ·è¡Œè½‰ç½® Job
        JobParameters params = new JobParametersBuilder()
            .addString("batchId", "TEST_BATCH_001")
            .addLong("time", System.currentTimeMillis())
            .toJobParameters();
        
        JobExecution execution = jobLauncherTestUtils.launchJob(params);
        
        // Then: é©—è­‰çµæœ
        assertThat(execution.getStatus()).isEqualTo(BatchStatus.COMPLETED);
        
        // é©—è­‰ç­†æ•¸
        Integer targetCount = targetJdbc.queryForObject(
            "SELECT COUNT(*) FROM new_customer WHERE migration_batch_id = ?",
            Integer.class, "TEST_BATCH_001"
        );
        assertThat(targetCount).isEqualTo(100);
        
        // é©—è­‰é‡‘é¡
        BigDecimal totalBalance = targetJdbc.queryForObject(
            "SELECT SUM(balance) FROM new_account WHERE migration_batch_id = ?",
            BigDecimal.class, "TEST_BATCH_001"
        );
        assertThat(totalBalance).isEqualByComparingTo(new BigDecimal("1234567.89"));
    }
    
    @Test
    @DisplayName("éŒ¯èª¤è³‡æ–™è™•ç†æ¸¬è©¦")
    void testErrorHandling() throws Exception {
        // Given: æ’å…¥ç•°å¸¸è³‡æ–™
        insertInvalidData();
        
        // When
        JobParameters params = new JobParametersBuilder()
            .addString("batchId", "TEST_BATCH_002")
            .addLong("time", System.currentTimeMillis())
            .toJobParameters();
        
        JobExecution execution = jobLauncherTestUtils.launchJob(params);
        
        // Then: ç¢ºèª Job å®Œæˆï¼ˆéŒ¯èª¤è¢«è·³éï¼‰
        assertThat(execution.getStatus()).isEqualTo(BatchStatus.COMPLETED);
        
        // ç¢ºèªéŒ¯èª¤è¢«è¨˜éŒ„
        Integer errorCount = targetJdbc.queryForObject(
            "SELECT COUNT(*) FROM migration_error_log WHERE batch_id = ?",
            Integer.class, "TEST_BATCH_002"
        );
        assertThat(errorCount).isGreaterThan(0);
    }
    
    @Test
    @DisplayName("Checkpoint æ¢å¾©æ¸¬è©¦")
    void testCheckpointRecovery() throws Exception {
        // Given: åŸ·è¡Œåˆ°ä¸€åŠä¸­æ–·
        JobParameters params = new JobParametersBuilder()
            .addString("batchId", "TEST_BATCH_003")
            .addLong("time", System.currentTimeMillis())
            .toJobParameters();
        
        // æ¨¡æ“¬ä¸­æ–·
        simulateInterruption();
        
        // When: é‡æ–°å•Ÿå‹•
        JobExecution execution = jobLauncherTestUtils.launchJob(params);
        
        // Then: ç¢ºèªå¾ Checkpoint æ¢å¾©
        assertThat(execution.getStatus()).isEqualTo(BatchStatus.COMPLETED);
        
        // ç¢ºèªæ²’æœ‰é‡è¤‡è³‡æ–™
        Integer duplicateCount = targetJdbc.queryForObject(
            """
            SELECT COUNT(*) FROM (
                SELECT customer_no, COUNT(*) AS cnt
                FROM new_customer
                WHERE migration_batch_id = ?
                GROUP BY customer_no
                HAVING COUNT(*) > 1
            ) t
            """,
            Integer.class, "TEST_BATCH_003"
        );
        assertThat(duplicateCount).isEqualTo(0);
    }
}
```

### 8.3 UAT é©—è­‰æ¨¡å¼

#### 8.3.1 UAT é©—è­‰æµç¨‹

```mermaid
flowchart TD
    A[UAT é–‹å§‹] --> B[ç’°å¢ƒæº–å‚™]
    B --> C[æ¸¬è©¦è³‡æ–™æº–å‚™]
    C --> D[åŸ·è¡Œè½‰ç½®]
    D --> E[æŠ€è¡“é©—è­‰]
    E --> F{æŠ€è¡“é€šé?}
    F -->|å¦| G[ä¿®å¾©å•é¡Œ]
    G --> D
    F -->|æ˜¯| H[æ¥­å‹™é©—è­‰]
    H --> I[æŠ½æ¨£æª¢æ ¸]
    I --> J[æ¥­å‹™ç¢ºèª]
    J --> K{æ¥­å‹™é€šé?}
    K -->|å¦| L[è¨˜éŒ„å•é¡Œ]
    L --> G
    K -->|æ˜¯| M[UAT ç°½æ ¸]
    M --> N[UAT å®Œæˆ]
```

#### 8.3.2 UAT æª¢æ ¸è¡¨

```markdown
## UAT é©—è­‰æª¢æ ¸è¡¨

### åŸºæœ¬è³‡è¨Š
- å°ˆæ¡ˆåç¨±ï¼š_______________
- è½‰ç½®æ‰¹æ¬¡ï¼š_______________
- é©—è­‰æ—¥æœŸï¼š_______________
- é©—è­‰äººå“¡ï¼š_______________

### ä¸€ã€æŠ€è¡“é©—è­‰ â˜‘

| é …ç›® | é æœŸå€¼ | å¯¦éš›å€¼ | çµæœ | å‚™è¨» |
|------|--------|--------|------|------|
| ä¾†æºç­†æ•¸ | 1,000,000 | | â–¡ Pass â–¡ Fail | |
| ç›®æ¨™ç­†æ•¸ | 1,000,000 | | â–¡ Pass â–¡ Fail | |
| éŒ¯èª¤ç­†æ•¸ | < 100 | | â–¡ Pass â–¡ Fail | |
| é‡‘é¡ç¸½å’Œ | 123,456,789.00 | | â–¡ Pass â–¡ Fail | |
| åŸ·è¡Œæ™‚é–“ | < 2 å°æ™‚ | | â–¡ Pass â–¡ Fail | |

### äºŒã€æ¥­å‹™é©—è­‰ â˜‘

| é©—è­‰æƒ…å¢ƒ | æ¸¬è©¦æ¡ˆä¾‹ | é æœŸçµæœ | å¯¦éš›çµæœ | çµæœ |
|---------|---------|---------|---------|------|
| å®¢æˆ¶æŸ¥è©¢ | æŸ¥è©¢å®¢æˆ¶ C001 | é¡¯ç¤ºå®Œæ•´è³‡æ–™ | | â–¡ Pass â–¡ Fail |
| å¸³æˆ¶é¤˜é¡ | å¸³æˆ¶ A001 é¤˜é¡ | 50,000.00 | | â–¡ Pass â–¡ Fail |
| äº¤æ˜“æ˜ç´° | è¿‘ 3 å€‹æœˆäº¤æ˜“ | é¡¯ç¤º 15 ç­† | | â–¡ Pass â–¡ Fail |

### ä¸‰ã€æŠ½æ¨£é©—è­‰ â˜‘

| åºè™Ÿ | å®¢æˆ¶ç·¨è™Ÿ | é©—è­‰é …ç›® | ä¾†æºå€¼ | ç›®æ¨™å€¼ | çµæœ |
|------|---------|---------|--------|--------|------|
| 1 | | å§“å | | | â–¡ Match |
| 2 | | é¤˜é¡ | | | â–¡ Match |
| 3 | | ç‹€æ…‹ | | | â–¡ Match |

### å››ã€ç°½æ ¸

| è§’è‰² | å§“å | ç°½å | æ—¥æœŸ |
|------|------|------|------|
| æŠ€è¡“è² è²¬äºº | | | |
| æ¥­å‹™è² è²¬äºº | | | |
| å°ˆæ¡ˆç¶“ç† | | | |
```

### 8.4 ä¸Šç·šå‰ Checklist

#### 8.4.1 å®Œæ•´ Checklist

```markdown
## è³‡æ–™è½‰ç½®ä¸Šç·šå‰æª¢æ ¸æ¸…å–®

### ğŸ“‹ T-7ï¼ˆä¸Šç·šå‰ 7 å¤©ï¼‰

#### ç’°å¢ƒç¢ºèª
- [ ] æ­£å¼ç’°å¢ƒè³‡æ–™åº«é€£ç·šæ¸¬è©¦é€šé
- [ ] æ­£å¼ç’°å¢ƒå¸³è™Ÿæ¬Šé™ç¢ºèª
- [ ] å‚™ä»½æ©Ÿåˆ¶ç¢ºèªå¯é‹ä½œ
- [ ] ç›£æ§å‘Šè­¦è¨­å®šå®Œæˆ

#### ç¨‹å¼ç¢ºèª
- [ ] è½‰ç½®ç¨‹å¼å·²éƒ¨ç½²è‡³æ­£å¼ç’°å¢ƒ
- [ ] ç¨‹å¼ç‰ˆæœ¬èˆ‡ UAT ç‰ˆæœ¬ä¸€è‡´
- [ ] è¨­å®šæª”å·²æ›´æ–°ç‚ºæ­£å¼ç’°å¢ƒåƒæ•¸
- [ ] Log è¼¸å‡ºè·¯å¾‘ç¢ºèª

#### æ–‡ä»¶ç¢ºèª
- [ ] Mapping æ–‡ä»¶æœ€çµ‚ç‰ˆå·²ç¢ºèª
- [ ] æ“ä½œæ‰‹å†Šå·²å®Œæˆ
- [ ] Rollback æ‰‹å†Šå·²å®Œæˆ
- [ ] ç·Šæ€¥è¯çµ¡æ¸…å–®å·²æ›´æ–°

### ğŸ“‹ T-3ï¼ˆä¸Šç·šå‰ 3 å¤©ï¼‰

#### è³‡æ–™ç¢ºèª
- [ ] ä¾†æºè³‡æ–™ç­†æ•¸ç¢ºèª
- [ ] ä¾†æºè³‡æ–™å“è³ªæª¢æ¸¬é€šé
- [ ] ä»£ç¢¼å°æ‡‰è¡¨å·²è¼‰å…¥
- [ ] æ¸¬è©¦è³‡æ–™å·²æ¸…é™¤

#### æ¼”ç·´ç¢ºèª
- [ ] æ­£å¼ç’°å¢ƒæ¼”ç·´å·²å®Œæˆ
- [ ] æ¼”ç·´æ™‚é–“ç¬¦åˆé æœŸ
- [ ] æ¼”ç·´é©—è­‰å ±å‘Šå·²ç”¢å‡º
- [ ] æ¼”ç·´å•é¡Œå·²ä¿®å¾©

### ğŸ“‹ T-1ï¼ˆä¸Šç·šå‰ 1 å¤©ï¼‰

#### æœ€çµ‚ç¢ºèª
- [ ] ä¸Šç·šè¨ˆç•«å·²ç™¼é€ç›¸é—œäººå“¡
- [ ] ç¶­è­·å…¬å‘Šå·²ç™¼å¸ƒ
- [ ] ç›¸é—œç³»çµ±å·²é€šçŸ¥
- [ ] å€¼ç­äººå“¡å·²ç¢ºèª

#### å‚™ä»½ç¢ºèª
- [ ] ä¾†æºè³‡æ–™å‚™ä»½å®Œæˆ
- [ ] ç›®æ¨™è³‡æ–™åº«å‚™ä»½å®Œæˆ
- [ ] å‚™ä»½å¯é‚„åŸå·²é©—è­‰

### ğŸ“‹ D-Dayï¼ˆä¸Šç·šç•¶å¤©ï¼‰

#### ä¸Šç·šå‰
- [ ] åœæ­¢ç›¸é—œæ‡‰ç”¨æœå‹™
- [ ] ç¢ºèªç„¡é€²è¡Œä¸­äº¤æ˜“
- [ ] å»ºç«‹æœ€æ–°å‚™ä»½é»
- [ ] è¨˜éŒ„é–‹å§‹æ™‚é–“

#### ä¸Šç·šä¸­
- [ ] åŸ·è¡Œè³‡æ–™æŠ½å– â†’ å®Œæˆæ™‚é–“ï¼š______
- [ ] åŸ·è¡Œè³‡æ–™è½‰æ› â†’ å®Œæˆæ™‚é–“ï¼š______
- [ ] åŸ·è¡Œè³‡æ–™è¼‰å…¥ â†’ å®Œæˆæ™‚é–“ï¼š______
- [ ] åŸ·è¡Œç­†æ•¸é©—è­‰ â†’ çµæœï¼š______
- [ ] åŸ·è¡Œé‡‘é¡é©—è­‰ â†’ çµæœï¼š______

#### ä¸Šç·šå¾Œ
- [ ] å•Ÿå‹•ç›¸é—œæ‡‰ç”¨æœå‹™
- [ ] åŸ·è¡ŒåŠŸèƒ½æ¸¬è©¦
- [ ] æ¥­å‹™ç¢ºèªé€šé
- [ ] ç›£æ§è§€å¯Ÿæ­£å¸¸

### ğŸ“‹ D+1ï¼ˆä¸Šç·šå¾Œ 1 å¤©ï¼‰

#### ç¢ºèªäº‹é …
- [ ] ç„¡ç•°å¸¸éŒ¯èª¤å›å ±
- [ ] ç›£æ§æŒ‡æ¨™æ­£å¸¸
- [ ] æ¥­å‹™é‹ä½œæ­£å¸¸
- [ ] ä¸Šç·šå ±å‘Šå·²ç”¢å‡º

### âœ… æœ€çµ‚ç°½æ ¸

| æª¢æ ¸é …ç›® | ç°½æ ¸äºº | ç°½æ ¸æ™‚é–“ |
|---------|--------|---------|
| æŠ€è¡“æª¢æ ¸å®Œæˆ | | |
| æ¥­å‹™ç¢ºèªå®Œæˆ | | |
| ä¸Šç·šè¨±å¯ | | |
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - Checklist å¿…é ˆé€é …ç¢ºèªï¼Œä¸å¯è·³é
> - æ¯å€‹æª¢æ ¸é …ç›®éƒ½æ‡‰æœ‰æ˜ç¢ºçš„å®Œæˆæ¨™æº–
> - å»ºè­°ä½¿ç”¨é›»å­åŒ–ç®¡ç†ï¼Œä¿ç•™ç°½æ ¸è¨˜éŒ„
> - ä¸Šç·šå¾ŒæŒçºŒç›£æ§è‡³å°‘ 3 å¤©

---

## ç¬¬ 9 ç« ï¼šå¯¦å‹™ç¶“é©—èˆ‡æœ€ä½³å¯¦è¸

### 9.1 å¸¸è¦‹è¸©é›·æ¡ˆä¾‹

#### 9.1.1 æ¡ˆä¾‹ä¸€ï¼šå­—å…ƒç·¨ç¢¼å•é¡Œ

**èƒŒæ™¯**ï¼šæŸéŠ€è¡Œå°‡èˆŠç³»çµ±ï¼ˆBig5 ç·¨ç¢¼ï¼‰è³‡æ–™è½‰ç½®åˆ°æ–°ç³»çµ±ï¼ˆUTF-8ï¼‰

**å•é¡Œ**ï¼š
- éƒ¨åˆ†ä¸­æ–‡å§“åè½‰ç½®å¾Œè®Šæˆäº‚ç¢¼
- å½±éŸ¿ç´„ 5,000 ç­†å®¢æˆ¶è³‡æ–™

**åŸå› **ï¼š
- èˆŠç³»çµ±ä½¿ç”¨ Big5 + ç§æœ‰ç¢¼å€
- è½‰æ›æ™‚æœªè™•ç†ç§æœ‰å­—å…ƒ

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```java
// å»ºç«‹è‡ªè¨‚å­—å…ƒæ˜ å°„è¡¨
Map<Character, String> customMapping = new HashMap<>();
customMapping.put('\uE000', "å ƒ");  // ç§æœ‰ç¢¼å€å­—å…ƒ
customMapping.put('\uE001', "ç‡Š");

public String convertEncoding(String input) {
    StringBuilder result = new StringBuilder();
    for (char c : input.toCharArray()) {
        if (customMapping.containsKey(c)) {
            result.append(customMapping.get(c));
        } else {
            result.append(c);
        }
    }
    return result.toString();
}
```

**æ•™è¨“**ï¼š
- âœ… è½‰ç½®å‰å¿…é ˆå®Œæ•´åˆ†æå­—å…ƒé›†
- âœ… å»ºç«‹ç§æœ‰å­—å…ƒå°æ‡‰è¡¨
- âœ… åŸ·è¡Œå­—å…ƒè½‰æ›å‰å¾Œæ¯”å°é©—è­‰

#### 9.1.2 æ¡ˆä¾‹äºŒï¼šæ—¥æœŸè™•ç†å•é¡Œ

**èƒŒæ™¯**ï¼šèˆŠç³»çµ±æ—¥æœŸæ¬„ä½å­˜åœ¨å¤šç¨®æ ¼å¼

**å•é¡Œ**ï¼š
```
æ­£å¸¸æ ¼å¼ï¼š20240101
ç•°å¸¸æ ¼å¼ï¼š2024/1/1ã€24-01-01ã€00000000ã€99999999
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```java
public LocalDate parseDateFlexible(String dateStr) {
    if (dateStr == null || dateStr.trim().isEmpty()) {
        return null;
    }
    
    // è™•ç†ç‰¹æ®Šå€¼
    if ("00000000".equals(dateStr) || "99999999".equals(dateStr)) {
        return null;
    }
    
    // å˜—è©¦å¤šç¨®æ ¼å¼
    List<DateTimeFormatter> formatters = Arrays.asList(
        DateTimeFormatter.ofPattern("yyyyMMdd"),
        DateTimeFormatter.ofPattern("yyyy/M/d"),
        DateTimeFormatter.ofPattern("yy-MM-dd"),
        DateTimeFormatter.ofPattern("yyyy-MM-dd")
    );
    
    for (DateTimeFormatter formatter : formatters) {
        try {
            return LocalDate.parse(dateStr.trim(), formatter);
        } catch (DateTimeParseException e) {
            // ç¹¼çºŒå˜—è©¦ä¸‹ä¸€å€‹æ ¼å¼
        }
    }
    
    // å…¨éƒ¨å¤±æ•—ï¼Œè¨˜éŒ„éŒ¯èª¤
    throw new DataException("ç„¡æ³•è§£ææ—¥æœŸ: " + dateStr);
}
```

#### 9.1.3 æ¡ˆä¾‹ä¸‰ï¼šæ•ˆèƒ½å•é¡Œ

**èƒŒæ™¯**ï¼š5,000 è¬ç­†äº¤æ˜“è³‡æ–™è½‰ç½®ï¼Œé ä¼° 4 å°æ™‚ï¼Œå¯¦éš›åŸ·è¡Œ 16 å°æ™‚

**åŸå› åˆ†æ**ï¼š
1. å–®åŸ·è¡Œç·’è™•ç†
2. æ¯ç­†è³‡æ–™éƒ½åš SELECT æª¢æŸ¥æ˜¯å¦å­˜åœ¨
3. æœªä½¿ç”¨æ‰¹æ¬¡å¯«å…¥

**å„ªåŒ–æ–¹æ¡ˆ**ï¼š

```java
// å„ªåŒ–å‰ï¼šå–®ç­†è™•ç†
for (Transaction txn : transactions) {
    if (!exists(txn.getId())) {
        insert(txn);
    }
}

// å„ªåŒ–å¾Œï¼šæ‰¹æ¬¡è™•ç† + ä¸¦è¡Œ
@Async
public CompletableFuture<Integer> processBatch(List<Transaction> batch) {
    // æ‰¹æ¬¡æª¢æŸ¥å­˜åœ¨æ€§
    Set<String> existingIds = findExistingIds(
        batch.stream().map(Transaction::getId).collect(toList())
    );
    
    // éæ¿¾å‡ºéœ€è¦æ–°å¢çš„
    List<Transaction> toInsert = batch.stream()
        .filter(t -> !existingIds.contains(t.getId()))
        .collect(toList());
    
    // æ‰¹æ¬¡å¯«å…¥
    batchInsert(toInsert);
    
    return CompletableFuture.completedFuture(toInsert.size());
}
```

**æ•ˆèƒ½å°æ¯”**ï¼š

| é …ç›® | å„ªåŒ–å‰ | å„ªåŒ–å¾Œ |
|------|--------|--------|
| åŸ·è¡Œæ™‚é–“ | 16 å°æ™‚ | 2.5 å°æ™‚ |
| CPU ä½¿ç”¨ç‡ | 15% | 70% |
| æ¯ç§’è™•ç†ç­†æ•¸ | 850 | 5,500 |

### 9.2 èˆ‡æ¥­å‹™å–®ä½çš„è³‡æ–™é©—è­‰åˆä½œæ–¹å¼

#### 9.2.1 åˆä½œæ¨¡å¼

```mermaid
flowchart LR
    subgraph IT åœ˜éšŠ
        A[æº–å‚™é©—è­‰å ±è¡¨]
        B[æä¾›æŸ¥è©¢å·¥å…·]
        C[ä¿®å¾©è³‡æ–™å•é¡Œ]
    end
    
    subgraph æ¥­å‹™å–®ä½
        D[æä¾›é©—è­‰æ¡ˆä¾‹]
        E[åŸ·è¡Œæ¥­å‹™é©—è­‰]
        F[ç¢ºèªé©—è­‰çµæœ]
    end
    
    A --> E
    B --> E
    D --> A
    E --> F
    F -->|æœ‰å•é¡Œ| C
    C --> A
    F -->|é€šé| G[ç°½æ ¸]
```

#### 9.2.2 æºé€šæ³¨æ„äº‹é …

| é …ç›® | å»ºè­°åšæ³• | é¿å…åšæ³• |
|------|---------|---------|
| **é©—è­‰ç¯„åœ** | é›™æ–¹äº‹å…ˆç¢ºèª | å–®æ–¹é¢æ±ºå®š |
| **é©—è­‰æ™‚ç¨‹** | é ç•™å……è¶³æ™‚é–“ | å£“ç¸®æ¥­å‹™é©—è­‰æ™‚é–“ |
| **å•é¡Œå›å ±** | çµ±ä¸€ç®¡é“ï¼ˆå¦‚ Issue Trackerï¼‰ | å£é ­å›å ± |
| **è²¬ä»»åŠƒåˆ†** | æ˜ç¢ºæ–‡ä»¶åŒ– | æ¨¡ç³Šè²¬ä»» |

#### 9.2.3 æ¥­å‹™é©—è­‰å·¥å…·

```java
/**
 * æ¥­å‹™é©—è­‰ç”¨æŸ¥è©¢ä»‹é¢
 */
@RestController
@RequestMapping("/api/migration/verify")
public class VerificationController {
    
    @Autowired
    private VerificationService verifyService;
    
    /**
     * å–®ç­†è³‡æ–™æ¯”å°
     */
    @GetMapping("/customer/{custId}")
    public CustomerCompareResult compareCustomer(@PathVariable String custId) {
        return verifyService.compareCustomer(custId);
    }
    
    /**
     * æŠ½æ¨£é©—è­‰å ±è¡¨
     */
    @GetMapping("/sample-report")
    public SampleReport getSampleReport(
            @RequestParam String batchId,
            @RequestParam(defaultValue = "100") int sampleSize) {
        return verifyService.generateSampleReport(batchId, sampleSize);
    }
    
    /**
     * åŒ¯å‡ºé©—è­‰è³‡æ–™ï¼ˆExcelï¼‰
     */
    @GetMapping("/export")
    public ResponseEntity<byte[]> exportVerificationData(
            @RequestParam String batchId) {
        byte[] excelData = verifyService.exportToExcel(batchId);
        
        return ResponseEntity.ok()
            .header(HttpHeaders.CONTENT_DISPOSITION, 
                "attachment; filename=verification_" + batchId + ".xlsx")
            .contentType(MediaType.APPLICATION_OCTET_STREAM)
            .body(excelData);
    }
}
```

### 9.3 æ–‡ä»¶åŒ–ã€ç¨½æ ¸èˆ‡å¯è¿½æº¯æ€§è¨­è¨ˆ

#### 9.3.1 æ–‡ä»¶æ¸…å–®

| æ–‡ä»¶é¡å‹ | å…§å®¹ | ä¿å­˜æœŸé™ |
|---------|------|---------|
| **Mapping æ–‡ä»¶** | æ¬„ä½å°æ‡‰è¦å‰‡ã€è½‰æ›é‚è¼¯ | æ°¸ä¹… |
| **è½‰ç½®è¨ˆç•«** | æ™‚ç¨‹ã€ç¯„åœã€ç­–ç•¥ | 5 å¹´ |
| **é©—è­‰å ±å‘Š** | é©—è­‰çµæœã€ç°½æ ¸è¨˜éŒ„ | 10 å¹´ |
| **éŒ¯èª¤è™•ç†è¨˜éŒ„** | ç•°å¸¸è³‡æ–™è™•ç†æ–¹å¼ | 10 å¹´ |
| **è®Šæ›´è¨˜éŒ„** | è½‰ç½®éç¨‹ä¸­çš„è®Šæ›´ | 5 å¹´ |

#### 9.3.2 ç¨½æ ¸è»Œè·¡è¨­è¨ˆ

```sql
-- è½‰ç½®ç¨½æ ¸è¡¨
CREATE TABLE migration_audit_log (
    audit_id        BIGINT AUTO_INCREMENT PRIMARY KEY,
    batch_id        VARCHAR(20) NOT NULL,
    action_type     VARCHAR(50) NOT NULL,  -- EXTRACT, TRANSFORM, LOAD, VERIFY
    action_detail   TEXT,
    source_table    VARCHAR(100),
    target_table    VARCHAR(100),
    affected_rows   BIGINT,
    executed_by     VARCHAR(50),
    executed_at     TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    client_ip       VARCHAR(45),
    checksum        VARCHAR(64),  -- è³‡æ–™æ ¡é©—ç¢¼
    
    INDEX idx_batch (batch_id),
    INDEX idx_time (executed_at)
);

-- è¨˜éŒ„ç¨½æ ¸æ—¥èªŒ
INSERT INTO migration_audit_log 
    (batch_id, action_type, action_detail, source_table, target_table, 
     affected_rows, executed_by, checksum)
VALUES 
    ('BATCH_001', 'LOAD', 'Customer migration completed', 
     'old_customer', 'new_customer', 1234567, 'system', 
     SHA2(CONCAT('BATCH_001', '1234567', NOW()), 256));
```

#### 9.3.3 è³‡æ–™è¡€ç·£è¿½è¹¤

```java
/**
 * è³‡æ–™è¡€ç·£è¨˜éŒ„
 */
@Entity
@Table(name = "data_lineage")
public class DataLineage {
    
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    private String batchId;
    
    // ä¾†æºè³‡è¨Š
    private String sourceSystem;
    private String sourceTable;
    private String sourceKey;
    private String sourceChecksum;
    
    // ç›®æ¨™è³‡è¨Š
    private String targetSystem;
    private String targetTable;
    private String targetKey;
    private String targetChecksum;
    
    // è½‰æ›è³‡è¨Š
    private String transformRules;  // JSON æ ¼å¼
    private LocalDateTime transformTime;
    
    // è¿½è¹¤è³‡è¨Š
    private String createdBy;
    private LocalDateTime createdAt;
}

/**
 * è¡€ç·£æŸ¥è©¢æœå‹™
 */
@Service
public class DataLineageService {
    
    /**
     * è¿½è¹¤è³‡æ–™ä¾†æº
     */
    public LineageTrace traceBack(String targetTable, String targetKey) {
        List<DataLineage> lineage = lineageRepo
            .findByTargetTableAndTargetKey(targetTable, targetKey);
        
        LineageTrace trace = new LineageTrace();
        trace.setTargetTable(targetTable);
        trace.setTargetKey(targetKey);
        
        for (DataLineage l : lineage) {
            trace.addSource(new SourceInfo(
                l.getSourceSystem(),
                l.getSourceTable(),
                l.getSourceKey(),
                l.getTransformRules()
            ));
        }
        
        return trace;
    }
}
```

### 9.4 é‡‘èèˆ‡æ ¸å¿ƒç³»çµ±å¸¸è¦‹åˆè¦è€ƒé‡

#### 9.4.1 åˆè¦è¦æ±‚

| æ³•è¦/æ¨™æº– | è¦æ±‚ | è½‰ç½®å½±éŸ¿ |
|----------|------|---------|
| **å€‹è³‡æ³•** | å€‹äººè³‡æ–™ä¿è­· | è³‡æ–™è„«æ•ã€å‚³è¼¸åŠ å¯† |
| **é‡‘èæª¢æŸ¥** | è³‡æ–™å®Œæ•´æ€§ã€ç¨½æ ¸è»Œè·¡ | å®Œæ•´è¨˜éŒ„ã€é•·æœŸä¿å­˜ |
| **ISO 27001** | è³‡è¨Šå®‰å…¨ç®¡ç† | å­˜å–æ§åˆ¶ã€åŠ å¯† |
| **SOX** | è²¡å‹™è³‡æ–™æ­£ç¢ºæ€§ | é‡‘é¡é©—è­‰ã€ç°½æ ¸æµç¨‹ |

#### 9.4.2 æ•æ„Ÿè³‡æ–™è™•ç†

```java
/**
 * æ•æ„Ÿè³‡æ–™è™•ç†
 */
@Service
public class SensitiveDataHandler {
    
    /**
     * èº«åˆ†è­‰å­—è™Ÿè„«æ•
     */
    public String maskIdNumber(String idNo) {
        if (idNo == null || idNo.length() < 10) {
            return idNo;
        }
        // A123456789 â†’ A12****789
        return idNo.substring(0, 3) + "****" + idNo.substring(7);
    }
    
    /**
     * åŠ å¯†å„²å­˜
     */
    public String encrypt(String plainText) {
        // ä½¿ç”¨ AES-256 åŠ å¯†
        return aesEncryptor.encrypt(plainText);
    }
    
    /**
     * è½‰ç½®æ™‚çš„æ•æ„Ÿè³‡æ–™è™•ç†
     */
    public NewCustomer processSensitiveData(OldCustomer source, boolean isMasked) {
        NewCustomer target = new NewCustomer();
        
        // ä¸€èˆ¬æ¬„ä½ç›´æ¥è½‰
        target.setCustomerNo(source.getCustId());
        target.setName(source.getCustName());
        
        // æ•æ„Ÿæ¬„ä½è™•ç†
        if (isMasked) {
            target.setIdNumber(maskIdNumber(source.getIdNo()));
        } else {
            target.setIdNumberEncrypted(encrypt(source.getIdNo()));
        }
        
        return target;
    }
}
```

#### 9.4.3 åˆè¦æª¢æŸ¥æ¸…å–®

```markdown
## è³‡æ–™è½‰ç½®åˆè¦æª¢æŸ¥æ¸…å–®

### å€‹äººè³‡æ–™ä¿è­·
- [ ] æ•æ„Ÿæ¬„ä½å·²è­˜åˆ¥ä¸¦æ¨™è¨»
- [ ] å‚³è¼¸éç¨‹å·²åŠ å¯†ï¼ˆTLS 1.2+ï¼‰
- [ ] éœæ…‹è³‡æ–™å·²åŠ å¯†æˆ–è„«æ•
- [ ] å­˜å–æ¬Šé™å·²è¨­å®šæœ€å°æ¬Šé™åŸå‰‡
- [ ] å€‹è³‡å­˜å–å·²è¨˜éŒ„ç¨½æ ¸æ—¥èªŒ

### è³‡æ–™å®Œæ•´æ€§
- [ ] æ‰€æœ‰è³‡æ–™éƒ½æœ‰é©—è­‰æ©Ÿåˆ¶
- [ ] é‡‘é¡é¡è³‡æ–™æ¡ç”¨ Decimal é¿å…ç²¾åº¦å•é¡Œ
- [ ] é—œéµæ¬„ä½è¨­å®š NOT NULL ç´„æŸ
- [ ] åƒç…§å®Œæ•´æ€§å·²é©—è­‰

### ç¨½æ ¸è¦æ±‚
- [ ] è½‰ç½®åŸ·è¡Œè¨˜éŒ„å®Œæ•´
- [ ] è®Šæ›´æ­·ç¨‹å¯è¿½æº¯
- [ ] éŒ¯èª¤è™•ç†è¨˜éŒ„ä¿å­˜
- [ ] é©—è­‰å ±å‘Šå·²å­˜æª”ä¸¦ç°½æ ¸

### è³‡æ–™ä¿å­˜
- [ ] è³‡æ–™ä¿å­˜æœŸé™å·²ç¢ºèª
- [ ] æ­·å²è³‡æ–™æ­¸æª”æ©Ÿåˆ¶å·²å»ºç«‹
- [ ] è³‡æ–™åˆªé™¤æ©Ÿåˆ¶å·²è¨­è¨ˆ
- [ ] å‚™ä»½é‚„åŸæ©Ÿåˆ¶å·²é©—è­‰
```

> **ğŸ“Œ å¯¦å‹™å»ºè­°**ï¼š
> - é‡‘èç³»çµ±è½‰ç½®å¿…é ˆèˆ‡æ³•éµã€ç¨½æ ¸å–®ä½äº‹å…ˆæºé€š
> - æ•æ„Ÿè³‡æ–™è™•ç†æ–¹å¼éœ€æ­£å¼æ–‡ä»¶åŒ–
> - ä¿ç•™å®Œæ•´çš„ç¨½æ ¸è»Œè·¡ï¼Œä»¥å‚™æ—¥å¾ŒæŸ¥æ ¸
> - ä¸Šç·šå‰éœ€å–å¾—ç›¸é—œå–®ä½æ­£å¼ç°½æ ¸

---

## é™„éŒ„ Aï¼šè³‡æ–™è½‰ç½®å°ˆæ¡ˆæª¢æŸ¥æ¸…å–®ï¼ˆChecklistï¼‰

### A.1 å°ˆæ¡ˆå•Ÿå‹•éšæ®µ

```markdown
## å°ˆæ¡ˆå•Ÿå‹•æª¢æŸ¥æ¸…å–®

### ç¯„åœç¢ºèª
- [ ] è½‰ç½®ç¯„åœå·²æ˜ç¢ºå®šç¾©ä¸¦ç°½æ ¸
- [ ] èˆŠç³»çµ±è³‡æ–™æ¸…å†Šå·²å®Œæˆ
- [ ] æ–°ç³»çµ±è³‡æ–™æ¨¡å‹å·²ç¢ºèª
- [ ] è½‰ç½®æ™‚ç¨‹å·²è¦åŠƒ

### åœ˜éšŠçµ„æˆ
- [ ] å°ˆæ¡ˆç¶“ç†å·²æŒ‡æ´¾
- [ ] æŠ€è¡“è² è²¬äººå·²æŒ‡æ´¾
- [ ] æ¥­å‹™çª—å£å·²ç¢ºèª
- [ ] DBA æ”¯æ´å·²å”èª¿

### ç’°å¢ƒæº–å‚™
- [ ] é–‹ç™¼ç’°å¢ƒå·²å»ºç½®
- [ ] æ¸¬è©¦ç’°å¢ƒå·²å»ºç½®
- [ ] ä¾†æºè³‡æ–™å­˜å–æ¬Šé™å·²å–å¾—
- [ ] ç›®æ¨™è³‡æ–™åº«å·²å»ºç«‹
```

### A.2 åˆ†æè¨­è¨ˆéšæ®µ

```markdown
## åˆ†æè¨­è¨ˆæª¢æŸ¥æ¸…å–®

### èˆŠç³»çµ±åˆ†æ
- [ ] æ‰€æœ‰è³‡æ–™ä¾†æºå·²ç›¤é»
- [ ] Table/File çµæ§‹å·²æ–‡ä»¶åŒ–
- [ ] Key èˆ‡é—œè¯å·²åˆ†æ
- [ ] è³‡æ–™å“è³ªå·²æª¢æ¸¬
- [ ] è³‡æ–™é‡å·²çµ±è¨ˆ

### æ–°ç³»çµ±è¨­è¨ˆ
- [ ] è³‡æ–™æ¨¡å‹å·²è¨­è¨ˆ
- [ ] Mapping è¦å‰‡å·²å®šç¾©
- [ ] ä»£ç¢¼å°æ‡‰è¡¨å·²å»ºç«‹
- [ ] æ­·å²è³‡æ–™ç­–ç•¥å·²ç¢ºèª

### è½‰ç½®ç­–ç•¥
- [ ] è½‰ç½®æ¨¡å¼å·²æ±ºå®šï¼ˆBig Bang / Parallel Runï¼‰
- [ ] æ‰¹æ¬¡ç­–ç•¥å·²è¦åŠƒ
- [ ] Rollback æ©Ÿåˆ¶å·²è¨­è¨ˆ
- [ ] é©—è­‰æ©Ÿåˆ¶å·²è¨­è¨ˆ
```

### A.3 é–‹ç™¼æ¸¬è©¦éšæ®µ

```markdown
## é–‹ç™¼æ¸¬è©¦æª¢æŸ¥æ¸…å–®

### ç¨‹å¼é–‹ç™¼
- [ ] Extract ç¨‹å¼å·²å®Œæˆ
- [ ] Transform ç¨‹å¼å·²å®Œæˆ
- [ ] Load ç¨‹å¼å·²å®Œæˆ
- [ ] Error Handling å·²å¯¦ä½œ
- [ ] Checkpoint æ©Ÿåˆ¶å·²å¯¦ä½œ

### å–®å…ƒæ¸¬è©¦
- [ ] è½‰æ›é‚è¼¯æ¸¬è©¦é€šé
- [ ] é‚Šç•Œæ¢ä»¶æ¸¬è©¦é€šé
- [ ] éŒ¯èª¤è™•ç†æ¸¬è©¦é€šé
- [ ] æ•ˆèƒ½æ¸¬è©¦é€šé

### æ•´åˆæ¸¬è©¦
- [ ] End-to-End æ¸¬è©¦é€šé
- [ ] ç­†æ•¸é©—è­‰é€šé
- [ ] é‡‘é¡é©—è­‰é€šé
- [ ] Rollback æ¸¬è©¦é€šé
```

### A.4 UAT éšæ®µ

```markdown
## UAT æª¢æŸ¥æ¸…å–®

### æ¸¬è©¦æº–å‚™
- [ ] UAT ç’°å¢ƒå·²å»ºç½®
- [ ] æ¸¬è©¦è³‡æ–™å·²æº–å‚™
- [ ] æ¸¬è©¦æ¡ˆä¾‹å·²ç¢ºèª
- [ ] æ¥­å‹™äººå“¡å·²è¨“ç·´

### æ¸¬è©¦åŸ·è¡Œ
- [ ] æŠ€è¡“é©—è­‰é€šé
- [ ] æ¥­å‹™é©—è­‰é€šé
- [ ] æŠ½æ¨£é©—è­‰é€šé
- [ ] æ•ˆèƒ½é©—è­‰é€šé

### å•é¡Œè™•ç†
- [ ] æ‰€æœ‰å•é¡Œå·²è¨˜éŒ„
- [ ] é—œéµå•é¡Œå·²ä¿®å¾©
- [ ] ä¿®å¾©å¾Œå›æ­¸æ¸¬è©¦é€šé
- [ ] UAT ç°½æ ¸å·²å®Œæˆ
```

### A.5 ä¸Šç·šéšæ®µ

```markdown
## ä¸Šç·šæª¢æŸ¥æ¸…å–®

### ä¸Šç·šå‰ï¼ˆT-1ï¼‰
- [ ] ä¸Šç·šè¨ˆç•«å·²ç™¼é€
- [ ] ç¶­è­·å…¬å‘Šå·²ç™¼å¸ƒ
- [ ] å‚™ä»½å·²å®Œæˆ
- [ ] Rollback è…³æœ¬å·²æº–å‚™
- [ ] å€¼ç­äººå“¡å·²ç¢ºèª

### ä¸Šç·šä¸­ï¼ˆD-Dayï¼‰
- [ ] ç³»çµ±å·²åœæ©Ÿ
- [ ] è³‡æ–™æŠ½å–å®Œæˆ â†’ æ™‚é–“ï¼š______
- [ ] è³‡æ–™è½‰æ›å®Œæˆ â†’ æ™‚é–“ï¼š______
- [ ] è³‡æ–™è¼‰å…¥å®Œæˆ â†’ æ™‚é–“ï¼š______
- [ ] é©—è­‰é€šé â†’ çµæœï¼š______
- [ ] ç³»çµ±å·²å•Ÿå‹•
- [ ] åŠŸèƒ½æ¸¬è©¦é€šé

### ä¸Šç·šå¾Œï¼ˆD+1ï¼‰
- [ ] ç›£æ§æ­£å¸¸
- [ ] ç„¡ç•°å¸¸å›å ±
- [ ] æ¥­å‹™ç¢ºèªæ­£å¸¸
- [ ] ä¸Šç·šå ±å‘Šå·²ç”¢å‡º
```

---

## é™„éŒ„ Bï¼šå¸¸ç”¨ SQL ç¯„æœ¬

### B.1 è³‡æ–™å“è³ªæª¢æ¸¬

```sql
-- B.1.1 å®Œæ•´çš„è³‡æ–™å“è³ªæª¢æ¸¬è…³æœ¬
-- =====================================================

-- 1. ç©ºå€¼æª¢æ¸¬
SELECT 
    'NULL_CHECK' AS check_type,
    column_name,
    COUNT(*) AS null_count,
    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM target_table), 2) AS null_pct
FROM (
    SELECT 'CUST_NAME' AS column_name FROM target_table WHERE cust_name IS NULL
    UNION ALL
    SELECT 'CUST_TYPE' FROM target_table WHERE cust_type IS NULL
    UNION ALL
    SELECT 'CREATE_DATE' FROM target_table WHERE create_date IS NULL
) t
GROUP BY column_name;

-- 2. é‡è¤‡å€¼æª¢æ¸¬
SELECT 
    'DUPLICATE_CHECK' AS check_type,
    cust_id,
    COUNT(*) AS dup_count
FROM target_table
GROUP BY cust_id
HAVING COUNT(*) > 1;

-- 3. æ ¼å¼é©—è­‰ï¼ˆèº«åˆ†è­‰å­—è™Ÿï¼‰
SELECT 
    'FORMAT_CHECK' AS check_type,
    'ID_NO' AS column_name,
    COUNT(*) AS invalid_count
FROM target_table
WHERE id_no IS NOT NULL
  AND NOT REGEXP_LIKE(id_no, '^[A-Z][12][0-9]{8}$');

-- 4. ç¯„åœé©—è­‰
SELECT 
    'RANGE_CHECK' AS check_type,
    'BALANCE' AS column_name,
    COUNT(*) AS invalid_count
FROM target_table
WHERE balance < 0;

-- 5. åƒç…§å®Œæ•´æ€§
SELECT 
    'FK_CHECK' AS check_type,
    'CUST_ID' AS column_name,
    COUNT(*) AS orphan_count
FROM account a
LEFT JOIN customer c ON a.cust_id = c.cust_id
WHERE c.cust_id IS NULL;
```

### B.2 è³‡æ–™æ¯”å°

```sql
-- B.2.1 æ–°èˆŠè³‡æ–™æ¯”å°è…³æœ¬
-- =====================================================

-- 1. ç­†æ•¸æ¯”å°
WITH counts AS (
    SELECT 'SOURCE' AS system, COUNT(*) AS cnt FROM old_customer
    UNION ALL
    SELECT 'TARGET', COUNT(*) FROM new_customer WHERE migration_batch_id IS NOT NULL
)
SELECT 
    MAX(CASE WHEN system = 'SOURCE' THEN cnt END) AS source_count,
    MAX(CASE WHEN system = 'TARGET' THEN cnt END) AS target_count,
    MAX(CASE WHEN system = 'SOURCE' THEN cnt END) - 
    MAX(CASE WHEN system = 'TARGET' THEN cnt END) AS diff
FROM counts;

-- 2. é‡‘é¡æ¯”å°
SELECT 
    SUM(s.balance) AS source_balance,
    SUM(t.balance) AS target_balance,
    SUM(s.balance) - SUM(t.balance) AS diff,
    CASE 
        WHEN ABS(SUM(s.balance) - SUM(t.balance)) < 0.01 THEN 'PASS'
        ELSE 'FAIL'
    END AS result
FROM old_account s
FULL OUTER JOIN new_account t 
    ON s.acct_no = t.account_no;

-- 3. æ¬„ä½å€¼æ¯”å°
SELECT 
    s.cust_id,
    'NAME_MISMATCH' AS mismatch_type,
    s.cust_name AS source_value,
    t.name AS target_value
FROM old_customer s
JOIN new_customer t ON s.cust_id = t.customer_no
WHERE TRIM(s.cust_name) <> TRIM(t.name)
UNION ALL
SELECT 
    s.cust_id,
    'TYPE_MISMATCH',
    s.cust_type,
    t.customer_type
FROM old_customer s
JOIN new_customer t ON s.cust_id = t.customer_no
WHERE s.cust_type <> (
    SELECT source_code 
    FROM migration_code_mapping 
    WHERE category = 'CUST_TYPE' AND target_code = t.customer_type
);
```

### B.3 è½‰ç½®é€²åº¦è¿½è¹¤

```sql
-- B.3.1 è½‰ç½®é€²åº¦æŸ¥è©¢
-- =====================================================

-- 1. æ‰¹æ¬¡é€²åº¦ç¸½è¦½
SELECT 
    batch_id,
    table_name,
    status,
    total_rows,
    processed_rows,
    ROUND(processed_rows * 100.0 / NULLIF(total_rows, 0), 2) AS progress_pct,
    start_time,
    end_time,
    TIMESTAMPDIFF(MINUTE, start_time, COALESCE(end_time, NOW())) AS duration_min
FROM migration_batch_control
ORDER BY batch_id;

-- 2. éŒ¯èª¤çµ±è¨ˆ
SELECT 
    batch_id,
    error_phase,
    error_type,
    COUNT(*) AS error_count,
    COUNT(CASE WHEN resolved_at IS NOT NULL THEN 1 END) AS resolved_count
FROM migration_error_log
GROUP BY batch_id, error_phase, error_type
ORDER BY batch_id, error_count DESC;

-- 3. æ¯å°æ™‚è™•ç†é‡è¶¨å‹¢
SELECT 
    DATE_FORMAT(load_time, '%Y-%m-%d %H:00') AS hour,
    COUNT(*) AS records_loaded
FROM stg_customer
WHERE process_status = 'LOADED'
GROUP BY DATE_FORMAT(load_time, '%Y-%m-%d %H:00')
ORDER BY hour;
```

---

## é™„éŒ„ Cï¼šåè©è§£é‡‹

| åè© | è‹±æ–‡ | èªªæ˜ |
|------|------|------|
| **è³‡æ–™è½‰ç½®** | Data Migration | å°‡è³‡æ–™å¾ä¸€å€‹ç³»çµ±æ¬ç§»ä¸¦è½‰æ›åˆ°å¦ä¸€å€‹ç³»çµ±çš„éç¨‹ |
| **ETL** | Extract, Transform, Load | è³‡æ–™è™•ç†çš„ä¸‰å€‹ä¸»è¦æ­¥é©Ÿï¼šæŠ½å–ã€è½‰æ›ã€è¼‰å…¥ |
| **CDC** | Change Data Capture | æ•ç²è³‡æ–™è®Šæ›´çš„æŠ€è¡“ï¼Œç”¨æ–¼å³æ™‚åŒæ­¥ |
| **Staging Table** | - | æš«å­˜è³‡æ–™çš„ä¸­é–“è¡¨ï¼Œç”¨æ–¼è³‡æ–™è™•ç†éç¨‹ |
| **Mapping** | - | æ¬„ä½å°æ‡‰é—œä¿‚ï¼Œå®šç¾©ä¾†æºèˆ‡ç›®æ¨™æ¬„ä½çš„å°æ‡‰è¦å‰‡ |
| **Big Bang** | - | ä¸€æ¬¡æ€§å®Œæ•´åˆ‡æ›çš„ä¸Šç·šç­–ç•¥ |
| **Parallel Run** | - | æ–°èˆŠç³»çµ±ä¸¦è¡Œé‹ä½œçš„ä¸Šç·šç­–ç•¥ |
| **Rollback** | - | å›å¾©åˆ°è½‰ç½®å‰ç‹€æ…‹çš„å‹•ä½œ |
| **Checkpoint** | - | æª¢æŸ¥é»ï¼Œç”¨æ–¼è¨˜éŒ„è™•ç†é€²åº¦ä»¥ä¾¿æ¢å¾© |
| **Data Profiling** | - | è³‡æ–™å‰–æï¼Œåˆ†æè³‡æ–™çš„å“è³ªèˆ‡ç‰¹æ€§ |
| **Upsert** | Update + Insert | å­˜åœ¨å‰‡æ›´æ–°ï¼Œä¸å­˜åœ¨å‰‡æ–°å¢çš„æ“ä½œ |
| **Batch Processing** | æ‰¹æ¬¡è™•ç† | å¤§é‡è³‡æ–™çš„æ‰¹æ¬¡è™•ç†æ–¹å¼ |
| **Data Lineage** | è³‡æ–™è¡€ç·£ | è¿½è¹¤è³‡æ–™å¾ä¾†æºåˆ°ç›®æ¨™çš„å®Œæ•´è·¯å¾‘ |
| **Code Mapping** | ä»£ç¢¼å°æ‡‰ | å°‡èˆŠç³»çµ±ä»£ç¢¼è½‰æ›ç‚ºæ–°ç³»çµ±ä»£ç¢¼çš„å°æ‡‰è¡¨ |
| **Incremental Load** | å¢é‡è¼‰å…¥ | åªè¼‰å…¥ç•°å‹•è³‡æ–™çš„æ–¹å¼ |
| **Full Load** | å…¨é‡è¼‰å…¥ | è¼‰å…¥å…¨éƒ¨è³‡æ–™çš„æ–¹å¼ |
| **Data Validation** | è³‡æ–™é©—è­‰ | ç¢ºèªè³‡æ–™æ­£ç¢ºæ€§çš„æª¢é©—éç¨‹ |
| **Audit Trail** | ç¨½æ ¸è»Œè·¡ | è¨˜éŒ„æ‰€æœ‰æ“ä½œçš„æ—¥èªŒï¼Œç”¨æ–¼è¿½è¹¤èˆ‡ç¨½æ ¸ |
| **SLA** | Service Level Agreement | æœå‹™ç­‰ç´šå”è­°ï¼Œå®šç¾©æœå‹™çš„å“è³ªæ¨™æº– |
| **UAT** | User Acceptance Testing | ä½¿ç”¨è€…é©—æ”¶æ¸¬è©¦ |

---

## ç‰ˆæœ¬æ­·ç¨‹

| ç‰ˆæœ¬ | æ—¥æœŸ | ä¿®æ”¹å…§å®¹ | ä¿®æ”¹äºº |
|------|------|---------|--------|
| 1.0 | 2026-02-02 | åˆç‰ˆç™¼å¸ƒ | ç³»çµ±æ¶æ§‹çµ„ |

---

## åƒè€ƒè³‡æ–™

1. **è³‡æ–™è½‰ç½®æœ€ä½³å¯¦è¸**
   - Oracle Data Migration Best Practices
   - Microsoft SQL Server Data Migration Guide

2. **ETL å·¥å…·æ–‡ä»¶**
   - Apache Airflow Documentation
   - Spring Batch Reference Guide
   - Talend Data Integration Guide

3. **è³‡æ–™å“è³ªç®¡ç†**
   - Data Quality Assessment Framework
   - Great Expectations Documentation

4. **ç›¸é—œæ¨™æº–**
   - ISO 8000 Data Quality
   - GDPR Data Protection Guidelines

---

> **æ–‡ä»¶ç¶­è­·èªªæ˜**ï¼š
> - æœ¬æ–‡ä»¶ç”±ç³»çµ±æ¶æ§‹çµ„ç¶­è­·
> - æ–‡ä»¶æ›´æ–°é »ç‡ï¼šæ¯å­£åº¦æª¢è¦–ä¸€æ¬¡