+++
date = '2026-01-26T21:17:47+08:00'
draft = false
title = 'Logs Visualizationæ•™å­¸æ‰‹å†Š'
+++
tags = ['æ•™å­¸', 'å·¥å…·', 'Visualization','ELK stack']
categories = ['æ•™å­¸']
+++


# Logs Visualization æ•™å­¸æ‰‹å†Šï¼ˆELK Stackï¼‰

> **ç‰ˆæœ¬**ï¼š1.0  
> **æœ€å¾Œæ›´æ–°**ï¼š2026 å¹´ 1 æœˆ  
> **é©ç”¨å°è±¡**ï¼šè³‡æ·±è»Ÿé«”å·¥ç¨‹å¸«ã€ç³»çµ±æ¶æ§‹å¸«ã€SRE / DevOps å·¥ç¨‹å¸« 
> **æœ€å¾Œæ›´æ–°**: 2026å¹´1æœˆ26æ—¥  
> **é©ç”¨æ–¼**: Logs Visualization 
> **Created by**: Eric Cheng


## ğŸ“‹ ç›®éŒ„

1. [Logs Visualization åœ¨ä¼æ¥­ç³»çµ±ä¸­çš„å®šä½](#1-logs-visualization-åœ¨ä¼æ¥­ç³»çµ±ä¸­çš„å®šä½)
   - [1.1 ç‚ºä»€éº¼ Logs æ˜¯ã€Œç¬¬äºŒå¥—çœŸå¯¦ç³»çµ±ã€](#11-ç‚ºä»€éº¼-logs-æ˜¯ç¬¬äºŒå¥—çœŸå¯¦ç³»çµ±)
   - [1.2 Logs vs Metrics vs Tracing](#12-logs-vs-metrics-vs-tracing)
   - [1.3 Logs åœ¨ Dev / QA / Prod çš„ä¸åŒåƒ¹å€¼](#13-logs-åœ¨-dev--qa--prod-çš„ä¸åŒåƒ¹å€¼)
2. [ELK Stack æ•´é«”æ¶æ§‹è¨­è¨ˆ](#2-elk-stack-æ•´é«”æ¶æ§‹è¨­è¨ˆ)
   - [2.1 Log ç”¢ç”Ÿç«¯ï¼ˆApplication / Middleware / OSï¼‰](#21-log-ç”¢ç”Ÿç«¯application--middleware--os)
   - [2.2 Logstash Pipeline è¨­è¨ˆåŸå‰‡](#22-logstash-pipeline-è¨­è¨ˆåŸå‰‡)
   - [2.3 Elasticsearch Index / Shard / Replica è¨­è¨ˆ](#23-elasticsearch-index--shard--replica-è¨­è¨ˆ)
   - [2.4 Kibana åœ¨è¦–è¦ºåŒ–èˆ‡åˆ†æä¸Šçš„è§’è‰²](#24-kibana-åœ¨è¦–è¦ºåŒ–èˆ‡åˆ†æä¸Šçš„è§’è‰²)
3. [Logstash æ·±åº¦å¯¦å‹™](#3-logstash-æ·±åº¦å¯¦å‹™)
   - [3.1 Pipeline æ¶æ§‹è¨­è¨ˆï¼ˆInput / Filter / Outputï¼‰](#31-pipeline-æ¶æ§‹è¨­è¨ˆinput--filter--output)
   - [3.2 Grok / JSON / Mutate å¯¦å‹™æŠ€å·§](#32-grok--json--mutate-å¯¦å‹™æŠ€å·§)
   - [3.3 æ•ˆèƒ½èª¿æ ¡èˆ‡å¸¸è¦‹ç“¶é ¸](#33-æ•ˆèƒ½èª¿æ ¡èˆ‡å¸¸è¦‹ç“¶é ¸)
   - [3.4 å¤šä¾†æº Logï¼ˆApp / DB / MQ / Batchï¼‰](#34-å¤šä¾†æº-logapp--db--mq--batch)
4. [Elasticsearch æ¶æ§‹èˆ‡æ•ˆèƒ½è¨­è¨ˆ](#4-elasticsearch-æ¶æ§‹èˆ‡æ•ˆèƒ½è¨­è¨ˆ)
   - [4.1 Index è¨­è¨ˆç­–ç•¥](#41-index-è¨­è¨ˆç­–ç•¥)
   - [4.2 Mapping èˆ‡æ•ˆèƒ½å½±éŸ¿](#42-mapping-èˆ‡æ•ˆèƒ½å½±éŸ¿)
   - [4.3 Hot / Warm / Cold æ¶æ§‹](#43-hot--warm--cold-æ¶æ§‹)
   - [4.4 æŸ¥è©¢æ•ˆèƒ½èˆ‡è³‡æºè¦åŠƒ](#44-æŸ¥è©¢æ•ˆèƒ½èˆ‡è³‡æºè¦åŠƒ)
5. [Kibana è¦–è¦ºåŒ–èˆ‡åˆ†æè¨­è¨ˆ](#5-kibana-è¦–è¦ºåŒ–èˆ‡åˆ†æè¨­è¨ˆ)
   - [5.1 Dashboard è¨­è¨ˆåŸå‰‡ï¼ˆçµ¦èª°çœ‹ï¼Ÿçœ‹ä»€éº¼ï¼Ÿï¼‰](#51-dashboard-è¨­è¨ˆåŸå‰‡çµ¦èª°çœ‹çœ‹ä»€éº¼)
   - [5.2 Discoverã€Lensã€Alerting å¯¦å‹™](#52-discoverlensalerting-å¯¦å‹™)
   - [5.3 å¸¸è¦‹ä¼æ¥­ Dashboard ç¯„ä¾‹](#53-å¸¸è¦‹ä¼æ¥­-dashboard-ç¯„ä¾‹)
6. [AI è¼”åŠ© Logs Visualization çš„å¯¦æˆ°æ‡‰ç”¨](#6-ai-è¼”åŠ©-logs-visualization-çš„å¯¦æˆ°æ‡‰ç”¨)
   - [6.1 ç”¨ AI å”åŠ©æ’°å¯« Elasticsearch Query](#61-ç”¨-ai-å”åŠ©æ’°å¯«-elasticsearch-query)
   - [6.2 ç”¨ AI åˆ†æéŒ¯èª¤ Log èˆ‡ç•°å¸¸æ¨¡å¼](#62-ç”¨-ai-åˆ†æéŒ¯èª¤-log-èˆ‡ç•°å¸¸æ¨¡å¼)
   - [6.3 å°‡ Logs æ•´ç†æˆ AI å¯ç†è§£çš„ Prompt](#63-å°‡-logs-æ•´ç†æˆ-ai-å¯ç†è§£çš„-prompt)
   - [6.4 AI åœ¨ Incident Response ä¸­çš„è§’è‰²](#64-ai-åœ¨-incident-response-ä¸­çš„è§’è‰²)
7. [å¸¸è¦‹å•é¡Œã€é™·é˜±èˆ‡æœ€ä½³å¯¦å‹™](#7-å¸¸è¦‹å•é¡Œé™·é˜±èˆ‡æœ€ä½³å¯¦å‹™)
   - [7.1 Log çˆ†é‡çš„è™•ç†æ–¹å¼](#71-log-çˆ†é‡çš„è™•ç†æ–¹å¼)
   - [7.2 Index æˆé•·å¤±æ§æ€éº¼è¾¦](#72-index-æˆé•·å¤±æ§æ€éº¼è¾¦)
   - [7.3 è³‡å®‰èˆ‡å€‹è³‡ï¼ˆPIIï¼‰è™•ç†](#73-è³‡å®‰èˆ‡å€‹è³‡piiè™•ç†)
   - [7.4 é‡‘èæ¥­å¸¸è¦‹ç¨½æ ¸èˆ‡æ³•éµéœ€æ±‚](#74-é‡‘èæ¥­å¸¸è¦‹ç¨½æ ¸èˆ‡æ³•éµéœ€æ±‚)
8. [ä¼æ¥­ç´šå°å…¥èˆ‡æ²»ç†å»ºè­°](#8-ä¼æ¥­ç´šå°å…¥èˆ‡æ²»ç†å»ºè­°)
   - [8.1 Log è¦ç¯„èˆ‡å‘½åæ¨™æº–](#81-log-è¦ç¯„èˆ‡å‘½åæ¨™æº–)
   - [8.2 åœ˜éšŠåˆ†å·¥èˆ‡æ¬Šé™è¨­è¨ˆ](#82-åœ˜éšŠåˆ†å·¥èˆ‡æ¬Šé™è¨­è¨ˆ)
   - [8.3 èˆ‡ CI/CDã€APMã€SIEM çš„æ•´åˆ](#83-èˆ‡-cicdapmsiem-çš„æ•´åˆ)
9. [æª¢æŸ¥æ¸…å–®ï¼ˆChecklistï¼‰](#9-æª¢æŸ¥æ¸…å–®checklist)
10. [é™„éŒ„](#é™„éŒ„)
    - [A. å¸¸ç”¨ Elasticsearch Query ç¯„ä¾‹](#a-å¸¸ç”¨-elasticsearch-query-ç¯„ä¾‹)
    - [B. å¸¸ç”¨ KQL æŸ¥è©¢ç¯„ä¾‹](#b-å¸¸ç”¨-kql-æŸ¥è©¢ç¯„ä¾‹)
    - [C. åƒè€ƒè³‡æº](#c-åƒè€ƒè³‡æº)

---

## 1. Logs Visualization åœ¨ä¼æ¥­ç³»çµ±ä¸­çš„å®šä½

### 1.1 ç‚ºä»€éº¼ Logs æ˜¯ã€Œç¬¬äºŒå¥—çœŸå¯¦ç³»çµ±ã€

åœ¨ä¼æ¥­ç´šç³»çµ±ä¸­ï¼Œ**Logs ä¸åªæ˜¯é™¤éŒ¯å·¥å…·ï¼Œè€Œæ˜¯ç³»çµ±è¡Œç‚ºçš„å®Œæ•´è¨˜éŒ„**ã€‚ç•¶ç”Ÿç”¢ç’°å¢ƒç™¼ç”Ÿå•é¡Œæ™‚ï¼ŒLogs å¾€å¾€æ˜¯å”¯ä¸€èƒ½é‚„åŸã€Œç•¶æ™‚åˆ°åº•ç™¼ç”Ÿä»€éº¼äº‹ã€çš„è­‰æ“šã€‚

#### æ ¸å¿ƒè§€å¿µ

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ç³»çµ±çš„å…©å¥—çœŸå¯¦                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç¬¬ä¸€å¥—çœŸå¯¦ï¼šç¨‹å¼ç¢¼ï¼ˆCodeï¼‰                                      â”‚
â”‚  â”œâ”€â”€ å®šç¾©ç³»çµ±ã€Œæ‡‰è©²ã€å¦‚ä½•é‹ä½œ                                    â”‚
â”‚  â””â”€â”€ éœæ…‹ã€å¯æ§ã€å¯ç‰ˆæœ¬ç®¡ç†                                      â”‚
â”‚                                                                 â”‚
â”‚  ç¬¬äºŒå¥—çœŸå¯¦ï¼šæ—¥èªŒï¼ˆLogsï¼‰                                        â”‚
â”‚  â”œâ”€â”€ è¨˜éŒ„ç³»çµ±ã€Œå¯¦éš›ã€å¦‚ä½•é‹ä½œ                                    â”‚
â”‚  â””â”€â”€ å‹•æ…‹ã€å³æ™‚ã€åæ˜ çœŸå¯¦è¡Œç‚º                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ç‚ºä»€éº¼é€™å€‹è§€å¿µé‡è¦ï¼Ÿ

| æƒ…å¢ƒ | ç¨‹å¼ç¢¼å‘Šè¨´ä½  | Logs å‘Šè¨´ä½  |
|------|-------------|-------------|
| äº¤æ˜“å¤±æ•— | æ‡‰è©²æœƒé‡è©¦ 3 æ¬¡ | å¯¦éš›é‡è©¦äº† 5 æ¬¡ï¼Œç¬¬ 3 æ¬¡ timeout |
| æ•ˆèƒ½å•é¡Œ | æŸ¥è©¢æ‡‰è©² < 100ms | å¯¦éš› P99 æ˜¯ 2.3 ç§’ |
| è³‡å®‰äº‹ä»¶ | æ‡‰è©²æœƒæ“‹æ‰éæ³•è«‹æ±‚ | æœ‰ 500 ç­†ç•°å¸¸è«‹æ±‚ä¾†è‡ªåŒä¸€ IP |
| ç³»çµ±æ•´åˆ | API æ‡‰è©²å›å‚³ 200 | ä¸‹æ¸¸ç³»çµ±å›å‚³ 503ï¼Œä½†æ²’æœ‰è¢«æ­£ç¢ºè™•ç† |

ğŸ’¡ **å¯¦æˆ°å»ºè­°**ï¼šæŠŠ Logs è¦–ç‚ºã€Œç³»çµ±çš„é»‘ç›’å­è¨˜éŒ„å™¨ã€ï¼Œè€Œéäº‹å¾Œè£œæ•‘çš„å·¥å…·ã€‚è¨­è¨ˆç³»çµ±æ™‚ï¼Œæ‡‰è©²åŒæ™‚è¨­è¨ˆ Log ç­–ç•¥ã€‚

#### é‡‘èæ¥­ç‰¹æ®Šè€ƒé‡

åœ¨éŠ€è¡Œèˆ‡é‡‘èç³»çµ±ä¸­ï¼ŒLogs é‚„æ‰¿æ“”ä»¥ä¸‹è²¬ä»»ï¼š

1. **ç¨½æ ¸è»Œè·¡ï¼ˆAudit Trailï¼‰**ï¼šæ¯ç­†äº¤æ˜“å¿…é ˆå¯è¿½æº¯
2. **æ³•éµè¦æ±‚ï¼ˆComplianceï¼‰**ï¼šä¸»ç®¡æ©Ÿé—œè¦æ±‚ä¿ç•™ç‰¹å®šå¹´é™
3. **äº‹æ•…èª¿æŸ¥ï¼ˆIncident Investigationï¼‰**ï¼šè³‡å®‰äº‹ä»¶çš„æ³•å¾‹è­‰æ“š
4. **ç‡Ÿé‹å ±è¡¨ï¼ˆOperational Reportingï¼‰**ï¼šäº¤æ˜“é‡ã€éŒ¯èª¤ç‡ç­‰ KPI

âš ï¸ **å¸¸è¦‹éŒ¯èª¤**ï¼šè¨±å¤šåœ˜éšŠæŠŠ Logs ç•¶æˆã€Œé–‹ç™¼éšæ®µçš„é™¤éŒ¯å·¥å…·ã€ï¼Œä¸Šç·šå¾Œå°±é—œæ‰æˆ–é™ä½ Log Levelã€‚é€™åœ¨é‡‘èæ¥­æ˜¯åš´é‡çš„åˆè¦é¢¨éšªã€‚

---

### 1.2 Logs vs Metrics vs Tracing

ç¾ä»£å¯è§€æ¸¬æ€§ï¼ˆObservabilityï¼‰ç”±ä¸‰å¤§æ”¯æŸ±çµ„æˆï¼Œå„æœ‰ä¸åŒç”¨é€”ï¼š

```mermaid
graph TB
    subgraph "å¯è§€æ¸¬æ€§ä¸‰å¤§æ”¯æŸ±"
        M[Metrics<br/>æŒ‡æ¨™]
        L[Logs<br/>æ—¥èªŒ]
        T[Tracing<br/>è¿½è¹¤]
    end
    
    M -->|"å›ç­”"| Q1["ç³»çµ±ç¾åœ¨æ€éº¼æ¨£ï¼Ÿ<br/>ï¼ˆèšåˆæ•¸æ“šï¼‰"]
    L -->|"å›ç­”"| Q2["ç™¼ç”Ÿäº†ä»€éº¼äº‹ï¼Ÿ<br/>ï¼ˆäº‹ä»¶ç´°ç¯€ï¼‰"]
    T -->|"å›ç­”"| Q3["è«‹æ±‚ç¶“éå“ªäº›åœ°æ–¹ï¼Ÿ<br/>ï¼ˆè·¨æœå‹™æµç¨‹ï¼‰"]
    
    style M fill:#e1f5fe
    style L fill:#fff3e0
    style T fill:#f3e5f5
```

#### ä¸‰è€…æ¯”è¼ƒ

| ç¶­åº¦ | Metrics | Logs | Tracing |
|------|---------|------|---------|
| **è³‡æ–™å‹æ…‹** | æ•¸å€¼ï¼ˆå¯èšåˆï¼‰ | æ–‡å­—ï¼ˆäº‹ä»¶ï¼‰ | çµæ§‹åŒ– Span |
| **è³‡æ–™é‡** | ä½ï¼ˆå£“ç¸®å¾Œï¼‰ | é«˜ï¼ˆåŸå§‹æ–‡å­—ï¼‰ | ä¸­ï¼ˆæ¡æ¨£ï¼‰ |
| **æŸ¥è©¢é€Ÿåº¦** | æ¥µå¿« | ä¸­ç­‰ | ä¸­ç­‰ |
| **é©ç”¨å ´æ™¯** | ç›£æ§ã€å‘Šè­¦ã€è¶¨å‹¢ | é™¤éŒ¯ã€ç¨½æ ¸ã€åˆ†æ | åˆ†æ•£å¼è¿½è¹¤ |
| **å…¸å‹å·¥å…·** | Prometheus, Grafana | ELK, Splunk | Jaeger, Zipkin |
| **ä¿ç•™æœŸé™** | é•·ï¼ˆå£“ç¸®å„²å­˜ï¼‰ | ä¸­ï¼ˆä¾æ³•è¦ï¼‰ | çŸ­ï¼ˆæ¡æ¨£å„²å­˜ï¼‰ |

#### å¯¦å‹™æ‡‰ç”¨å ´æ™¯

```text
å•é¡Œï¼šã€Œç‚ºä»€éº¼ä»Šå¤©ä¸‹åˆ 3 é»äº¤æ˜“å¤±æ•—ç‡çªç„¶ä¸Šå‡ï¼Ÿã€

Step 1: Metricsï¼ˆç™¼ç¾å•é¡Œï¼‰
         â””â”€â”€ Grafana çœ‹åˆ° error_rate å¾ 0.1% è·³åˆ° 5%

Step 2: Logsï¼ˆå®šä½åŸå› ï¼‰
         â””â”€â”€ Kibana æœå°‹è©²æ™‚æ®µ ERROR logs
         â””â”€â”€ ç™¼ç¾å¤§é‡ "Connection timeout to payment-gateway"

Step 3: Tracingï¼ˆè¿½è¹¤è·¯å¾‘ï¼‰
         â””â”€â”€ Jaeger æŸ¥çœ‹å¤±æ•—è«‹æ±‚çš„å®Œæ•´å‘¼å«éˆ
         â””â”€â”€ ç™¼ç¾ payment-gateway â†’ bank-api é€™æ®µè€—æ™‚ç•°å¸¸
```

ğŸ’¡ **å¯¦æˆ°å»ºè­°**ï¼šä¸è¦æœŸå¾…å–®ä¸€å·¥å…·è§£æ±ºæ‰€æœ‰å•é¡Œã€‚å»ºç«‹ Metrics â†’ Logs â†’ Tracing çš„é—œè¯æ©Ÿåˆ¶ï¼ˆå¦‚ Trace IDï¼‰ï¼Œè®“ä¸‰è€…å¯ä»¥äº’ç›¸è·³è½‰ã€‚

---

### 1.3 Logs åœ¨ Dev / QA / Prod çš„ä¸åŒåƒ¹å€¼

ä¸åŒç’°å¢ƒå° Logs çš„éœ€æ±‚å·®ç•°å¾ˆå¤§ï¼š

#### ç’°å¢ƒæ¯”è¼ƒè¡¨

| ç¶­åº¦ | Development | QA / Staging | Production |
|------|-------------|--------------|------------|
| **ä¸»è¦ç”¨é€”** | é™¤éŒ¯ã€é–‹ç™¼é©—è­‰ | åŠŸèƒ½æ¸¬è©¦ã€æ•´åˆæ¸¬è©¦ | ç›£æ§ã€ç¨½æ ¸ã€äº‹æ•…è™•ç† |
| **Log Level** | DEBUG / TRACE | INFO / DEBUG | INFO / WARN / ERROR |
| **è³‡æ–™æ•æ„Ÿåº¦** | ä½ï¼ˆæ¸¬è©¦è³‡æ–™ï¼‰ | ä¸­ï¼ˆå¯èƒ½æœ‰çœŸå¯¦è³‡æ–™ï¼‰ | é«˜ï¼ˆçœŸå¯¦å®¢æˆ¶è³‡æ–™ï¼‰ |
| **æ•ˆèƒ½è€ƒé‡** | ä¸é‡è¦ | ä¸­ç­‰ | é—œéµï¼ˆä¸èƒ½å½±éŸ¿æ•ˆèƒ½ï¼‰ |
| **ä¿ç•™æœŸé™** | çŸ­ï¼ˆå¹¾å¤©ï¼‰ | ä¸­ï¼ˆæ•¸é€±ï¼‰ | é•·ï¼ˆä¾æ³•è¦ï¼Œå¯èƒ½æ•¸å¹´ï¼‰ |
| **å­˜å–æ¬Šé™** | é–‹ç™¼äººå“¡çš†å¯ | æ¸¬è©¦åœ˜éšŠ + é–‹ç™¼ | åš´æ ¼ç®¡æ§ |

#### å„ç’°å¢ƒ Log ç­–ç•¥ç¯„ä¾‹

#### Development ç’°å¢ƒ

```yaml
# log4j2.xml ç¯„ä¾‹
<Root level="DEBUG">
    <AppenderRef ref="Console"/>
    <AppenderRef ref="File"/>
</Root>

# ç‰¹é»ï¼š
# - è¼¸å‡ºå®Œæ•´å †ç–Šè¿½è¹¤
# - åŒ…å« SQL æŸ¥è©¢ã€HTTP è«‹æ±‚/å›æ‡‰ body
# - å¯è¼¸å‡ºåˆ° Console æ–¹ä¾¿å³æ™‚æŸ¥çœ‹
```

#### Production ç’°å¢ƒ

```yaml
# log4j2.xml ç¯„ä¾‹
<Root level="INFO">
    <AppenderRef ref="AsyncFile"/>
    <AppenderRef ref="Logstash"/>
</Root>

# ç‰¹é»ï¼š
# - ä½¿ç”¨ Async Appender é¿å…é˜»å¡
# - æ•æ„Ÿè³‡æ–™å¿…é ˆé®è”½
# - çµæ§‹åŒ– JSON æ ¼å¼æ–¹ä¾¿è§£æ
# - ç›´æ¥é€åˆ° Logstash/Kafka
```

âš ï¸ **å¸¸è¦‹éŒ¯èª¤**ï¼š

1. **Dev ç¿’æ…£å¸¶åˆ° Prod**ï¼šDEBUG level åœ¨ Prod é–‹å•Ÿï¼Œé€ æˆ Log çˆ†é‡
2. **æ•æ„Ÿè³‡æ–™å¤–æ´©**ï¼šDev ç’°å¢ƒçš„ Log æ ¼å¼ï¼ˆå«å®Œæ•´è³‡æ–™ï¼‰ç›´æ¥ç”¨åœ¨ Prod
3. **æ•ˆèƒ½å¿½è¦–**ï¼šåŒæ­¥å¯« Log é€ æˆ Latency ä¸Šå‡

---

## 2. ELK Stack æ•´é«”æ¶æ§‹è¨­è¨ˆ

### 2.1 Log ç”¢ç”Ÿç«¯ï¼ˆApplication / Middleware / OSï¼‰

#### ä¼æ¥­ç´š Log ä¾†æºå…¨æ™¯åœ–

```mermaid
graph LR
    subgraph "Log ç”¢ç”Ÿç«¯"
        A[Application Logs<br/>æ‡‰ç”¨ç¨‹å¼æ—¥èªŒ]
        M[Middleware Logs<br/>ä¸­ä»‹è»Ÿé«”æ—¥èªŒ]
        O[OS/Infra Logs<br/>ä½œæ¥­ç³»çµ±æ—¥èªŒ]
        S[Security Logs<br/>è³‡å®‰æ—¥èªŒ]
    end
    
    subgraph "å‚³è¼¸å±¤"
        B[Beats / Fluentd<br/>è¼•é‡æ¡é›†å™¨]
        K[Kafka / Redis<br/>ç·©è¡ä½‡åˆ—]
    end
    
    subgraph "è™•ç†å±¤"
        L[Logstash<br/>è§£æèˆ‡è½‰æ›]
    end
    
    subgraph "å„²å­˜èˆ‡æŸ¥è©¢"
        E[Elasticsearch<br/>ç´¢å¼•èˆ‡æœå°‹]
        KB[Kibana<br/>è¦–è¦ºåŒ–]
    end
    
    A --> B
    M --> B
    O --> B
    S --> B
    B --> K
    K --> L
    L --> E
    E --> KB
```

#### å„é¡ Log ä¾†æºè©³è§£

| é¡åˆ¥ | ä¾†æºç¯„ä¾‹ | Log å…§å®¹ | é‡è¦æ€§ |
|------|---------|----------|--------|
| **Application** | Spring Boot, .NET, Node.js | æ¥­å‹™é‚è¼¯ã€äº¤æ˜“è¨˜éŒ„ã€ä¾‹å¤– | â­â­â­â­â­ |
| **Middleware** | Nginx, Tomcat, WildFly | å­˜å–æ—¥èªŒã€éŒ¯èª¤ã€æ•ˆèƒ½ | â­â­â­â­ |
| **Database** | Oracle, PostgreSQL, MongoDB | æ…¢æŸ¥è©¢ã€éŒ¯èª¤ã€é€£ç·š | â­â­â­â­ |
| **Message Queue** | Kafka, RabbitMQ, IBM MQ | è¨Šæ¯è™•ç†ã€å»¶é²ã€å¤±æ•— | â­â­â­â­ |
| **OS/Infra** | Linux syslog, Windows Event | ç³»çµ±éŒ¯èª¤ã€è³‡æºè­¦å‘Š | â­â­â­ |
| **Security** | WAF, IDS, Firewall | æ”»æ“Šåµæ¸¬ã€å­˜å–é•è¦ | â­â­â­â­â­ |
| **Container** | Docker, Kubernetes | Pod äº‹ä»¶ã€å®¹å™¨æ—¥èªŒ | â­â­â­â­ |

#### Application Log çµæ§‹åŒ–è¨­è¨ˆ

#### âŒ ä¸å¥½çš„ Log æ ¼å¼ï¼ˆéçµæ§‹åŒ–ï¼‰

```text
2026-01-26 10:30:45 ERROR PaymentService - Payment failed for user john@example.com, amount 50000, card ending 1234
```

#### âœ… å¥½çš„ Log æ ¼å¼ï¼ˆçµæ§‹åŒ– JSONï¼‰

```json
{
  "timestamp": "2026-01-26T10:30:45.123Z",
  "level": "ERROR",
  "logger": "com.bank.payment.PaymentService",
  "thread": "http-nio-8080-exec-15",
  "traceId": "abc123def456",
  "spanId": "789xyz",
  "service": "payment-service",
  "environment": "prod",
  "message": "Payment processing failed",
  "context": {
    "userId": "USR-78901",
    "transactionId": "TXN-20260126-001234",
    "amount": 50000,
    "currency": "TWD",
    "cardLast4": "****",
    "errorCode": "GATEWAY_TIMEOUT",
    "errorMessage": "Connection timeout after 30s"
  },
  "exception": {
    "class": "java.net.SocketTimeoutException",
    "message": "Read timed out",
    "stackTrace": "..."
  }
}
```

ğŸ’¡ **å¯¦æˆ°å»ºè­°**ï¼š

1. **å¿…å‚™æ¬„ä½**ï¼štimestamp, level, traceId, service, message
2. **æ•æ„Ÿè³‡æ–™é®è”½**ï¼šå¡è™Ÿã€èº«åˆ†è­‰ã€å¯†ç¢¼ç­‰ä¸€å¾‹é®è”½
3. **ä½¿ç”¨ MDC**ï¼šåˆ©ç”¨ Mapped Diagnostic Context è‡ªå‹•æ³¨å…¥ traceId
4. **é¿å… Log æ¨¡æ¿è®Šæ•¸**ï¼š`log.info("User {} login", userId)` å„ªæ–¼å­—ä¸²ä¸²æ¥

---

### 2.2 Logstash Pipeline è¨­è¨ˆåŸå‰‡

#### Pipeline æ¶æ§‹æ¦‚å¿µ

```mermaid
graph LR
    subgraph "Logstash Pipeline"
        I[Input<br/>è¼¸å…¥] --> F[Filter<br/>éæ¿¾/è½‰æ›]
        F --> O[Output<br/>è¼¸å‡º]
    end
    
    subgraph "Input ä¾†æº"
        I1[Beats] --> I
        I2[Kafka] --> I
        I3[File] --> I
        I4[TCP/UDP] --> I
    end
    
    subgraph "Output ç›®æ¨™"
        O --> O1[Elasticsearch]
        O --> O2[Kafka]
        O --> O3[File]
        O --> O4[Alerting]
    end
```

#### Pipeline è¨­è¨ˆåŸå‰‡

| åŸå‰‡ | èªªæ˜ | ç¯„ä¾‹ |
|------|------|------|
| **å–®ä¸€è·è²¬** | æ¯å€‹ Pipeline è™•ç†ä¸€ç¨® Log é¡å‹ | app-logs.conf, nginx-logs.conf |
| **è§£è€¦è¼¸å…¥è¼¸å‡º** | ä½¿ç”¨ Kafka ä½œç‚ºç·©è¡ï¼Œè§£è€¦ç”Ÿç”¢èˆ‡æ¶ˆè²» | Input: Kafka â†’ Output: ES |
| **å¤±æ•—è™•ç†** | å®šç¾© Dead Letter Queue | ç„¡æ³•è§£æçš„é€åˆ° DLQ |
| **æ•ˆèƒ½å„ªå…ˆ** | å–„ç”¨ Workerã€Batchã€Pipeline ä¸¦è¡Œ | workers: 4, batch_size: 1000 |

#### åŸºæœ¬ Pipeline ç¯„ä¾‹

```ruby
# /etc/logstash/conf.d/application-logs.conf

input {
  kafka {
    bootstrap_servers => "kafka-1:9092,kafka-2:9092,kafka-3:9092"
    topics => ["app-logs"]
    group_id => "logstash-app-logs"
    consumer_threads => 3
    codec => json
    decorate_events => true
  }
}

filter {
  # è§£æ JSONï¼ˆå¦‚æœé‚„ä¸æ˜¯ï¼‰
  if [message] =~ /^\{/ {
    json {
      source => "message"
      target => "parsed"
    }
    mutate {
      rename => { "[parsed][timestamp]" => "@timestamp" }
      rename => { "[parsed][level]" => "level" }
      rename => { "[parsed][service]" => "service" }
      rename => { "[parsed][traceId]" => "traceId" }
    }
  }
  
  # æ•æ„Ÿè³‡æ–™é®è”½
  mutate {
    gsub => [
      "[parsed][context][email]", "(?<=.{3}).(?=.*@)", "*",
      "[parsed][context][phone]", "(?<=.{4}).(?=.{4})", "*"
    ]
  }
  
  # æ·»åŠ è™•ç†æ™‚é–“æˆ³
  ruby {
    code => "event.set('processed_at', Time.now.utc.iso8601(3))"
  }
  
  # ç§»é™¤ä¸éœ€è¦çš„æ¬„ä½
  mutate {
    remove_field => ["message", "@version", "host"]
  }
}

output {
  elasticsearch {
    hosts => ["es-1:9200", "es-2:9200", "es-3:9200"]
    index => "app-logs-%{[service]}-%{+YYYY.MM.dd}"
    user => "${ES_USER}"
    password => "${ES_PASSWORD}"
    ssl => true
    cacert => "/etc/logstash/certs/ca.crt"
  }
  
  # Dead Letter Queue for failed events
  if "_jsonparsefailure" in [tags] or "_grokparsefailure" in [tags] {
    elasticsearch {
      hosts => ["es-1:9200"]
      index => "dlq-app-logs-%{+YYYY.MM.dd}"
    }
  }
}
```

âš ï¸ **å¸¸è¦‹éŒ¯èª¤**ï¼š

1. **æ²’æœ‰ DLQ**ï¼šè§£æå¤±æ•—çš„ Log ç›´æ¥ä¸Ÿå¤±
2. **å–®ä¸€ Pipeline è™•ç†æ‰€æœ‰ Log**ï¼šé›£ä»¥ç¶­è­·ã€æ•ˆèƒ½å·®
3. **æ²’æœ‰ä½¿ç”¨ Kafka ç·©è¡**ï¼šLogstash é‡å•Ÿæˆ– ES å£“åŠ›å¤§æ™‚æœƒä¸Ÿ Log

---

### 2.3 Elasticsearch Index / Shard / Replica è¨­è¨ˆ

#### Index å‘½åç­–ç•¥

```text
ç´¢å¼•å‘½åè¦å‰‡ï¼š{é¡å‹}-{æœå‹™}-{æ—¥æœŸ}

ç¯„ä¾‹ï¼š
â”œâ”€â”€ app-logs-payment-service-2026.01.26
â”œâ”€â”€ app-logs-user-service-2026.01.26
â”œâ”€â”€ access-logs-nginx-2026.01.26
â”œâ”€â”€ audit-logs-all-2026.01
â””â”€â”€ security-logs-waf-2026.01.26
```

#### Shard èˆ‡ Replica è¨­è¨ˆ

```mermaid
graph TB
    subgraph "Index: app-logs-payment-2026.01.26"
        subgraph "Primary Shards"
            P0[Shard 0<br/>Primary]
            P1[Shard 1<br/>Primary]
            P2[Shard 2<br/>Primary]
        end
        subgraph "Replica Shards"
            R0[Shard 0<br/>Replica]
            R1[Shard 1<br/>Replica]
            R2[Shard 2<br/>Replica]
        end
    end
    
    P0 -.-> R0
    P1 -.-> R1
    P2 -.-> R2
```

#### Shard æ•¸é‡è¨­è¨ˆæŒ‡å—

| å–®ä¸€ Shard å»ºè­°å¤§å° | æƒ…å¢ƒ |
|---------------------|------|
| 10-30 GB | æ™‚åºè³‡æ–™ï¼ˆLogsï¼‰ |
| 30-50 GB | æœå°‹å°å‘è³‡æ–™ |

**è¨ˆç®—ç¯„ä¾‹**ï¼š

```text
æ¯æ—¥ Log é‡ï¼š100 GB
å»ºè­° Shard æ•¸ï¼š100 GB Ã· 25 GB = 4 Primary Shards
Replicaï¼š1ï¼ˆç”Ÿç”¢ç’°å¢ƒè‡³å°‘ 1ï¼‰
ç¸½ Shard æ•¸ï¼š4 Ã— 2 = 8 Shards
```

#### Index Template è¨­è¨ˆ

```json
PUT _index_template/app-logs-template
{
  "index_patterns": ["app-logs-*"],
  "priority": 100,
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "refresh_interval": "5s",
      "index.lifecycle.name": "logs-policy",
      "index.lifecycle.rollover_alias": "app-logs"
    },
    "mappings": {
      "dynamic": "strict",
      "properties": {
        "@timestamp": { "type": "date" },
        "level": { "type": "keyword" },
        "service": { "type": "keyword" },
        "traceId": { "type": "keyword" },
        "message": { "type": "text" },
        "context": {
          "type": "object",
          "dynamic": true
        },
        "exception": {
          "properties": {
            "class": { "type": "keyword" },
            "message": { "type": "text" },
            "stackTrace": { "type": "text", "index": false }
          }
        }
      }
    }
  }
}
```

ğŸ’¡ **å¯¦æˆ°å»ºè­°**ï¼š

1. **ä½¿ç”¨ Index Lifecycle Managementï¼ˆILMï¼‰**ï¼šè‡ªå‹•ç®¡ç† Hot/Warm/Cold/Delete
2. **é¿å…å‹•æ…‹ Mapping**ï¼šä½¿ç”¨ `"dynamic": "strict"` é˜²æ­¢ Mapping çˆ†ç‚¸
3. **Keyword vs Text**ï¼šç”¨æ–¼éæ¿¾çš„æ¬„ä½ç”¨ keywordï¼Œå…¨æ–‡æœå°‹ç”¨ text

---

### 2.4 Kibana åœ¨è¦–è¦ºåŒ–èˆ‡åˆ†æä¸Šçš„è§’è‰²

#### Kibana æ ¸å¿ƒåŠŸèƒ½å®šä½

```mermaid
graph TB
    subgraph "Kibana åŠŸèƒ½å±¤"
        D[Discover<br/>å³æ™‚æœå°‹]
        V[Visualize / Lens<br/>åœ–è¡¨å»ºç«‹]
        DB[Dashboard<br/>å„€è¡¨æ¿]
        A[Alerting<br/>å‘Šè­¦]
        M[Management<br/>ç®¡ç†]
    end
    
    subgraph "ä½¿ç”¨è€…è§’è‰²"
        DEV[é–‹ç™¼äººå“¡] --> D
        OPS[ç¶­é‹äººå“¡] --> DB
        OPS --> A
        MGR[ç®¡ç†å±¤] --> DB
        ADMIN[ç®¡ç†å“¡] --> M
    end
```

#### å„åŠŸèƒ½ä½¿ç”¨å ´æ™¯

| åŠŸèƒ½ | ä¸»è¦ç”¨é€” | é©ç”¨è§’è‰² | ä½¿ç”¨é »ç‡ |
|------|---------|---------|---------|
| **Discover** | å³æ™‚ Log æœå°‹ã€é™¤éŒ¯ | é–‹ç™¼ã€ç¶­é‹ | é«˜ |
| **Lens/Visualize** | å»ºç«‹åœ–è¡¨å…ƒä»¶ | ç¶­é‹ã€åˆ†æå¸« | ä¸­ |
| **Dashboard** | æ•´åˆè¦–åœ–ã€ç›£æ§ç‰† | å…¨é«” | é«˜ |
| **Alerting** | ç•°å¸¸å‘Šè­¦ã€é€šçŸ¥ | ç¶­é‹ã€SRE | æŒçºŒ |
| **Dev Tools** | Query æ¸¬è©¦ã€é™¤éŒ¯ | é–‹ç™¼ã€ç¶­é‹ | ä¸­ |

âš ï¸ **å¸¸è¦‹éŒ¯èª¤**ï¼š

1. **æŠŠ Kibana ç•¶æˆå”¯ä¸€ç›£æ§å·¥å…·**ï¼šKibana é©åˆæ·±åº¦åˆ†æï¼Œå³æ™‚ç›£æ§æ‡‰æ­é… Grafana
2. **Dashboard éåº¦è¤‡é›œ**ï¼šå–®ä¸€ Dashboard å¡å¤ªå¤šåœ–è¡¨ï¼Œåè€Œçœ‹ä¸åˆ°é‡é»
3. **æ²’æœ‰è¨­å®š RBAC**ï¼šæ‰€æœ‰äººéƒ½èƒ½çœ‹åˆ°æ‰€æœ‰ Logï¼Œé€ æˆè³‡å®‰é¢¨éšª

---

## 3. Logstash æ·±åº¦å¯¦å‹™

### 3.1 Pipeline æ¶æ§‹è¨­è¨ˆï¼ˆInput / Filter / Outputï¼‰

#### å¤š Pipeline æ¶æ§‹

```mermaid
graph TB
    subgraph "Pipeline æ¶æ§‹"
        subgraph "Input Pipelines"
            IP1[pipeline-input-app.conf]
            IP2[pipeline-input-nginx.conf]
            IP3[pipeline-input-security.conf]
        end
        
        subgraph "Processing Pipelines"
            PP1[pipeline-process-app.conf]
            PP2[pipeline-process-access.conf]
            PP3[pipeline-process-security.conf]
        end
        
        subgraph "Output Pipelines"
            OP1[pipeline-output-es.conf]
            OP2[pipeline-output-kafka.conf]
        end
    end
    
    IP1 -->|pipeline-to-pipeline| PP1
    IP2 -->|pipeline-to-pipeline| PP2
    IP3 -->|pipeline-to-pipeline| PP3
    PP1 --> OP1
    PP2 --> OP1
    PP3 --> OP1
    PP3 --> OP2
```

#### pipelines.yml é…ç½®

```yaml
# /etc/logstash/pipelines.yml

# Application Logs Pipeline
- pipeline.id: app-logs
  path.config: "/etc/logstash/conf.d/app-logs.conf"
  pipeline.workers: 4
  pipeline.batch.size: 1000
  pipeline.batch.delay: 50
  queue.type: persisted
  queue.max_bytes: 4gb

# Access Logs Pipeline
- pipeline.id: access-logs
  path.config: "/etc/logstash/conf.d/access-logs.conf"
  pipeline.workers: 2
  pipeline.batch.size: 2000

# Security Logs Pipelineï¼ˆé«˜å„ªå…ˆç´šï¼‰
- pipeline.id: security-logs
  path.config: "/etc/logstash/conf.d/security-logs.conf"
  pipeline.workers: 2
  pipeline.batch.size: 500
  queue.type: persisted
```

#### Input è¨­è¨ˆè€ƒé‡

| Input Type | é©ç”¨å ´æ™¯ | å„ªé» | ç¼ºé» |
|------------|---------|------|------|
| **Beats** | è¼•é‡æ¡é›† | è³‡æºä½”ç”¨ä½ | åŠŸèƒ½æœ‰é™ |
| **Kafka** | é«˜æµé‡ã€è§£è€¦ | ç·©è¡ã€é‡æ’­ | éœ€ç¶­è­· Kafka |
| **File** | æª”æ¡ˆå‹ Log | ç°¡å–® | ä¸é©åˆå¤§é‡ |
| **TCP/UDP** | Syslog | æ¨™æº–å”å®š | å¯èƒ½ä¸Ÿå¤± |
| **HTTP** | Webhookã€API | éˆæ´» | éœ€è™•ç†èªè­‰ |

---

### 3.2 Grok / JSON / Mutate å¯¦å‹™æŠ€å·§

#### Grok Pattern å¯¦å‹™

#### Nginx Access Log è§£æ

```ruby
filter {
  grok {
    match => {
      "message" => '%{IPORHOST:client_ip} - %{DATA:user} \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:http_version}" %{NUMBER:status:int} %{NUMBER:bytes:int} "%{DATA:referrer}" "%{DATA:user_agent}" %{NUMBER:request_time:float}'
    }
    tag_on_failure => ["_grokparsefailure_nginx"]
  }
  
  # è§£ææ™‚é–“æˆ³
  date {
    match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
    target => "@timestamp"
    remove_field => ["timestamp"]
  }
  
  # GeoIP è§£æ
  geoip {
    source => "client_ip"
    target => "geo"
    fields => ["country_name", "city_name", "location"]
  }
  
  # User-Agent è§£æ
  useragent {
    source => "user_agent"
    target => "ua"
  }
}
```

#### è‡ªè¨‚ Grok Pattern

```ruby
# /etc/logstash/patterns/custom

# éŠ€è¡Œäº¤æ˜“æ ¼å¼
BANK_TXN_ID TXN-%{YEAR}%{MONTHNUM}%{MONTHDAY}-%{NUMBER:6}
BANK_ACCOUNT [0-9]{3}-[0-9]{2}-[0-9]{7}-[0-9]
MASKED_CARD \*{12}[0-9]{4}

# ä½¿ç”¨ç¯„ä¾‹
filter {
  grok {
    patterns_dir => ["/etc/logstash/patterns"]
    match => {
      "message" => "%{BANK_TXN_ID:txn_id} %{BANK_ACCOUNT:account} %{MASKED_CARD:card}"
    }
  }
}
```

#### JSON è™•ç†æŠ€å·§

```ruby
filter {
  # è§£æ JSON
  json {
    source => "message"
    target => "data"
    skip_on_invalid_json => true
    tag_on_failure => ["_jsonparsefailure"]
  }
  
  # è™•ç†å·¢ç‹€ JSON
  if [data][nested_json] {
    json {
      source => "[data][nested_json]"
      target => "[data][parsed_nested]"
    }
  }
  
  # æ‰å¹³åŒ–ï¼ˆflattenï¼‰
  ruby {
    code => '
      def flatten_hash(hash, parent_key = "", sep = "_")
        hash.each_with_object({}) do |(k, v), h|
          new_key = parent_key.empty? ? k : "#{parent_key}#{sep}#{k}"
          if v.is_a?(Hash)
            h.merge!(flatten_hash(v, new_key, sep))
          else
            h[new_key] = v
          end
        end
      end
      
      if event.get("[data]").is_a?(Hash)
        flattened = flatten_hash(event.get("[data]"))
        event.set("[flat]", flattened)
      end
    '
  }
}
```

#### Mutate å¯¦å‹™æŠ€å·§

```ruby
filter {
  mutate {
    # é‡æ–°å‘½åæ¬„ä½
    rename => {
      "[data][userName]" => "[user][name]"
      "[data][userEmail]" => "[user][email]"
    }
    
    # å‹åˆ¥è½‰æ›
    convert => {
      "[data][amount]" => "float"
      "[data][count]" => "integer"
      "[data][success]" => "boolean"
    }
    
    # å­—ä¸²è™•ç†
    lowercase => ["[user][email]"]
    strip => ["[data][message]"]
    gsub => [
      # é®è”½ä¿¡ç”¨å¡è™Ÿ
      "[data][card_number]", "^(\d{4})\d{8}(\d{4})$", "\1********\2",
      # é®è”½ Email
      "[user][email]", "(?<=.{3}).(?=.*@)", "*"
    ]
    
    # ç§»é™¤æ¬„ä½
    remove_field => ["message", "host", "@version"]
    
    # æ·»åŠ æ¬„ä½
    add_field => {
      "[meta][processed_by]" => "logstash-prod-01"
      "[meta][pipeline_version]" => "2.1.0"
    }
  }
}
```

ğŸ’¡ **å¯¦æˆ°å»ºè­°**ï¼š

1. **Grok æ•ˆèƒ½æ®ºæ‰‹**ï¼šè¤‡é›œçš„ Grok pattern æœƒåš´é‡å½±éŸ¿æ•ˆèƒ½ï¼Œå„ªå…ˆä½¿ç”¨ JSON æ ¼å¼
2. **æ¸¬è©¦ Grok**ï¼šä½¿ç”¨ Kibana Dev Tools çš„ Grok Debugger æ¸¬è©¦
3. **é¿å…éåº¦è™•ç†**ï¼šä¸æ˜¯æ‰€æœ‰æ¬„ä½éƒ½éœ€è¦è§£æï¼Œåªè™•ç†æœƒæŸ¥è©¢çš„æ¬„ä½

---

### 3.3 æ•ˆèƒ½èª¿æ ¡èˆ‡å¸¸è¦‹ç“¶é ¸

#### æ•ˆèƒ½åƒæ•¸èª¿æ ¡

```yaml
# /etc/logstash/logstash.yml

# Worker æ•¸é‡ï¼ˆå»ºè­° = CPU æ ¸å¿ƒæ•¸ï¼‰
pipeline.workers: 8

# Batch è¨­å®š
pipeline.batch.size: 1000
pipeline.batch.delay: 50

# è¨˜æ†¶é«”è¨­å®š
# /etc/logstash/jvm.options
-Xms4g
-Xmx4g

# æŒä¹…åŒ– Queueï¼ˆé˜²æ­¢è³‡æ–™ä¸Ÿå¤±ï¼‰
queue.type: persisted
queue.max_bytes: 8gb
queue.checkpoint.writes: 1024
```

#### å¸¸è¦‹ç“¶é ¸èˆ‡è§£æ³•

| ç“¶é ¸ | ç—‡ç‹€ | è§£æ³• |
|------|------|------|
| **Grok éæ…¢** | CPU ä½¿ç”¨ç‡é«˜ã€ååé‡ä½ | æ”¹ç”¨ JSONã€ç°¡åŒ– Pattern |
| **ES å¯«å…¥æ…¢** | Queue å †ç©ã€èƒŒå£“ | å¢åŠ  ES ç¯€é»ã€èª¿æ•´ Bulk å¤§å° |
| **è¨˜æ†¶é«”ä¸è¶³** | OOMã€é »ç¹ GC | å¢åŠ  Heapã€ä½¿ç”¨æŒä¹…åŒ– Queue |
| **å–®ä¸€ Pipeline ç“¶é ¸** | æŸé¡ Log è™•ç†æ…¢å½±éŸ¿å…¶ä»– | æ‹†åˆ†å¤š Pipeline |
| **ç¶²è·¯ç“¶é ¸** | Beats å‚³è¼¸å»¶é² | ä½¿ç”¨ Kafka ç·©è¡ã€å£“ç¸® |

#### ç›£æ§ Logstash æ•ˆèƒ½

```bash
# æŸ¥çœ‹ Pipeline çµ±è¨ˆ
curl -s localhost:9600/_node/stats/pipelines?pretty

# é—œéµæŒ‡æ¨™
{
  "pipelines": {
    "app-logs": {
      "events": {
        "in": 1000000,           # è¼¸å…¥äº‹ä»¶æ•¸
        "filtered": 1000000,     # éæ¿¾å¾Œäº‹ä»¶æ•¸
        "out": 999500,           # è¼¸å‡ºäº‹ä»¶æ•¸
        "duration_in_millis": 60000,
        "queue_push_duration_in_millis": 5000
      },
      "queue": {
        "events_count": 500,     # Queue ä¸­ç­‰å¾…çš„äº‹ä»¶
        "max_queue_size_in_bytes": 8589934592
      }
    }
  }
}
```

---

### 3.4 å¤šä¾†æº Logï¼ˆApp / DB / MQ / Batchï¼‰

#### å¤šä¾†æºæ•´åˆæ¶æ§‹

```mermaid
graph TB
    subgraph "Log ä¾†æº"
        APP[Application<br/>Spring Boot / .NET]
        DB[Database<br/>Oracle / PostgreSQL]
        MQ[Message Queue<br/>Kafka / RabbitMQ]
        BATCH[Batch Jobs<br/>Spring Batch]
        NGINX[Web Server<br/>Nginx / Apache]
    end
    
    subgraph "æ¡é›†å±¤"
        FB[Filebeat]
        MB[Metricbeat]
        KB[Kafka Connect]
    end
    
    subgraph "ç·©è¡å±¤"
        KAFKA[Kafka Cluster]
    end
    
    subgraph "è™•ç†å±¤"
        LS[Logstash<br/>å¤š Pipeline]
    end
    
    APP -->|JSON| FB
    NGINX -->|File| FB
    DB -->|JDBC| MB
    MQ -->|Native| KB
    BATCH -->|JSON| FB
    
    FB --> KAFKA
    MB --> KAFKA
    KB --> KAFKA
    KAFKA --> LS
```

#### å„ä¾†æº Log è™•ç†ç¯„ä¾‹

#### Oracle æ…¢æŸ¥è©¢ Log

```ruby
# oracle-slow-query.conf
input {
  jdbc {
    jdbc_driver_library => "/opt/oracle/ojdbc8.jar"
    jdbc_driver_class => "Java::oracle.jdbc.OracleDriver"
    jdbc_connection_string => "jdbc:oracle:thin:@//db-host:1521/ORCL"
    jdbc_user => "${ORACLE_USER}"
    jdbc_password => "${ORACLE_PASSWORD}"
    schedule => "*/5 * * * *"
    statement => "
      SELECT 
        sql_id,
        sql_text,
        elapsed_time/1000000 as elapsed_seconds,
        executions,
        buffer_gets,
        disk_reads,
        TO_CHAR(last_active_time, 'YYYY-MM-DD HH24:MI:SS') as last_active_time
      FROM v$sql 
      WHERE elapsed_time/1000000 > 5
      AND last_active_time > SYSDATE - 1/24
    "
    tracking_column => "last_active_time"
    use_column_value => true
  }
}

filter {
  mutate {
    add_field => { "log_type" => "oracle_slow_query" }
    add_field => { "database" => "ORCL" }
  }
}
```

#### Kafka Consumer Lag ç›£æ§

```ruby
# kafka-consumer-lag.conf
input {
  exec {
    command => "/opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --describe --all-groups 2>/dev/null | grep -v CONSUMER-ID"
    interval => 60
    codec => plain
  }
}

filter {
  split { field => "message" }
  
  grok {
    match => {
      "message" => "%{NOTSPACE:consumer_group}\s+%{NOTSPACE:topic}\s+%{NUMBER:partition:int}\s+%{NUMBER:current_offset:int}\s+%{NUMBER:log_end_offset:int}\s+%{NUMBER:lag:int}\s+%{NOTSPACE:consumer_id}\s+%{NOTSPACE:host}\s+%{NOTSPACE:client_id}"
    }
  }
  
  mutate {
    add_field => { "log_type" => "kafka_consumer_lag" }
  }
  
  # Lag è¶…éé–¾å€¼æ¨™è¨˜
  if [lag] > 10000 {
    mutate {
      add_tag => ["high_lag"]
      add_field => { "alert_level" => "warning" }
    }
  }
}
```

âš ï¸ **å¸¸è¦‹éŒ¯èª¤**ï¼š

1. **æ²’æœ‰çµ±ä¸€æ™‚é–“æˆ³æ ¼å¼**ï¼šä¸åŒä¾†æºçš„æ™‚é–“æ ¼å¼ä¸ä¸€è‡´ï¼Œé›£ä»¥é—œè¯åˆ†æ
2. **ç¼ºå°‘ Log Type æ¨™è¨˜**ï¼šæ··åœ¨ä¸€èµ·çš„ Log é›£ä»¥å€åˆ†ä¾†æº
3. **å¿½ç•¥æ™‚å€å•é¡Œ**ï¼šå°¤å…¶è·¨åœ‹ç³»çµ±ï¼Œå‹™å¿…çµ±ä¸€ä½¿ç”¨ UTC

---

## 4. Elasticsearch æ¶æ§‹èˆ‡æ•ˆèƒ½è¨­è¨ˆ

### 4.1 Index è¨­è¨ˆç­–ç•¥

#### æ™‚åºè³‡æ–™ Index ç­–ç•¥

```mermaid
graph LR
    subgraph "Index ç”Ÿå‘½é€±æœŸ"
        H[Hot<br/>ç•¶æ—¥è³‡æ–™<br/>SSD + é«˜é‹ç®—]
        W[Warm<br/>è¿‘æœŸè³‡æ–™<br/>SSD + ä¸­é‹ç®—]
        C[Cold<br/>æ­·å²è³‡æ–™<br/>HDD + ä½é‹ç®—]
        D[Delete<br/>éæœŸåˆªé™¤]
    end
    
    H -->|1å¤©å¾Œ| W
    W -->|7å¤©å¾Œ| C
    C -->|90å¤©å¾Œ| D
```

#### Index å‘½åè¦ç¯„

```text
æ ¼å¼ï¼š{ç’°å¢ƒ}-{é¡å‹}-{æœå‹™}-{æ™‚é–“ç²’åº¦}

ç¯„ä¾‹ï¼š
â”œâ”€â”€ prod-app-logs-payment-service-2026.01.26    # æ¯æ—¥
â”œâ”€â”€ prod-app-logs-user-service-2026.01.26       # æ¯æ—¥
â”œâ”€â”€ prod-audit-logs-all-2026.01                 # æ¯æœˆï¼ˆç¨½æ ¸éœ€é•·æœŸä¿ç•™ï¼‰
â”œâ”€â”€ prod-metrics-system-2026.01.26              # æ¯æ—¥
â””â”€â”€ prod-security-logs-waf-2026.01.26           # æ¯æ—¥
```

#### Index Lifecycle Management (ILM) è¨­è¨ˆ

```json
PUT _ilm/policy/logs-lifecycle-policy
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_age": "1d",
            "max_size": "30gb",
            "max_docs": 10000000
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "1d",
        "actions": {
          "shrink": {
            "number_of_shards": 1
          },
          "forcemerge": {
            "max_num_segments": 1
          },
          "set_priority": {
            "priority": 50
          },
          "allocate": {
            "require": {
              "data": "warm"
            }
          }
        }
      },
      "cold": {
        "min_age": "7d",
        "actions": {
          "set_priority": {
            "priority": 0
          },
          "allocate": {
            "require": {
              "data": "cold"
            }
          },
          "freeze": {}
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

---

### 4.2 Mapping èˆ‡æ•ˆèƒ½å½±éŸ¿

#### Mapping è¨­è¨ˆåŸå‰‡

| è³‡æ–™é¡å‹ | ES Type | é©ç”¨å ´æ™¯ | æ•ˆèƒ½å½±éŸ¿ |
|---------|---------|---------|---------|
| ç²¾ç¢ºåŒ¹é… | `keyword` | status, level, traceId | ä½ï¼Œé©åˆèšåˆ |
| å…¨æ–‡æœå°‹ | `text` | message, description | é«˜ï¼Œå»ºç«‹å€’æ’ç´¢å¼• |
| æ™‚é–“ | `date` | @timestamp | ä½ï¼Œç¯„åœæŸ¥è©¢é«˜æ•ˆ |
| æ•¸å€¼ | `long/double` | amount, count | ä½ |
| å¸ƒæ— | `boolean` | success, enabled | æ¥µä½ |
| ä¸ç´¢å¼• | `enabled: false` | stackTraceï¼ˆåªå­˜ä¸æŸ¥ï¼‰ | ç„¡ |

#### æœ€ä½³åŒ– Mapping ç¯„ä¾‹

```json
PUT _index_template/optimized-logs-template
{
  "index_patterns": ["prod-app-logs-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "index.mapping.total_fields.limit": 500,
      "index.mapping.depth.limit": 5,
      "index.mapping.nested_fields.limit": 20
    },
    "mappings": {
      "dynamic": "strict",
      "_source": {
        "enabled": true,
        "excludes": ["stackTrace"]
      },
      "properties": {
        "@timestamp": {
          "type": "date",
          "format": "strict_date_optional_time||epoch_millis"
        },
        "level": {
          "type": "keyword",
          "ignore_above": 16
        },
        "service": {
          "type": "keyword",
          "ignore_above": 64
        },
        "traceId": {
          "type": "keyword",
          "ignore_above": 64
        },
        "message": {
          "type": "text",
          "analyzer": "standard",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "context": {
          "type": "object",
          "dynamic": true
        },
        "exception": {
          "properties": {
            "class": { "type": "keyword" },
            "message": { "type": "text" },
            "stackTrace": {
              "type": "text",
              "index": false,
              "doc_values": false
            }
          }
        }
      }
    }
  }
}
```

âš ï¸ **Mapping å¸¸è¦‹éŒ¯èª¤**ï¼š

1. **Mapping Explosion**ï¼šå‹•æ…‹ Mapping å°è‡´æ¬„ä½æ•¸çˆ†ç‚¸
2. **Text éåº¦ä½¿ç”¨**ï¼šæ‰€æœ‰å­—ä¸²éƒ½ç”¨ textï¼Œæµªè²»è³‡æº
3. **æ²’æœ‰ ignore_above**ï¼šé•·å­—ä¸²è¶…éé™åˆ¶å°è‡´éŒ¯èª¤
4. **å·¢ç‹€éæ·±**ï¼šè¶…é 5 å±¤çš„å·¢ç‹€çµæ§‹æ•ˆèƒ½å·®

---

### 4.3 Hot / Warm / Cold æ¶æ§‹

#### ç¯€é»è§’è‰²è¨­è¨ˆ

```mermaid
graph TB
    subgraph "Elasticsearch Cluster"
        subgraph "Hot Nodes (SSD)"
            H1[hot-node-1<br/>32GB RAM<br/>16 CPU]
            H2[hot-node-2<br/>32GB RAM<br/>16 CPU]
            H3[hot-node-3<br/>32GB RAM<br/>16 CPU]
        end
        
        subgraph "Warm Nodes (SSD)"
            W1[warm-node-1<br/>64GB RAM<br/>8 CPU]
            W2[warm-node-2<br/>64GB RAM<br/>8 CPU]
        end
        
        subgraph "Cold Nodes (HDD)"
            C1[cold-node-1<br/>96GB RAM<br/>4 CPU]
            C2[cold-node-2<br/>96GB RAM<br/>4 CPU]
        end
        
        subgraph "Master Nodes"
            M1[master-1]
            M2[master-2]
            M3[master-3]
        end
    end
```

#### ç¯€é»é…ç½®

```yaml
# Hot Node é…ç½®
# elasticsearch.yml
node.name: hot-node-1
node.roles: [data_hot, data_content]
node.attr.data: hot
path.data: /ssd/elasticsearch/data

# Warm Node é…ç½®
node.name: warm-node-1
node.roles: [data_warm]
node.attr.data: warm
path.data: /ssd/elasticsearch/data

# Cold Node é…ç½®
node.name: cold-node-1
node.roles: [data_cold, data_frozen]
node.attr.data: cold
path.data: /hdd/elasticsearch/data

# Master Node é…ç½®
node.name: master-1
node.roles: [master]
```

#### ç¡¬é«”è¦åŠƒæŒ‡å—

| ç¯€é»é¡å‹ | CPU | RAM | å„²å­˜ | ç¶²è·¯ |
|---------|-----|-----|------|------|
| **Hot** | é«˜ï¼ˆ16+ coresï¼‰ | 32-64 GB | NVMe SSD | 10 Gbps |
| **Warm** | ä¸­ï¼ˆ8 coresï¼‰ | 64-128 GB | SSD | 10 Gbps |
| **Cold** | ä½ï¼ˆ4 coresï¼‰ | 64-128 GB | HDD | 1 Gbps |
| **Master** | ä¸­ï¼ˆ4 coresï¼‰ | 16-32 GB | SSDï¼ˆå°å®¹é‡ï¼‰ | 10 Gbps |

ğŸ’¡ **å¯¦æˆ°å»ºè­°**ï¼š

1. **RAM èˆ‡ Heap**ï¼šHeap è¨­ç‚º RAM çš„ 50%ï¼Œæœ€å¤§ä¸è¶…é 31 GB
2. **å„²å­˜è¨ˆç®—**ï¼šHot ç¯€é»è³‡æ–™é‡ = æ¯æ—¥å¯«å…¥é‡ Ã— Hot å¤©æ•¸ Ã— 1.2ï¼ˆoverheadï¼‰
3. **æœ€å°‘ç¯€é»æ•¸**ï¼šç”Ÿç”¢ç’°å¢ƒè‡³å°‘ 3 å€‹ Masterã€3 å€‹ Hotã€2 å€‹ Warm

---

### 4.4 æŸ¥è©¢æ•ˆèƒ½èˆ‡è³‡æºè¦åŠƒ

#### æŸ¥è©¢æ•ˆèƒ½æœ€ä½³åŒ–

#### é«˜æ•ˆæŸ¥è©¢ç¯„ä¾‹

```json
// âœ… å¥½çš„æŸ¥è©¢ï¼šä½¿ç”¨ filter contextï¼ˆå¯å¿«å–ï¼‰
GET app-logs-*/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "level": "ERROR" } },
        { "term": { "service": "payment-service" } },
        { "range": { "@timestamp": { "gte": "now-1h" } } }
      ],
      "must": [
        { "match": { "message": "timeout" } }
      ]
    }
  },
  "size": 100,
  "_source": ["@timestamp", "level", "service", "message", "traceId"],
  "sort": [{ "@timestamp": "desc" }]
}

// âŒ ä¸å¥½çš„æŸ¥è©¢ï¼šwildcard é–‹é ­ã€æœªé™åˆ¶æ™‚é–“ç¯„åœ
GET app-logs-*/_search
{
  "query": {
    "wildcard": { "message": "*timeout*" }
  }
}
```

#### èšåˆæŸ¥è©¢æœ€ä½³åŒ–

```json
// éŒ¯èª¤ç‡çµ±è¨ˆï¼ˆæŒ‰æœå‹™ã€æ¯å°æ™‚ï¼‰
GET app-logs-*/_search
{
  "size": 0,
  "query": {
    "bool": {
      "filter": [
        { "range": { "@timestamp": { "gte": "now-24h" } } }
      ]
    }
  },
  "aggs": {
    "by_service": {
      "terms": {
        "field": "service",
        "size": 20
      },
      "aggs": {
        "by_hour": {
          "date_histogram": {
            "field": "@timestamp",
            "calendar_interval": "hour"
          },
          "aggs": {
            "error_count": {
              "filter": { "term": { "level": "ERROR" } }
            },
            "total_count": {
              "value_count": { "field": "_id" }
            },
            "error_rate": {
              "bucket_script": {
                "buckets_path": {
                  "errors": "error_count._count",
                  "total": "total_count"
                },
                "script": "params.total > 0 ? params.errors / params.total * 100 : 0"
              }
            }
          }
        }
      }
    }
  }
}
```

#### è³‡æºè¦åŠƒè¨ˆç®—

#### å®¹é‡è¦åŠƒå…¬å¼

```text
æ—¥å¯«å…¥é‡ï¼ˆåŸå§‹ï¼‰ï¼šR GB/day
å£“ç¸®æ¯”ï¼šç´„ 10:1ï¼ˆJSON Logï¼‰
ç´¢å¼• Overheadï¼šç´„ 1.5x

æ¯æ—¥å„²å­˜éœ€æ±‚ = R Ã— 0.1 Ã— 1.5 = R Ã— 0.15 GB

ç¯„ä¾‹ï¼š
- æ¯æ—¥åŸå§‹ Logï¼š1 TB
- å£“ç¸®å¾Œï¼š100 GB
- å«ç´¢å¼•ï¼š150 GB
- ä¿ç•™ 90 å¤©ï¼š150 Ã— 90 = 13.5 TB
- å« Replicaï¼š13.5 Ã— 2 = 27 TB
```

---

## 5. Kibana è¦–è¦ºåŒ–èˆ‡åˆ†æè¨­è¨ˆ

### 5.1 Dashboard è¨­è¨ˆåŸå‰‡ï¼ˆçµ¦èª°çœ‹ï¼Ÿçœ‹ä»€éº¼ï¼Ÿï¼‰

#### Dashboard åˆ†å±¤è¨­è¨ˆ

```mermaid
graph TB
    subgraph "Dashboard å±¤ç´š"
        L1[Level 1: ç®¡ç†å±¤ Dashboard<br/>é«˜éš KPIã€è¶¨å‹¢ã€å¥åº·ç‹€æ…‹]
        L2[Level 2: ç¶­é‹åœ˜éšŠ Dashboard<br/>å³æ™‚ç›£æ§ã€å‘Šè­¦ã€æœå‹™ç‹€æ…‹]
        L3[Level 3: é–‹ç™¼åœ˜éšŠ Dashboard<br/>éŒ¯èª¤åˆ†æã€æ•ˆèƒ½è¿½è¹¤ã€é™¤éŒ¯]
    end
    
    L1 --> L2
    L2 --> L3
```

#### å„è§’è‰² Dashboard è¨­è¨ˆ

| è§’è‰² | é—œæ³¨é‡é» | æ›´æ–°é »ç‡ | è¤‡é›œåº¦ |
|------|---------|---------|--------|
| **ç®¡ç†å±¤** | å¯ç”¨æ€§ã€SLAã€è¶¨å‹¢ | æ¯å°æ™‚/æ¯æ—¥ | ç°¡å–® |
| **ç¶­é‹/SRE** | å³æ™‚ç‹€æ…‹ã€å‘Šè­¦ã€è³‡æº | å³æ™‚ï¼ˆ5s-1minï¼‰ | ä¸­ç­‰ |
| **é–‹ç™¼åœ˜éšŠ** | éŒ¯èª¤ç´°ç¯€ã€Traceã€é™¤éŒ¯ | å³æ™‚ | è¤‡é›œ |
| **è³‡å®‰åœ˜éšŠ** | ç•°å¸¸å­˜å–ã€æ”»æ“Šåµæ¸¬ | å³æ™‚ | ä¸­ç­‰ |

#### Dashboard è¨­è¨ˆæœ€ä½³å¯¦å‹™

```text
âœ… å¥½çš„ Dashboardï¼š
â”œâ”€â”€ æ¸…æ¥šçš„æ¨™é¡Œèˆ‡èªªæ˜
â”œâ”€â”€ å¾é«˜éšåˆ°ç´°ç¯€çš„è³‡è¨Šæµ
â”œâ”€â”€ ä¸€è‡´çš„é¡è‰²ç·¨ç¢¼ï¼ˆç´…=éŒ¯èª¤ã€é»ƒ=è­¦å‘Šã€ç¶ =æ­£å¸¸ï¼‰
â”œâ”€â”€ åˆç†çš„æ™‚é–“ç¯„åœé è¨­
â”œâ”€â”€ å¯é»æ“Šæ·±å…¥ï¼ˆDrill-downï¼‰
â””â”€â”€ ä¸è¶…é 15 å€‹è¦–è¦ºåŒ–å…ƒä»¶

âŒ ä¸å¥½çš„ Dashboardï¼š
â”œâ”€â”€ å¡æ»¿æ•´å€‹è¢å¹•çš„åœ–è¡¨
â”œâ”€â”€ æ²’æœ‰ä¸Šä¸‹æ–‡çš„æ•¸å­—
â”œâ”€â”€ ä¸ä¸€è‡´çš„æ™‚é–“ç¯„åœ
â”œâ”€â”€ éåº¦è¤‡é›œçš„èšåˆ
â””â”€â”€ æ²’æœ‰æ¨™ç¤ºå–®ä½
```

---

### 5.2 Discoverã€Lensã€Alerting å¯¦å‹™

#### Discover é«˜æ•ˆæœå°‹æŠ€å·§

#### KQLï¼ˆKibana Query Languageï¼‰ç¯„ä¾‹

```text
# åŸºæœ¬æœå°‹
level: ERROR and service: payment-service

# æ™‚é–“ç¯„åœ
@timestamp >= "2026-01-26T00:00:00" and @timestamp < "2026-01-27T00:00:00"

# è¬ç”¨å­—å…ƒ
message: *timeout* and service: payment*

# æ’é™¤
level: ERROR and not service: test-service

# çµ„åˆæ¢ä»¶
(level: ERROR or level: WARN) and service: (payment-service or user-service)

# å­˜åœ¨æ€§æª¢æŸ¥
exception.class: * and level: ERROR

# æ•¸å€¼ç¯„åœ
context.response_time > 1000 and context.response_time <= 5000
```

#### Lucene Query ç¯„ä¾‹ï¼ˆé€²éšï¼‰

```text
# æ­£è¦è¡¨é”å¼
message: /.*Connection refused.*/

# æ¨¡ç³Šæœå°‹ï¼ˆå®¹éŒ¯ 1 å€‹å­—å…ƒï¼‰
message: timout~1

# é„°è¿‘æœå°‹ï¼ˆtimeout å’Œ connection ç›¸è· 5 å€‹å­—ä»¥å…§ï¼‰
message: "timeout connection"~5

# æ¬„ä½å­˜åœ¨
_exists_: exception.stackTrace

# ç¯„åœæŸ¥è©¢
context.amount: [1000 TO 50000]
```

#### Lens è¦–è¦ºåŒ–å»ºç«‹

#### å¸¸ç”¨è¦–è¦ºåŒ–é¡å‹é¸æ“‡

| è³‡æ–™é¡å‹ | æ¨è–¦è¦–è¦ºåŒ– | é©ç”¨å ´æ™¯ |
|---------|-----------|---------|
| æ™‚åºè¨ˆæ•¸ | Line Chart | éŒ¯èª¤ç‡è¶¨å‹¢ã€è«‹æ±‚é‡ |
| åˆ†é¡è¨ˆæ•¸ | Bar Chart (Vertical) | å„æœå‹™éŒ¯èª¤æ•¸ |
| ä½”æ¯” | Pie / Donut | éŒ¯èª¤é¡å‹åˆ†å¸ƒ |
| å–®ä¸€æ•¸å€¼ | Metric | ç¸½éŒ¯èª¤æ•¸ã€å¯ç”¨æ€§ |
| è¡¨æ ¼è³‡æ–™ | Data Table | Top N éŒ¯èª¤ã€æ…¢æŸ¥è©¢ |
| åœ°ç†åˆ†å¸ƒ | Map | è«‹æ±‚ä¾†æºåœ°å€ |
| ç†±åº¦ | Heatmap | æ™‚æ®µ Ã— æœå‹™ éŒ¯èª¤åˆ†å¸ƒ |

#### Alerting è¦å‰‡è¨­è¨ˆ

```json
// Kibana Alerting Rule ç¯„ä¾‹ï¼šéŒ¯èª¤ç‡è¶…æ¨™å‘Šè­¦
{
  "name": "Payment Service High Error Rate",
  "consumer": "alerts",
  "rule_type_id": ".es-query",
  "schedule": { "interval": "1m" },
  "params": {
    "index": ["app-logs-payment-service-*"],
    "timeField": "@timestamp",
    "searchType": "esQuery",
    "esQuery": {
      "query": {
        "bool": {
          "filter": [
            { "term": { "service": "payment-service" } },
            { "term": { "level": "ERROR" } },
            { "range": { "@timestamp": { "gte": "now-5m" } } }
          ]
        }
      }
    },
    "threshold": [50],
    "thresholdComparator": ">"
  },
  "actions": [
    {
      "group": "threshold met",
      "id": "slack-connector-id",
      "params": {
        "message": "ğŸš¨ Payment Service éŒ¯èª¤ç‡éé«˜ï¼\néå» 5 åˆ†é˜éŒ¯èª¤æ•¸ï¼š{{context.value}}\nè«‹ç«‹å³æª¢æŸ¥ï¼š{{context.link}}"
      }
    },
    {
      "group": "threshold met",
      "id": "pagerduty-connector-id",
      "params": {
        "severity": "critical",
        "summary": "Payment Service High Error Rate Alert"
      }
    }
  ]
}
```

---

### 5.3 å¸¸è¦‹ä¼æ¥­ Dashboard ç¯„ä¾‹

#### ç¯„ä¾‹ 1ï¼šæœå‹™å¥åº·ç¸½è¦½ Dashboard

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service Health Overview                    [Last 24 hours â–¼] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ 99.95%   â”‚  â”‚  1.2M    â”‚  â”‚  0.05%   â”‚  â”‚  125ms   â”‚       â”‚
â”‚  â”‚ Uptime   â”‚  â”‚ Requests â”‚  â”‚ Error %  â”‚  â”‚ P95 Lat  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Request Volume & Error Rate - Line Chart]                    â”‚
â”‚  â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Error by Service        â”‚  â”‚ Error by Type               â”‚ â”‚
â”‚  â”‚ [Bar Chart]             â”‚  â”‚ [Donut Chart]               â”‚ â”‚
â”‚  â”‚ payment: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 450   â”‚  â”‚  Timeout: 45%               â”‚ â”‚
â”‚  â”‚ user:    â–ˆâ–ˆâ–ˆâ–ˆ 200       â”‚  â”‚  DB Error: 30%              â”‚ â”‚
â”‚  â”‚ order:   â–ˆâ–ˆ 100         â”‚  â”‚  Validation: 25%            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Top 10 Errors - Data Table]                                  â”‚
â”‚  Exception                  | Service  | Count | Last Seen    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  SocketTimeoutException     â”‚ payment  â”‚  230  â”‚ 2 min ago    â”‚
â”‚  DataIntegrityViolation     â”‚ order    â”‚   85  â”‚ 5 min ago    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ç¯„ä¾‹ 2ï¼šäº¤æ˜“ç›£æ§ Dashboardï¼ˆé‡‘èæ¥­ï¼‰

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transaction Monitoring                     [Last 1 hour â–¼]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  15,234  â”‚  â”‚ NT$ 2.3B â”‚  â”‚  99.8%   â”‚  â”‚    12    â”‚       â”‚
â”‚  â”‚ Total Tx â”‚  â”‚  Amount  â”‚  â”‚ Success  â”‚  â”‚ Failures â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Transaction Volume by Channel - Stacked Area]                â”‚
â”‚  â–ˆ Mobile  â–ˆ Web  â–ˆ ATM  â–ˆ Branch                             â”‚
â”‚  â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Tx by Type              â”‚  â”‚ Response Time Distribution  â”‚ â”‚
â”‚  â”‚ Transfer:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 45% â”‚  â”‚ [Histogram]                 â”‚ â”‚
â”‚  â”‚ Payment:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 30%   â”‚  â”‚ < 100ms:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 80%  â”‚ â”‚
â”‚  â”‚ Inquiry:   â–ˆâ–ˆâ–ˆâ–ˆ 20%     â”‚  â”‚ 100-500ms: â–ˆâ–ˆâ–ˆâ–ˆ 15%         â”‚ â”‚
â”‚  â”‚ Other:     â–ˆ 5%         â”‚  â”‚ > 500ms:   â–ˆ 5%             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Failed Transactions - Table with drill-down]                 â”‚
â”‚  Time        | TxnId          | Type     | Error      | Amount â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  10:35:22    â”‚ TXN-2026012... â”‚ Transfer â”‚ TIMEOUT    â”‚ 50,000 â”‚
â”‚  10:33:15    â”‚ TXN-2026012... â”‚ Payment  â”‚ DECLINED   â”‚ 12,000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. AI è¼”åŠ© Logs Visualization çš„å¯¦æˆ°æ‡‰ç”¨

### 6.1 ç”¨ AI å”åŠ©æ’°å¯« Elasticsearch Query

#### ä½¿ç”¨æƒ…å¢ƒ

ç•¶éœ€è¦æ’°å¯«è¤‡é›œçš„ ES Query æ™‚ï¼Œå¯ä»¥è«‹ AI å”åŠ©ï¼š

#### Prompt ç¯„ä¾‹ 1ï¼šåŸºæœ¬æŸ¥è©¢

```text
æˆ‘éœ€è¦ä¸€å€‹ Elasticsearch æŸ¥è©¢ï¼Œæ¢ä»¶å¦‚ä¸‹ï¼š
- Index: app-logs-*
- æ™‚é–“ç¯„åœ: éå» 24 å°æ™‚
- æ¢ä»¶: level æ˜¯ ERRORï¼Œservice æ˜¯ payment-service
- æ’åº: æŒ‰æ™‚é–“é™åº
- åªå›å‚³: @timestamp, level, message, traceId
- æœ€å¤š 100 ç­†

è«‹çµ¦æˆ‘å®Œæ•´çš„ ES Query JSONã€‚
```

#### AI å›æ‡‰ç¯„ä¾‹

```json
GET app-logs-*/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "level": "ERROR" } },
        { "term": { "service": "payment-service" } },
        { "range": { "@timestamp": { "gte": "now-24h" } } }
      ]
    }
  },
  "size": 100,
  "_source": ["@timestamp", "level", "message", "traceId"],
  "sort": [{ "@timestamp": "desc" }]
}
```

#### Prompt ç¯„ä¾‹ 2ï¼šè¤‡é›œèšåˆ

```text
æˆ‘éœ€è¦åˆ†æéå» 7 å¤©çš„éŒ¯èª¤è¶¨å‹¢ï¼š
1. æŒ‰æœå‹™åˆ†çµ„
2. æ¯å€‹æœå‹™æŒ‰å°æ™‚çµ±è¨ˆéŒ¯èª¤æ•¸
3. è¨ˆç®—æ¯å°æ™‚çš„éŒ¯èª¤ç‡ï¼ˆéŒ¯èª¤æ•¸/ç¸½æ•¸ï¼‰
4. åªçœ‹éŒ¯èª¤ç‡è¶…é 1% çš„æ™‚æ®µ

è«‹çµ¦æˆ‘ ES Queryã€‚
```

#### AI è¼”åŠ©çš„é™åˆ¶èˆ‡æ³¨æ„äº‹é …

âš ï¸ **æ³¨æ„äº‹é …**ï¼š

1. **é©—è­‰ Query**ï¼šAI ç”¢ç”Ÿçš„ Query éœ€è¦åœ¨ Dev Tools æ¸¬è©¦
2. **æ•ˆèƒ½æª¢æŸ¥**ï¼šAI å¯èƒ½ä¸è€ƒæ…®æ•ˆèƒ½ï¼Œéœ€äººå·¥ç¢ºèª
3. **ç‰ˆæœ¬å·®ç•°**ï¼šç¢ºèª Query èªæ³•èˆ‡ ES ç‰ˆæœ¬ç›¸å®¹
4. **æ•æ„Ÿè³‡æ–™**ï¼šä¸è¦æŠŠçœŸå¯¦ Log å…§å®¹è²¼çµ¦å¤–éƒ¨ AI

---

### 6.2 ç”¨ AI åˆ†æéŒ¯èª¤ Log èˆ‡ç•°å¸¸æ¨¡å¼

#### éŒ¯èª¤åˆ†æ Prompt ç¯„ä¾‹

```text
ä»¥ä¸‹æ˜¯éå» 1 å°æ™‚ payment-service çš„ ERROR logs æ‘˜è¦ï¼š

1. SocketTimeoutException - 230 æ¬¡
   - ä¸»è¦ç™¼ç”Ÿåœ¨ 10:30-10:45
   - éƒ½æ˜¯é€£æ¥ payment-gateway.bank.com:443

2. DataIntegrityViolationException - 85 æ¬¡
   - åˆ†æ•£åœ¨æ•´å€‹å°æ™‚
   - duplicate key value violates unique constraint "pk_transaction"

3. IllegalArgumentException - 45 æ¬¡
   - Invalid currency code: null

è«‹åˆ†æï¼š
1. é€™äº›éŒ¯èª¤çš„å¯èƒ½æ ¹æœ¬åŸå› 
2. å„ªå…ˆè™•ç†é †åº
3. å»ºè­°çš„æ’æŸ¥æ­¥é©Ÿ
```

#### AI åˆ†æçµæœç¯„ä¾‹

```text
## éŒ¯èª¤åˆ†æå ±å‘Š

### 1. SocketTimeoutExceptionï¼ˆæœ€é«˜å„ªå…ˆï¼‰
**å¯èƒ½åŸå› **ï¼š
- payment-gateway åœ¨ 10:30-10:45 æœŸé–“ç™¼ç”Ÿå•é¡Œ
- å¯èƒ½æ˜¯ç¶²è·¯å•é¡Œã€ä¸‹æ¸¸æœå‹™éè¼‰æˆ–éƒ¨ç½²

**æ’æŸ¥æ­¥é©Ÿ**ï¼š
1. æª¢æŸ¥è©²æ™‚æ®µ payment-gateway çš„ metrics/logs
2. ç¢ºèªç¶²è·¯é€£ç·šç‹€æ…‹ï¼ˆping, tracerouteï¼‰
3. æª¢æŸ¥æ˜¯å¦æœ‰è©²æ™‚æ®µçš„è®Šæ›´éƒ¨ç½²

### 2. DataIntegrityViolationExceptionï¼ˆä¸­å„ªå…ˆï¼‰
**å¯èƒ½åŸå› **ï¼š
- é‡è¤‡äº¤æ˜“ ID ç”¢ç”Ÿé‚è¼¯æœ‰å•é¡Œ
- å¯èƒ½æœ‰é‡è©¦æ©Ÿåˆ¶æœªæ­£ç¢ºè™•ç†

**æ’æŸ¥æ­¥é©Ÿ**ï¼š
1. æª¢æŸ¥äº¤æ˜“ ID ç”¢ç”Ÿé‚è¼¯ï¼ˆæ˜¯å¦æœ‰ race conditionï¼‰
2. ç¢ºèªé‡è©¦æ©Ÿåˆ¶æ˜¯å¦æœ‰ idempotency key

### 3. IllegalArgumentExceptionï¼ˆä½å„ªå…ˆï¼‰
**å¯èƒ½åŸå› **ï¼š
- ä¸Šæ¸¸å‚³å…¥çš„è³‡æ–™ç¼ºå°‘ currency code
- è¼¸å…¥é©—è­‰ä¸å®Œæ•´

**æ’æŸ¥æ­¥é©Ÿ**ï¼š
1. è¿½è¹¤é€™äº›è«‹æ±‚çš„ä¾†æºï¼ˆtraceIdï¼‰
2. ç¢ºèª API contract æ˜¯å¦æ¸…æ¥šå®šç¾© currency å¿…å¡«
```

---

### 6.3 å°‡ Logs æ•´ç†æˆ AI å¯ç†è§£çš„ Prompt

#### Log æ•´ç†æŠ€å·§

#### åŸå§‹ Logï¼ˆé›œäº‚ã€è³‡è¨Šéå¤šï¼‰

```text
{"@timestamp":"2026-01-26T10:30:45.123Z","level":"ERROR","logger":"com.bank.payment.service.PaymentGatewayClient","thread":"http-nio-8080-exec-15","traceId":"abc123","spanId":"def456","service":"payment-service","environment":"prod","message":"Failed to process payment","context":{"userId":"USR-78901","transactionId":"TXN-20260126-001234","amount":50000,"currency":"TWD","merchantId":"MER-001","channel":"MOBILE","retryCount":3},"exception":{"class":"java.net.SocketTimeoutException","message":"Read timed out","stackTrace":"java.net.SocketTimeoutException: Read timed out\n\tat java.base/sun.nio.ch.NioSocketImpl.timedRead...(çœç•¥ 50 è¡Œ)"}}
```

#### æ•´ç†å¾Œçš„ Prompt è¼¸å…¥

```text
## éŒ¯èª¤æ‘˜è¦
- æ™‚é–“: 2026-01-26 10:30:45
- æœå‹™: payment-service
- éŒ¯èª¤é¡å‹: SocketTimeoutException
- TraceId: abc123

## é—œéµä¸Šä¸‹æ–‡
- äº¤æ˜“ID: TXN-20260126-001234
- é‡‘é¡: 50,000 TWD
- é€šè·¯: MOBILE
- å·²é‡è©¦: 3 æ¬¡

## éŒ¯èª¤è¨Šæ¯
Read timed outï¼ˆé€£æ¥ payment gateway é€¾æ™‚ï¼‰

## æˆ‘éœ€è¦çŸ¥é“
1. é€™å€‹éŒ¯èª¤çš„å¯èƒ½åŸå› 
2. å¦‚ä½•é€²ä¸€æ­¥è¨ºæ–·
3. æš«æ™‚ç·©è§£æªæ–½
```

#### æ‰¹é‡ Log åˆ†æ Prompt æ¨¡æ¿

```text
è«‹åˆ†æä»¥ä¸‹ Log æ¨¡å¼ï¼š

## æ™‚é–“ç¯„åœ
2026-01-26 10:00 - 11:00

## Log çµ±è¨ˆ
| éŒ¯èª¤é¡å‹ | æ•¸é‡ | é¦–æ¬¡å‡ºç¾ | æœ€å¾Œå‡ºç¾ |
|---------|------|---------|---------|
| SocketTimeoutException | 230 | 10:30:12 | 10:45:33 |
| NullPointerException | 45 | 10:15:00 | 10:55:00 |
| SQLException | 12 | 10:20:00 | 10:22:00 |

## é—œè¯äº‹ä»¶
- 10:28: payment-gateway é–‹å§‹å›æ‡‰è®Šæ…¢ï¼ˆå¾ P95 100ms â†’ 2000msï¼‰
- 10:30: éƒ¨ç½² payment-service v2.3.1
- 10:45: æ‰‹å‹•é‡å•Ÿ payment-gateway

## å•é¡Œ
1. é€™äº›éŒ¯èª¤æ˜¯å¦ç›¸é—œï¼Ÿ
2. æ ¹æœ¬åŸå› å¯èƒ½æ˜¯ä»€éº¼ï¼Ÿ
3. å¦‚ä½•é¿å…å†æ¬¡ç™¼ç”Ÿï¼Ÿ
```

---

### 6.4 AI åœ¨ Incident Response ä¸­çš„è§’è‰²

#### Incident Response æµç¨‹ä¸­çš„ AI æ‡‰ç”¨

```mermaid
graph TB
    subgraph "Incident Response æµç¨‹"
        D[Detection<br/>åµæ¸¬] --> T[Triage<br/>åˆ†é¡]
        T --> I[Investigation<br/>èª¿æŸ¥]
        I --> R[Resolution<br/>è§£æ±º]
        R --> P[Post-mortem<br/>äº‹å¾Œæª¢è¨]
    end
    
    subgraph "AI è¼”åŠ©"
        A1[è‡ªå‹•å‘Šè­¦æ‘˜è¦] --> D
        A2[åš´é‡æ€§è©•ä¼°] --> T
        A3[Log åˆ†æ<br/>é—œè¯ç™¼ç¾] --> I
        A4[å»ºè­°ä¿®å¾©æ–¹æ¡ˆ] --> R
        A5[å ±å‘Šæ’°å¯«<br/>æ”¹å–„å»ºè­°] --> P
    end
```

#### å¯¦æˆ°æ¡ˆä¾‹ï¼šAI è¼”åŠ© Incident èª¿æŸ¥

**æƒ…å¢ƒ**ï¼šå‡Œæ™¨ 3:00 æ”¶åˆ°å‘Šè­¦ï¼Œæ”¯ä»˜æˆåŠŸç‡å¾ 99.9% é™åˆ° 85%

#### Step 1: è«‹ AI æ•´ç†å‘Šè­¦æ‘˜è¦

```text
å‘Šè­¦å…§å®¹ï¼š
- æ™‚é–“: 2026-01-26 03:00
- å‘Šè­¦: Payment Success Rate < 90%
- ç•¶å‰å€¼: 85%
- å½±éŸ¿æœå‹™: payment-service, order-service

è«‹æ•´ç†æˆ Incident Summaryï¼ŒåŒ…å«ï¼š
1. å½±éŸ¿ç¯„åœ
2. æ™‚é–“ç·š
3. é—œéµæŒ‡æ¨™è®ŠåŒ–
```

#### Step 2: è«‹ AI åˆ†æç›¸é—œ Log

```text
ä»¥ä¸‹æ˜¯ payment-service åœ¨ 02:55-03:10 çš„ ERROR logs çµ±è¨ˆï¼š

| æ™‚é–“ | SocketTimeout | DBConnection | Validation |
|------|---------------|--------------|------------|
| 02:55 | 5 | 0 | 2 |
| 03:00 | 150 | 0 | 3 |
| 03:05 | 200 | 45 | 2 |
| 03:10 | 180 | 80 | 1 |

åŒæ™‚æ®µçš„åŸºç¤è¨­æ–½äº‹ä»¶ï¼š
- 02:58: DB failover é–‹å§‹
- 03:02: DB failover å®Œæˆ
- 03:08: DB connection pool é‡å»ºå®Œæˆ

è«‹åˆ†æéŒ¯èª¤æ¨¡å¼èˆ‡äº‹ä»¶çš„é—œè¯ã€‚
```

#### Step 3: è«‹ AI æ’°å¯« Post-mortem

```text
è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šæ’°å¯« Post-mortem å ±å‘Šï¼š

## äº‹ä»¶æ‘˜è¦
- æ™‚é–“: 2026-01-26 03:00-03:15
- å½±éŸ¿: æ”¯ä»˜æˆåŠŸç‡ä¸‹é™åˆ° 85%
- æ ¹æœ¬åŸå› : è³‡æ–™åº« failover å°è‡´é€£ç·šä¸­æ–·

## æ™‚é–“ç·š
ï¼ˆè©³ç´°æ™‚é–“ç·š...ï¼‰

## éœ€è¦æ¶µè“‹çš„ç« ç¯€
1. Executive Summary
2. Impact Analysis
3. Root Cause
4. Resolution
5. Action Items
6. Lessons Learned
```

ğŸ’¡ **å¯¦æˆ°å»ºè­°**ï¼š

1. **AI æ˜¯è¼”åŠ©ï¼Œä¸æ˜¯æ±ºç­–è€…**ï¼šAI åˆ†æçµæœéœ€è¦äººå·¥é©—è­‰
2. **å»ºç«‹ Prompt æ¨¡æ¿**ï¼šåœ˜éšŠå…±ç”¨æ¨™æº–åŒ–çš„ Prompt æ¨¡æ¿
3. **ä¿è­·æ•æ„Ÿè³‡è¨Š**ï¼šä½¿ç”¨å…§éƒ¨ AI æˆ–é®è”½æ•æ„Ÿè³‡æ–™
4. **è¨˜éŒ„ AI è¼”åŠ©éç¨‹**ï¼šä½œç‚º Post-mortem çš„ä¸€éƒ¨åˆ†

---

## 7. å¸¸è¦‹å•é¡Œã€é™·é˜±èˆ‡æœ€ä½³å¯¦å‹™

### 7.1 Log çˆ†é‡çš„è™•ç†æ–¹å¼

#### å¸¸è¦‹åŸå› èˆ‡è§£æ³•

| åŸå›  | ç—‡ç‹€ | è§£æ³• |
|------|------|------|
| **DEBUG å¿˜è¨˜é—œ** | Log é‡çªç„¶æš´å¢ 10x | å»ºç«‹ç’°å¢ƒåˆ¥ Log Level æ§ç®¡ |
| **ç„¡é™è¿´åœˆ Log** | ç›¸åŒè¨Šæ¯å¤§é‡é‡è¤‡ | å¯¦ä½œ Log é™æµï¼ˆRate Limitingï¼‰ |
| **Trace Log å¤–æ´©** | HTTP Body å®Œæ•´è¨˜éŒ„ | æ•æ„Ÿè³‡æ–™ Log è¦ç¯„ |
| **ç•°å¸¸é¢¨æš´** | åŒä¸€éŒ¯èª¤é‡è¤‡ç™¼ç”Ÿ | Circuit Breaker + èšåˆå‘Šè­¦ |
| **å¤–éƒ¨æ”»æ“Š** | Access Log æš´å¢ | WAF + Log æ¡æ¨£ |

#### Log é™æµå¯¦ä½œï¼ˆJavaï¼‰

```java
@Component
public class RateLimitedLogger {
    
    private final Logger log = LoggerFactory.getLogger(this.getClass());
    private final LoadingCache<String, RateLimiter> limiters = CacheBuilder.newBuilder()
        .expireAfterAccess(10, TimeUnit.MINUTES)
        .build(new CacheLoader<>() {
            @Override
            public RateLimiter load(String key) {
                return RateLimiter.create(1.0); // æ¯ç§’æœ€å¤š 1 æ¢
            }
        });
    
    public void error(String key, String message, Object... args) {
        try {
            RateLimiter limiter = limiters.get(key);
            if (limiter.tryAcquire()) {
                log.error(message, args);
            } else {
                // å¯é¸ï¼šè¨˜éŒ„è¢«é™æµçš„æ¬¡æ•¸
                log.debug("Log rate limited for key: {}", key);
            }
        } catch (ExecutionException e) {
            log.error(message, args);
        }
    }
}

// ä½¿ç”¨æ–¹å¼
@Service
public class PaymentService {
    
    @Autowired
    private RateLimitedLogger rateLimitedLogger;
    
    public void processPayment() {
        try {
            // æ¥­å‹™é‚è¼¯
        } catch (SocketTimeoutException e) {
            // åŒé¡éŒ¯èª¤æ¯ç§’æœ€å¤šè¨˜éŒ„ 1 æ¬¡
            rateLimitedLogger.error(
                "payment-gateway-timeout",
                "Payment gateway timeout: {}",
                e.getMessage()
            );
        }
    }
}
```

#### ç·Šæ€¥è™•ç½® SOP

```text
1. ç«‹å³ç¢ºèªå½±éŸ¿ç¯„åœ
   â””â”€â”€ ES Cluster å¥åº·ç‹€æ…‹ã€ç£ç¢Ÿç©ºé–“ã€Index ç‹€æ…‹

2. æš«æ™‚ç·©è§£
   â”œâ”€â”€ å‹•æ…‹èª¿é«˜ Log Levelï¼ˆINFO â†’ WARNï¼‰
   â”œâ”€â”€ Logstash å•Ÿå‹• Samplingï¼ˆæ¯ 10 ç­†å– 1 ç­†ï¼‰
   â””â”€â”€ é—œé–‰éå¿…è¦çš„ Log ä¾†æº

3. æ ¹æœ¬è§£æ±º
   â”œâ”€â”€ æ‰¾å‡ºçˆ†é‡çš„ Log ä¾†æºï¼ˆå“ªå€‹æœå‹™ã€å“ªç¨®é¡å‹ï¼‰
   â”œâ”€â”€ ä¿®æ­£ç¨‹å¼ï¼ˆé—œé–‰ Debugã€ä¿®å¾©è¿´åœˆï¼‰
   â””â”€â”€ éƒ¨ç½²ä¿®æ­£ç‰ˆæœ¬

4. äº‹å¾Œè™•ç†
   â”œâ”€â”€ æ¸…ç†å¤šé¤˜çš„ Index
   â”œâ”€â”€ æª¢è¨ Log è¦ç¯„
   â””â”€â”€ å»ºç«‹ç›£æ§å‘Šè­¦ï¼ˆLog Volume Alertï¼‰
```

---

### 7.2 Index æˆé•·å¤±æ§æ€éº¼è¾¦

#### è¨ºæ–·æŒ‡ä»¤

```bash
# æŸ¥çœ‹å„ Index å¤§å°
GET _cat/indices?v&s=store.size:desc&h=index,docs.count,store.size

# æŸ¥çœ‹ Shard åˆ†å¸ƒ
GET _cat/shards?v&s=store:desc

# æŸ¥çœ‹ Mapping æ¬„ä½æ•¸
GET app-logs-*/_mapping?pretty | jq 'to_entries | .[0].value.mappings.properties | keys | length'

# æŸ¥çœ‹ Index è¨­å®š
GET app-logs-*/_settings
```

#### å¸¸è¦‹å•é¡Œèˆ‡è§£æ³•

| å•é¡Œ | è¨ºæ–·æ–¹å¼ | è§£æ³• |
|------|---------|------|
| **Mapping Explosion** | æ¬„ä½æ•¸ > 1000 | è¨­å®š `dynamic: strict`ï¼Œæ¸…ç†å‹•æ…‹æ¬„ä½ |
| **Shard éå¤š** | Total Shards > 1000/node | åˆä½µå° Indexï¼Œèª¿æ•´ Shard æ•¸ |
| **æœªå•Ÿç”¨ ILM** | èˆŠ Index æ²’æœ‰åˆªé™¤ | è¨­å®š ILM Policy |
| **Replica éå¤š** | æ¯å€‹ Index 3+ Replica | èª¿æ•´ç‚º 1 Replica |
| **æœªå£“ç¸®** | å„²å­˜æ•ˆç‡ä½ | å•Ÿç”¨ `best_compression` |

#### ç·Šæ€¥æ¸…ç†æ­¥é©Ÿ

```bash
# 1. åˆªé™¤éèˆŠçš„ Indexï¼ˆè¬¹æ…æ“ä½œï¼ï¼‰
DELETE app-logs-*-2025.10.*

# 2. å¼·åˆ¶åˆä½µ Segmentï¼ˆWarm/Cold Indexï¼‰
POST app-logs-2025.11.*/_forcemerge?max_num_segments=1

# 3. ç¸®æ¸› Shard æ•¸ï¼ˆéœ€è¦å…ˆè¨­å®š read-onlyï¼‰
PUT app-logs-2025.11.01/_settings
{
  "index.blocks.write": true
}

POST app-logs-2025.11.01/_shrink/app-logs-2025.11.01-shrunk
{
  "settings": {
    "index.number_of_shards": 1,
    "index.number_of_replicas": 1,
    "index.codec": "best_compression"
  }
}

# 4. å¥—ç”¨ ILM Policy åˆ°ç¾æœ‰ Index
PUT app-logs-*/_settings
{
  "index.lifecycle.name": "logs-policy"
}
```

---

### 7.3 è³‡å®‰èˆ‡å€‹è³‡ï¼ˆPIIï¼‰è™•ç†

#### æ•æ„Ÿè³‡æ–™åˆ†é¡

| é¡åˆ¥ | è³‡æ–™ç¯„ä¾‹ | è™•ç†æ–¹å¼ |
|------|---------|---------|
| **ç¦æ­¢è¨˜éŒ„** | å¯†ç¢¼ã€CVVã€å®Œæ•´å¡è™Ÿ | æ°¸ä¸è¨˜éŒ„ |
| **é®è”½** | Emailã€é›»è©±ã€èº«åˆ†è­‰ | éƒ¨åˆ†é®è”½ |
| **åŠ å¯†** | å¸³è™Ÿã€å§“åï¼ˆå¦‚éœ€æŸ¥è©¢ï¼‰ | åŠ å¯†å„²å­˜ |
| **é™åˆ¶å­˜å–** | äº¤æ˜“é‡‘é¡ã€IP | RBAC æ§ç®¡ |

#### Logstash æ•æ„Ÿè³‡æ–™é®è”½

```ruby
filter {
  # ä¿¡ç”¨å¡è™Ÿé®è”½
  mutate {
    gsub => [
      # ä¿ç•™å‰ 4 å¾Œ 4
      "[context][card_number]", "^(\d{4})\d{8}(\d{4})$", "\1********\2",
      # å®Œæ•´é®è”½
      "[context][cvv]", ".*", "***"
    ]
  }
  
  # Email é®è”½
  mutate {
    gsub => [
      "[user][email]", "(?<=.{3}).(?=.*@)", "*"
    ]
  }
  
  # èº«åˆ†è­‰å­—è™Ÿé®è”½ï¼ˆå°ç£ï¼‰
  mutate {
    gsub => [
      "[user][id_number]", "^([A-Z])(\d{2})\d{5}(\d{2})$", "\1\2*****\3"
    ]
  }
  
  # ç§»é™¤çµ•å°ä¸æ‡‰è¨˜éŒ„çš„æ¬„ä½
  mutate {
    remove_field => [
      "[context][password]",
      "[context][cvv]",
      "[context][pin]",
      "[request][body][password]"
    ]
  }
}
```

#### Application å±¤é®è”½ï¼ˆJavaï¼‰

```java
@Component
public class SensitiveDataMasker {
    
    private static final Pattern CARD_PATTERN = 
        Pattern.compile("\\b(\\d{4})\\d{8}(\\d{4})\\b");
    private static final Pattern EMAIL_PATTERN = 
        Pattern.compile("(?<=.{3}).(?=.*@)");
    private static final Pattern TW_ID_PATTERN = 
        Pattern.compile("\\b([A-Z])(\\d{2})\\d{5}(\\d{2})\\b");
    
    public String mask(String input) {
        if (input == null) return null;
        
        String result = input;
        result = CARD_PATTERN.matcher(result).replaceAll("$1********$2");
        result = EMAIL_PATTERN.matcher(result).replaceAll("*");
        result = TW_ID_PATTERN.matcher(result).replaceAll("$1$2*****$3");
        
        return result;
    }
}

// Log4j2 Layout æ•´åˆ
@Plugin(name = "MaskingPatternLayout", category = Node.CATEGORY, 
        elementType = Layout.ELEMENT_TYPE, printObject = true)
public class MaskingPatternLayout extends AbstractStringLayout {
    
    private final SensitiveDataMasker masker = new SensitiveDataMasker();
    
    @Override
    public String toSerializable(LogEvent event) {
        String message = event.getMessage().getFormattedMessage();
        return masker.mask(message);
    }
}
```

---

### 7.4 é‡‘èæ¥­å¸¸è¦‹ç¨½æ ¸èˆ‡æ³•éµéœ€æ±‚

#### æ³•è¦è¦æ±‚å°ç…§è¡¨

| æ³•è¦/æ¨™æº– | Log ç›¸é—œè¦æ±‚ | å¯¦ä½œå»ºè­° |
|----------|-------------|---------|
| **é‡‘ç®¡æœƒè³‡å®‰è¦ç¯„** | é‡è¦ç³»çµ±ä¿ç•™ 5 å¹´ | ILM è¨­å®šé•·æœŸä¿ç•™ + æ­¸æª” |
| **PCI-DSS** | ç¨½æ ¸è»Œè·¡ä¸å¯ç«„æ”¹ | å”¯å¯«æ¬Šé™ + å®Œæ•´æ€§æª¢æŸ¥ |
| **å€‹è³‡æ³•** | å­˜å–ç´€éŒ„å¯è¿½æº¯ | è¨˜éŒ„èª°ã€ä½•æ™‚ã€å­˜å–ä»€éº¼ |
| **ISO 27001** | æ—¥èªŒå®Œæ•´æ€§ä¿è­· | æ•¸ä½ç°½ç«  + ç•°åœ°å‚™ä»½ |

#### ç¨½æ ¸ Log è¨­è¨ˆ

```json
// ç¨½æ ¸ Log ç¯„ä¾‹çµæ§‹
{
  "@timestamp": "2026-01-26T10:30:45.123Z",
  "audit": {
    "event_type": "DATA_ACCESS",
    "action": "READ",
    "result": "SUCCESS",
    "actor": {
      "user_id": "EMP-001234",
      "user_name": "ç‹å°æ˜",
      "department": "è²¡å‹™éƒ¨",
      "ip_address": "10.1.2.100",
      "session_id": "sess-abc123"
    },
    "resource": {
      "type": "CUSTOMER_ACCOUNT",
      "id": "ACC-78901234",
      "fields_accessed": ["balance", "transaction_history"]
    },
    "context": {
      "application": "core-banking",
      "module": "account-inquiry",
      "transaction_id": "TXN-20260126-001234",
      "reason": "å®¢æˆ¶è‡¨æ«ƒæŸ¥è©¢",
      "ticket_number": "SR-2026012600123"
    }
  },
  "integrity": {
    "hash": "sha256:abc123...",
    "previous_hash": "sha256:xyz789..."
  }
}
```

#### Log å®Œæ•´æ€§ä¿è­·

```java
@Service
public class AuditLogService {
    
    private final MessageDigest digest = MessageDigest.getInstance("SHA-256");
    private String previousHash = "";
    
    public void writeAuditLog(AuditEvent event) {
        // è¨ˆç®— Hash Chain
        String content = objectMapper.writeValueAsString(event);
        String currentHash = calculateHash(previousHash + content);
        
        event.getIntegrity().setHash(currentHash);
        event.getIntegrity().setPreviousHash(previousHash);
        
        // å¯«å…¥ Log
        auditLogger.info(objectMapper.writeValueAsString(event));
        
        // æ›´æ–° Chain
        previousHash = currentHash;
        
        // åŒæ™‚å¯«å…¥ä¸å¯ç«„æ”¹çš„å„²å­˜ï¼ˆå¦‚ WORM Storageï¼‰
        wormStorage.append(event);
    }
    
    private String calculateHash(String input) {
        byte[] hash = digest.digest(input.getBytes(StandardCharsets.UTF_8));
        return "sha256:" + bytesToHex(hash);
    }
}
```

---

## 8. ä¼æ¥­ç´šå°å…¥èˆ‡æ²»ç†å»ºè­°

### 8.1 Log è¦ç¯„èˆ‡å‘½åæ¨™æº–

#### Log Level ä½¿ç”¨è¦ç¯„

| Level | ä½¿ç”¨æƒ…å¢ƒ | ç¯„ä¾‹ |
|-------|---------|------|
| **ERROR** | éœ€è¦ç«‹å³è™•ç†çš„éŒ¯èª¤ | äº¤æ˜“å¤±æ•—ã€è³‡æ–™åº«é€£ç·šå¤±æ•— |
| **WARN** | æ½›åœ¨å•é¡Œï¼Œä½†ç³»çµ±ä»å¯é‹ä½œ | é‡è©¦æˆåŠŸã€æ¥è¿‘é–¾å€¼ |
| **INFO** | é‡è¦æ¥­å‹™äº‹ä»¶ | äº¤æ˜“å®Œæˆã€ä½¿ç”¨è€…ç™»å…¥ |
| **DEBUG** | é–‹ç™¼é™¤éŒ¯ç”¨ï¼ˆç”Ÿç”¢ç’°å¢ƒé—œé–‰ï¼‰ | æ–¹æ³•é€²å‡ºã€è®Šæ•¸å€¼ |
| **TRACE** | æ¥µç´°ç¯€è¿½è¹¤ï¼ˆåƒ…é–‹ç™¼ç”¨ï¼‰ | æ¯è¡ŒåŸ·è¡Œã€å®Œæ•´ payload |

#### Log æ¬„ä½å‘½åè¦ç¯„

```yaml
# æ¨™æº–æ¬„ä½å‘½åï¼ˆåœ˜éšŠå…±ç”¨ï¼‰

# æ™‚é–“ç›¸é—œ
timestamp: ISO 8601 æ ¼å¼ï¼ŒUTC æ™‚å€
processed_at: Logstash è™•ç†æ™‚é–“

# è­˜åˆ¥ç›¸é—œ
trace_id: åˆ†æ•£å¼è¿½è¹¤ IDï¼ˆå°å¯«åº•ç·šï¼‰
span_id: Span ID
request_id: è«‹æ±‚ ID
transaction_id: äº¤æ˜“ ID
session_id: Session ID

# ä¾†æºç›¸é—œ
service: æœå‹™åç¨±ï¼ˆå°å¯«æ©«ç·šï¼Œå¦‚ payment-serviceï¼‰
environment: ç’°å¢ƒï¼ˆprod, staging, devï¼‰
version: æœå‹™ç‰ˆæœ¬
host: ä¸»æ©Ÿåç¨±
instance: å¯¦ä¾‹ ID

# ä½¿ç”¨è€…ç›¸é—œ
user.id: ä½¿ç”¨è€… ID
user.type: ä½¿ç”¨è€…é¡å‹ï¼ˆcustomer, employee, systemï¼‰
user.ip: ä¾†æº IP

# æ¥­å‹™ç›¸é—œ
context.*: æ¥­å‹™ä¸Šä¸‹æ–‡ï¼ˆè‡ªç”±å®šç¾©ï¼‰

# éŒ¯èª¤ç›¸é—œ
error.type: éŒ¯èª¤é¡å‹
error.code: éŒ¯èª¤ä»£ç¢¼
error.message: éŒ¯èª¤è¨Šæ¯
error.stack_trace: å †ç–Šè¿½è¹¤ï¼ˆåƒ… ERROR levelï¼‰
```

#### Log æ ¼å¼ç¯„æœ¬ï¼ˆJavaï¼‰

```java
// logback-spring.xml
<configuration>
    <springProperty name="SERVICE_NAME" source="spring.application.name"/>
    <springProperty name="ENV" source="spring.profiles.active"/>
    
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <includeMdcKeyName>traceId</includeMdcKeyName>
            <includeMdcKeyName>spanId</includeMdcKeyName>
            <includeMdcKeyName>userId</includeMdcKeyName>
            <customFields>
                {"service":"${SERVICE_NAME}","environment":"${ENV}"}
            </customFields>
            <fieldNames>
                <timestamp>@timestamp</timestamp>
                <version>[ignore]</version>
                <levelValue>[ignore]</levelValue>
            </fieldNames>
        </encoder>
    </appender>
    
    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

---

### 8.2 åœ˜éšŠåˆ†å·¥èˆ‡æ¬Šé™è¨­è¨ˆ

#### RBAC è§’è‰²å®šç¾©

```mermaid
graph TB
    subgraph "Kibana RBAC"
        R1[Admin<br/>ç®¡ç†å“¡]
        R2[SRE<br/>ç¶­é‹äººå“¡]
        R3[Developer<br/>é–‹ç™¼äººå“¡]
        R4[Auditor<br/>ç¨½æ ¸äººå“¡]
        R5[Manager<br/>ç®¡ç†å±¤]
    end
    
    subgraph "æ¬Šé™ç¯„åœ"
        P1[æ‰€æœ‰ Index<br/>æ‰€æœ‰åŠŸèƒ½]
        P2[Prod Index<br/>Dashboard + Discover]
        P3[Dev/Staging Index<br/>Discover + Visualize]
        P4[Audit Index<br/>å”¯è®€]
        P5[Dashboard<br/>å”¯è®€]
    end
    
    R1 --> P1
    R2 --> P2
    R3 --> P3
    R4 --> P4
    R5 --> P5
```

#### Elasticsearch Security è¨­å®š

```json
// å»ºç«‹è§’è‰²
PUT _security/role/developer
{
  "cluster": ["monitor"],
  "indices": [
    {
      "names": ["dev-*", "staging-*"],
      "privileges": ["read", "view_index_metadata"],
      "field_security": {
        "except": ["user.password", "context.card_number"]
      }
    }
  ],
  "applications": [
    {
      "application": "kibana-.kibana",
      "privileges": ["feature_discover.read", "feature_visualize.all"],
      "resources": ["space:dev-space"]
    }
  ]
}

// å»ºç«‹ä½¿ç”¨è€…
PUT _security/user/dev_user_001
{
  "password": "...",
  "roles": ["developer"],
  "full_name": "Developer 001",
  "email": "dev001@company.com",
  "metadata": {
    "department": "Engineering",
    "team": "Payment"
  }
}
```

---

### 8.3 èˆ‡ CI/CDã€APMã€SIEM çš„æ•´åˆ

#### æ•´åˆæ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "CI/CD Pipeline"
        GIT[Git Repository]
        CI[CI Server<br/>Jenkins/GitLab]
        CD[CD Pipeline]
    end
    
    subgraph "æ‡‰ç”¨ç¨‹å¼"
        APP[Application]
        APM[APM Agent<br/>Elastic APM]
    end
    
    subgraph "Log Platform"
        ELK[ELK Stack]
    end
    
    subgraph "ç›£æ§å¹³å°"
        GRAF[Grafana]
        PROM[Prometheus]
    end
    
    subgraph "è³‡å®‰å¹³å°"
        SIEM[SIEM<br/>Splunk/QRadar]
    end
    
    GIT -->|webhook| CI
    CI -->|deploy| CD
    CD -->|notify| ELK
    
    APP -->|logs| ELK
    APP -->|traces| APM
    APM --> ELK
    
    ELK -->|metrics| PROM
    PROM --> GRAF
    
    ELK -->|security logs| SIEM
```

#### CI/CD æ•´åˆï¼šéƒ¨ç½²äº‹ä»¶æ¨™è¨˜

```yaml
# GitLab CI ç¯„ä¾‹
deploy_production:
  stage: deploy
  script:
    - kubectl apply -f k8s/
    # ç™¼é€éƒ¨ç½²äº‹ä»¶åˆ° Elasticsearch
    - |
      curl -X POST "https://es-cluster:9200/deploy-events/_doc" \
        -H "Content-Type: application/json" \
        -d '{
          "@timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
          "event_type": "deployment",
          "service": "'$CI_PROJECT_NAME'",
          "version": "'$CI_COMMIT_TAG'",
          "environment": "production",
          "deployer": "'$GITLAB_USER_LOGIN'",
          "commit_sha": "'$CI_COMMIT_SHA'",
          "pipeline_url": "'$CI_PIPELINE_URL'"
        }'
```

#### APM æ•´åˆï¼šTrace-Log é—œè¯

```java
// ç¢ºä¿ TraceId å‚³éåˆ° Log
@Configuration
public class TracingConfig {
    
    @Bean
    public Filter traceIdFilter() {
        return (request, response, chain) -> {
            String traceId = tracer.currentSpan().context().traceId();
            MDC.put("traceId", traceId);
            MDC.put("spanId", tracer.currentSpan().context().spanId());
            try {
                chain.doFilter(request, response);
            } finally {
                MDC.clear();
            }
        };
    }
}
```

#### SIEM æ•´åˆï¼šå®‰å…¨äº‹ä»¶è½‰ç™¼

```ruby
# Logstash: å®‰å…¨äº‹ä»¶è½‰ç™¼åˆ° SIEM
output {
  if [level] == "ERROR" and [context][security_event] {
    # ç™¼é€åˆ° SIEM
    syslog {
      host => "siem.company.com"
      port => 514
      protocol => "tcp"
      severity => "warning"
      facility => "local0"
      message => "%{message}"
    }
  }
  
  # åŒæ™‚ä¿ç•™åœ¨ ES
  elasticsearch {
    hosts => ["es-cluster:9200"]
    index => "security-logs-%{+YYYY.MM.dd}"
  }
}
```

---

## 9. æª¢æŸ¥æ¸…å–®ï¼ˆChecklistï¼‰

### ğŸ“‹ æ–°å°ˆæ¡ˆå°å…¥ ELK æª¢æŸ¥æ¸…å–®

#### éšæ®µä¸€ï¼šè¦åŠƒèˆ‡è¨­è¨ˆ

- [ ] ç¢ºèª Log é¡å‹èˆ‡ä¾†æºï¼ˆApplication, Middleware, OS, Securityï¼‰
- [ ] å®šç¾© Log Level ä½¿ç”¨è¦ç¯„
- [ ] è¨­è¨ˆ Log æ¬„ä½å‘½åæ¨™æº–
- [ ] ç¢ºèªæ•æ„Ÿè³‡æ–™è™•ç†ç­–ç•¥ï¼ˆé®è”½ã€åŠ å¯†ã€ä¸è¨˜éŒ„ï¼‰
- [ ] ä¼°ç®—æ¯æ—¥ Log é‡èˆ‡å„²å­˜éœ€æ±‚
- [ ] è¨­è¨ˆ Index å‘½åèˆ‡ç”Ÿå‘½é€±æœŸç­–ç•¥
- [ ] ç¢ºèªæ³•è¦èˆ‡ç¨½æ ¸è¦æ±‚ï¼ˆä¿ç•™å¹´é™ã€å®Œæ•´æ€§ï¼‰

#### éšæ®µäºŒï¼šåŸºç¤è¨­æ–½

- [ ] éƒ¨ç½² Elasticsearch Clusterï¼ˆHot/Warm/Coldï¼‰
- [ ] è¨­å®š Index Template èˆ‡ Mapping
- [ ] è¨­å®š ILM Policy
- [ ] éƒ¨ç½² Logstashï¼ˆå¤š Pipelineï¼‰
- [ ] è¨­å®š Kafka ä½œç‚ºç·©è¡å±¤
- [ ] éƒ¨ç½² Kibana ä¸¦è¨­å®š RBAC
- [ ] è¨­å®š TLS/SSL åŠ å¯†
- [ ] è¨­å®šå‚™ä»½èˆ‡ç½é›£å¾©åŸ

#### éšæ®µä¸‰ï¼šæ‡‰ç”¨ç¨‹å¼æ•´åˆ

- [ ] è¨­å®š Application Log æ ¼å¼ï¼ˆJSONï¼‰
- [ ] æ•´åˆ TraceIdï¼ˆåˆ†æ•£å¼è¿½è¹¤ï¼‰
- [ ] å¯¦ä½œæ•æ„Ÿè³‡æ–™é®è”½
- [ ] éƒ¨ç½² Filebeat/Log Agent
- [ ] é©—è­‰ Log æ­£ç¢ºå‚³è¼¸åˆ° ES
- [ ] å»ºç«‹ Discover Index Pattern

#### éšæ®µå››ï¼šè¦–è¦ºåŒ–èˆ‡å‘Šè­¦

- [ ] å»ºç«‹æœå‹™å¥åº· Dashboard
- [ ] å»ºç«‹éŒ¯èª¤åˆ†æ Dashboard
- [ ] è¨­å®šé—œéµå‘Šè­¦è¦å‰‡ï¼ˆéŒ¯èª¤ç‡ã€å¯ç”¨æ€§ï¼‰
- [ ] æ•´åˆå‘Šè­¦é€šçŸ¥ç®¡é“ï¼ˆSlack, PagerDutyï¼‰
- [ ] è¨­å®š CI/CD éƒ¨ç½²äº‹ä»¶æ¨™è¨˜

#### éšæ®µäº”ï¼šç¶­é‹èˆ‡æ²»ç†

- [ ] å»ºç«‹ Log ç›£æ§ Dashboardï¼ˆVolume, Latencyï¼‰
- [ ] è¨­å®š ES Cluster ç›£æ§
- [ ] å»ºç«‹ç·Šæ€¥è™•ç½® SOP
- [ ] å®Œæˆåœ˜éšŠæ•™è‚²è¨“ç·´
- [ ] æ–‡ä»¶åŒ–ä¸¦ç´å…¥å…§éƒ¨ Wiki

---

### ğŸ“‹ æ—¥å¸¸ç¶­é‹æª¢æŸ¥æ¸…å–®

#### æ¯æ—¥æª¢æŸ¥

- [ ] ES Cluster å¥åº·ç‹€æ…‹ï¼ˆGreen/Yellow/Redï¼‰
- [ ] Index å¯«å…¥æ­£å¸¸ï¼ˆç„¡ rejected requestsï¼‰
- [ ] Logstash Pipeline ç„¡å †ç©
- [ ] é—œéµæœå‹™ç„¡ç•°å¸¸ ERROR çˆ†é‡
- [ ] ç£ç¢Ÿä½¿ç”¨ç‡ < 80%

#### æ¯é€±æª¢æŸ¥

- [ ] ILM æ­£å¸¸åŸ·è¡Œï¼ˆIndex æœ‰æ­£ç¢ºè¼ªè½‰ï¼‰
- [ ] Shard åˆ†å¸ƒå‡è¡¡
- [ ] æŸ¥è©¢æ•ˆèƒ½æ­£å¸¸ï¼ˆP95 < 3sï¼‰
- [ ] å‘Šè­¦è¦å‰‡æœ‰æ•ˆï¼ˆç„¡èª¤å ±/æ¼å ±ï¼‰
- [ ] å‚™ä»½æˆåŠŸåŸ·è¡Œ

#### æ¯æœˆæª¢æŸ¥

- [ ] å®¹é‡è¦åŠƒ Reviewï¼ˆæ˜¯å¦éœ€è¦æ“´å®¹ï¼‰
- [ ] Mapping æ¬„ä½æ•¸ Reviewï¼ˆé¿å… Explosionï¼‰
- [ ] RBAC æ¬Šé™ Review
- [ ] Dashboard ä½¿ç”¨ç‡ Review
- [ ] æ³•è¦åˆè¦æ€§ Review

---

### ğŸ“‹ Incident Response æª¢æŸ¥æ¸…å–®

#### æ”¶åˆ°å‘Šè­¦æ™‚

- [ ] ç¢ºèªå‘Šè­¦æœ‰æ•ˆæ€§ï¼ˆéèª¤å ±ï¼‰
- [ ] é–‹å•Ÿ Incident Ticket
- [ ] é€šçŸ¥ç›¸é—œåœ˜éšŠ

#### èª¿æŸ¥éšæ®µ

- [ ] ç¢ºèªå½±éŸ¿ç¯„åœï¼ˆæœå‹™ã€ä½¿ç”¨è€…æ•¸ï¼‰
- [ ] æŸ¥çœ‹ Kibana Discover éŒ¯èª¤ Log
- [ ] æŸ¥çœ‹ Grafana Metricsï¼ˆç›¸é—œæ™‚é–“é»ï¼‰
- [ ] ç¢ºèªæœ€è¿‘è®Šæ›´ï¼ˆéƒ¨ç½²ã€è¨­å®šè®Šæ›´ï¼‰
- [ ] å»ºç«‹æ™‚é–“ç·š

#### è§£æ±ºéšæ®µ

- [ ] å¯¦æ–½ç·©è§£æªæ–½
- [ ] é©—è­‰å•é¡Œè§£æ±º
- [ ] é€šçŸ¥ Stakeholders

#### äº‹å¾Œè™•ç†

- [ ] æ’°å¯« Post-mortem
- [ ] å»ºç«‹ Action Items
- [ ] æ›´æ–°å‘Šè­¦è¦å‰‡ï¼ˆå¦‚éœ€è¦ï¼‰
- [ ] åˆ†äº« Lessons Learned

---

## é™„éŒ„

### A. å¸¸ç”¨ Elasticsearch Query ç¯„ä¾‹

```json
// 1. æœå°‹ç‰¹å®šæ™‚é–“ç¯„åœçš„ ERROR
GET app-logs-*/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "level": "ERROR" } },
        { "range": { "@timestamp": { "gte": "now-1h" } } }
      ]
    }
  }
}

// 2. çµ±è¨ˆå„æœå‹™éŒ¯èª¤æ•¸
GET app-logs-*/_search
{
  "size": 0,
  "query": {
    "bool": {
      "filter": [
        { "term": { "level": "ERROR" } },
        { "range": { "@timestamp": { "gte": "now-24h" } } }
      ]
    }
  },
  "aggs": {
    "by_service": {
      "terms": { "field": "service", "size": 20 }
    }
  }
}

// 3. è¿½è¹¤ç‰¹å®š TraceId
GET app-logs-*/_search
{
  "query": {
    "term": { "traceId": "abc123def456" }
  },
  "sort": [{ "@timestamp": "asc" }]
}

// 4. æœå°‹ç‰¹å®šç•°å¸¸é¡å‹
GET app-logs-*/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "exception.class": "java.net.SocketTimeoutException" } }
      ]
    }
  }
}
```

### B. å¸¸ç”¨ KQL æŸ¥è©¢ç¯„ä¾‹

```text
# åŸºæœ¬æ¢ä»¶
level: ERROR and service: payment-service

# æ™‚é–“ç¯„åœ
@timestamp >= "2026-01-26" and @timestamp < "2026-01-27"

# æ¨¡ç³Šæœå°‹
message: *timeout* and service: payment*

# çµ„åˆæ¢ä»¶
(level: ERROR or level: WARN) and context.amount > 10000

# æ’é™¤
level: ERROR and not exception.class: "ValidationException"

# å­˜åœ¨æ€§
exception.stackTrace: * and level: ERROR
```

### C. åƒè€ƒè³‡æº

- [Elastic å®˜æ–¹æ–‡ä»¶](https://www.elastic.co/guide/index.html)
- [Logstash Filter Plugins](https://www.elastic.co/guide/en/logstash/current/filter-plugins.html)
- [Elasticsearch Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)
- [Kibana User Guide](https://www.elastic.co/guide/en/kibana/current/index.html)
- [ELK Stack æœ€ä½³å¯¦å‹™](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html)


