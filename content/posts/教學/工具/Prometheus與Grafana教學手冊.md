+++
date = '2026-01-29T19:08:16+08:00'
draft = false
title = 'Prometheusèˆ‡Grafanaæ•™å­¸æ‰‹å†Š'
tags = ['æ•™å­¸', 'å·¥å…·', 'Metrics','Visualization','Prometheus' , 'Grafana']
categories = ['æ•™å­¸']
+++


# Prometheusèˆ‡Grafanaæ•™å­¸æ‰‹å†Š

> **ç‰ˆæœ¬**ï¼š1.0  
> **æœ€å¾Œæ›´æ–°**ï¼š2026 å¹´ 1 æœˆ  
> **é©ç”¨å°è±¡**ï¼šè³‡æ·±å·¥ç¨‹å¸«ã€DevOps / SREã€ç³»çµ±æ¶æ§‹å¸« 
> **å®šä½**ï¼šä¼æ¥­ç´šå¯¦å‹™å°å‘æ•™å­¸æ‰‹å†Š
> **æœ€å¾Œæ›´æ–°**: 2026å¹´1æœˆ27æ—¥  
> **é©ç”¨æ–¼**: Metrics Visualization 
> **Created by**: Eric Cheng


## ç›®éŒ„

### 1. [ç¸½è¦½ï¼ˆOverviewï¼‰](#1-ç¸½è¦½overview)

- [1.1 ç‚ºä½•éœ€è¦ Metrics Visualization](#11-ç‚ºä½•éœ€è¦-metrics-visualization)
- [1.2 Prometheus èˆ‡ Grafana åœ¨ Observability ä¸­çš„è§’è‰²](#12-prometheus-èˆ‡-grafana-åœ¨-observability-ä¸­çš„è§’è‰²)
- [1.3 èˆ‡ Logging / Tracing çš„å·®ç•°èˆ‡æ•´åˆæ–¹å¼](#13-èˆ‡-logging--tracing-çš„å·®ç•°èˆ‡æ•´åˆæ–¹å¼)
- [1.4 é©åˆçš„ä½¿ç”¨å ´æ™¯](#14-é©åˆçš„ä½¿ç”¨å ´æ™¯)

### 2. [æ¶æ§‹èªªæ˜ï¼ˆArchitectureï¼‰](#2-æ¶æ§‹èªªæ˜architecture)

- [2.1 Prometheus æ¶æ§‹](#21-prometheus-æ¶æ§‹)
- [2.2 Exporter æ¦‚å¿µ](#22-exporter-æ¦‚å¿µ)
- [2.3 Grafana æ¶æ§‹](#23-grafana-æ¶æ§‹)
- [2.4 Prometheus èˆ‡ Grafana ä¸²æ¥æµç¨‹](#24-prometheus-èˆ‡-grafana-ä¸²æ¥æµç¨‹)
- [2.5 å–®æ©Ÿ vs HA / Federation æ¶æ§‹](#25-å–®æ©Ÿ-vs-ha--federation-æ¶æ§‹)

### 3. [ç³»çµ±å®‰è£ï¼ˆInstallationï¼‰](#3-ç³»çµ±å®‰è£installation)

- [3.1 ç’°å¢ƒæº–å‚™](#31-ç’°å¢ƒæº–å‚™)
- [3.2 Prometheus å®‰è£](#32-prometheus-å®‰è£)
- [3.3 Grafana å®‰è£](#33-grafana-å®‰è£)
- [3.4 Node Exporter å®‰è£](#34-node-exporter-å®‰è£)
- [3.5 ç›®éŒ„çµæ§‹èªªæ˜](#35-ç›®éŒ„çµæ§‹èªªæ˜)
- [3.6 å¸¸è¦‹å®‰è£éŒ¯èª¤èˆ‡æ’é™¤](#36-å¸¸è¦‹å®‰è£éŒ¯èª¤èˆ‡æ’é™¤)

### 4. [ç³»çµ±è¨­å®šï¼ˆConfigurationï¼‰](#4-ç³»çµ±è¨­å®šconfiguration)

- [4.1 Prometheus è¨­å®š](#41-prometheus-è¨­å®š)
- [4.2 Grafana è¨­å®š](#42-grafana-è¨­å®š)

### 5. [ç³»çµ±ä½¿ç”¨ï¼ˆUsageï¼‰](#5-ç³»çµ±ä½¿ç”¨usage)

- [5.1 PromQL åŸºæœ¬èˆ‡é€²éšèªæ³•](#51-promql-åŸºæœ¬èˆ‡é€²éšèªæ³•)
- [5.2 å¸¸è¦‹ Metrics ç¯„ä¾‹](#52-å¸¸è¦‹-metrics-ç¯„ä¾‹)
- [5.3 Dashboard è¨­è¨ˆæœ€ä½³å¯¦å‹™](#53-dashboard-è¨­è¨ˆæœ€ä½³å¯¦å‹™)
- [5.4 å¯¦å‹™ç¯„ä¾‹](#54-å¯¦å‹™ç¯„ä¾‹)
- [5.5 èˆ‡ AI æ­é…ä½¿ç”¨](#55-èˆ‡-ai-æ­é…ä½¿ç”¨)

### 6. [å‘Šè­¦èˆ‡é€šçŸ¥ï¼ˆAlertingï¼‰](#6-å‘Šè­¦èˆ‡é€šçŸ¥alerting)

- [6.1 Prometheus Alertmanager æ¶æ§‹](#61-prometheus-alertmanager-æ¶æ§‹)
- [6.2 Alert Rule æ’°å¯«ç¯„ä¾‹](#62-alert-rule-æ’°å¯«ç¯„ä¾‹)
- [6.3 å‘Šè­¦åˆ†ç´š](#63-å‘Šè­¦åˆ†ç´š)
- [6.4 Grafana Alert èˆ‡ Prometheus Alert å·®ç•°](#64-grafana-alert-èˆ‡-prometheus-alert-å·®ç•°)
- [6.5 èˆ‡ Teams / Slack æ•´åˆ](#65-èˆ‡-teams--slack-æ•´åˆ)

### 7. [ç³»çµ±ç¶­è­·ï¼ˆMaintenanceï¼‰](#7-ç³»çµ±ç¶­è­·maintenance)

- [7.1 è³‡æ–™æˆé•·èˆ‡ç£ç¢Ÿç©ºé–“ç®¡ç†](#71-è³‡æ–™æˆé•·èˆ‡ç£ç¢Ÿç©ºé–“ç®¡ç†)
- [7.2 æ•ˆèƒ½èª¿æ ¡å»ºè­°](#72-æ•ˆèƒ½èª¿æ ¡å»ºè­°)
- [7.3 å¸¸è¦‹å•é¡Œè™•ç†](#73-å¸¸è¦‹å•é¡Œè™•ç†)
- [7.4 å‚™ä»½èˆ‡é‚„åŸç­–ç•¥](#74-å‚™ä»½èˆ‡é‚„åŸç­–ç•¥)

### 8. [ç³»çµ±å‡ç´šï¼ˆUpgradeï¼‰](#8-ç³»çµ±å‡ç´šupgrade)

- [8.1 Prometheus å‡ç´šæ³¨æ„äº‹é …](#81-prometheus-å‡ç´šæ³¨æ„äº‹é …)
- [8.2 Grafana å‡ç´šæ³¨æ„äº‹é …](#82-grafana-å‡ç´šæ³¨æ„äº‹é …)
- [8.3 å‡ç´šå‰æª¢æŸ¥æ¸…å–®](#83-å‡ç´šå‰æª¢æŸ¥æ¸…å–®)
- [8.4 å›æ»¾ï¼ˆRollbackï¼‰ç­–ç•¥](#84-å›æ»¾rollbackç­–ç•¥)

### 9. [ä¼æ¥­å¯¦å‹™èˆ‡æœ€ä½³å¯¦è¸ï¼ˆBest Practicesï¼‰](#9-ä¼æ¥­å¯¦å‹™èˆ‡æœ€ä½³å¯¦è¸best-practices)

- [9.1 æŒ‡æ¨™å‘½åè¦ç¯„](#91-æŒ‡æ¨™å‘½åè¦ç¯„)
- [9.2 Label è¨­è¨ˆåŸå‰‡](#92-label-è¨­è¨ˆåŸå‰‡)
- [9.3 å¤šç’°å¢ƒè¨­è¨ˆï¼ˆDEV / SIT / UAT / PRODï¼‰](#93-å¤šç’°å¢ƒè¨­è¨ˆdev--sit--uat--prod)
- [9.4 èˆ‡ CI/CDã€Batchã€å¾®æœå‹™æ•´åˆ](#94-èˆ‡-cicdbatchå¾®æœå‹™æ•´åˆ)
- [9.5 éŠ€è¡Œèˆ‡é«˜ç©©å®šç³»çµ±å°å…¥å»ºè­°](#95-éŠ€è¡Œèˆ‡é«˜ç©©å®šç³»çµ±å°å…¥å»ºè­°)

### 10. [é™„éŒ„ï¼ˆAppendixï¼‰](#10-é™„éŒ„appendix)

- [10.1 å¸¸ç”¨ PromQL Cheat Sheet](#101-å¸¸ç”¨-promql-cheat-sheet)
- [10.2 æ¨è–¦ Exporter æ¸…å–®](#102-æ¨è–¦-exporter-æ¸…å–®)
- [10.3 Dashboard ç¯„æœ¬å»ºè­°](#103-dashboard-ç¯„æœ¬å»ºè­°)
- [10.4 å¸¸è¦‹éŒ¯èª¤èˆ‡ FAQ](#104-å¸¸è¦‹éŒ¯èª¤èˆ‡-faq)

### 11. [æª¢æŸ¥æ¸…å–®ï¼ˆChecklistï¼‰](#11-æª¢æŸ¥æ¸…å–®checklist)

- [11.1 å®‰è£æª¢æŸ¥æ¸…å–®](#111-å®‰è£æª¢æŸ¥æ¸…å–®)
- [11.2 è¨­å®šæª¢æŸ¥æ¸…å–®](#112-è¨­å®šæª¢æŸ¥æ¸…å–®)
- [11.3 ç”Ÿç”¢ç’°å¢ƒæª¢æŸ¥æ¸…å–®](#113-ç”Ÿç”¢ç’°å¢ƒæª¢æŸ¥æ¸…å–®)
- [11.4 æ—¥å¸¸ç¶­é‹æª¢æŸ¥æ¸…å–®](#114-æ—¥å¸¸ç¶­é‹æª¢æŸ¥æ¸…å–®)

### [åƒè€ƒè³‡æº](#åƒè€ƒè³‡æº)

---

## 1. ç¸½è¦½ï¼ˆOverviewï¼‰

### 1.1 ç‚ºä½•éœ€è¦ Metrics Visualization

åœ¨ç¾ä»£ä¼æ¥­ç³»çµ±ä¸­ï¼Œ**å¯è§€æ¸¬æ€§ï¼ˆObservabilityï¼‰** æ˜¯ç¶­é‹çš„æ ¸å¿ƒèƒ½åŠ›ã€‚Metrics Visualization æä¾›ä»¥ä¸‹åƒ¹å€¼ï¼š

| éœ€æ±‚é¢å‘ | èªªæ˜ |
|---------|------|
| **æ•ˆèƒ½ç›£æ§** | å³æ™‚æŒæ¡ç³»çµ±è³‡æºä½¿ç”¨ç‡ï¼ˆCPUã€Memoryã€Disk I/Oï¼‰ |
| **å•é¡Œå®šä½** | é€éæŒ‡æ¨™è¶¨å‹¢å¿«é€Ÿå®šä½æ•ˆèƒ½ç“¶é ¸ |
| **å®¹é‡è¦åŠƒ** | é æ¸¬è³‡æºéœ€æ±‚ï¼Œæå‰æ“´å®¹ |
| **SLA/SLO ç®¡ç†** | é‡åŒ–æœå‹™å“è³ªï¼Œç¢ºä¿åˆç´„é”æ¨™ |
| **ç•°å¸¸å‘Šè­¦** | è‡ªå‹•åµæ¸¬ç•°å¸¸ä¸¦é€šçŸ¥ç›¸é—œäººå“¡ |

#### ğŸ’¡ å¯¦å‹™è§€é»
> åœ¨éŠ€è¡Œèˆ‡é‡‘èç³»çµ±ä¸­ï¼ŒMetrics æ˜¯ã€Œç¬¬ä¸€å±¤é˜²ç·šã€ã€‚ç•¶ç³»çµ±å‡ºç¾å•é¡Œæ™‚ï¼ŒMetrics èƒ½åœ¨ä½¿ç”¨è€…æ„ŸçŸ¥å‰æä¾›æ—©æœŸé è­¦ï¼Œæ˜¯é”æˆ 99.99% SLA çš„é—œéµå·¥å…·ã€‚

### 1.2 Prometheus èˆ‡ Grafana åœ¨ Observability ä¸­çš„è§’è‰²

```mermaid
graph TB
    subgraph "Observability ä¸‰å¤§æ”¯æŸ±"
        M[Metrics<br/>æŒ‡æ¨™]
        L[Logs<br/>æ—¥èªŒ]
        T[Traces<br/>è¿½è¹¤]
    end
    
    subgraph "æŠ€è¡“é¸å‹"
        M --> P[Prometheus]
        P --> G[Grafana]
        L --> ELK[ELK Stack]
        T --> J[Jaeger / Zipkin]
    end
    
    subgraph "æ•´åˆå±¤"
        G --> Dashboard[çµ±ä¸€å„€è¡¨æ¿]
        ELK --> Dashboard
        J --> Dashboard
    end
```

| å·¥å…· | è§’è‰²å®šä½ | æ ¸å¿ƒåŠŸèƒ½ |
|-----|---------|---------|
| **Prometheus** | æ™‚åºè³‡æ–™åº« + è³‡æ–™æ”¶é›†å™¨ | æŠ“å–ã€å„²å­˜ã€æŸ¥è©¢ Metrics |
| **Grafana** | è¦–è¦ºåŒ–å¹³å° | Dashboardã€å‘Šè­¦ã€å¤šè³‡æ–™æºæ•´åˆ |

### 1.3 èˆ‡ Logging / Tracing çš„å·®ç•°èˆ‡æ•´åˆæ–¹å¼

| é¢å‘ | Metrics | Logs | Traces |
|-----|---------|------|--------|
| **è³‡æ–™å‹æ…‹** | æ•¸å€¼å‹æ™‚åºè³‡æ–™ | æ–‡å­—äº‹ä»¶è¨˜éŒ„ | è«‹æ±‚éˆè·¯è¿½è¹¤ |
| **ç”¨é€”** | ç›£æ§è¶¨å‹¢ã€å‘Šè­¦ | å•é¡Œæ ¹å› åˆ†æ | åˆ†æ•£å¼è¿½è¹¤ |
| **å„²å­˜æˆæœ¬** | ä½ | é«˜ | ä¸­ |
| **æŸ¥è©¢é€Ÿåº¦** | å¿« | ä¸­ | ä¸­ |
| **é©ç”¨å•é¡Œ** | "ç³»çµ±æ˜¯å¦å¥åº·ï¼Ÿ" | "ç™¼ç”Ÿäº†ä»€éº¼ï¼Ÿ" | "è«‹æ±‚ç¶“éå“ªè£¡ï¼Ÿ" |

#### æ•´åˆæ¶æ§‹ç¯„ä¾‹

```mermaid
flowchart LR
    App[æ‡‰ç”¨ç¨‹å¼] -->|Metrics| Prometheus
    App -->|Logs| Logstash
    App -->|Traces| Jaeger
    
    Prometheus --> Grafana
    Logstash --> ES[Elasticsearch]
    ES --> Grafana
    Jaeger --> Grafana
    
    Grafana -->|çµ±ä¸€è¦–åœ–| User[ç¶­é‹äººå“¡]
```

### 1.4 é©åˆçš„ä½¿ç”¨å ´æ™¯

#### âœ… é©åˆä½¿ç”¨ Prometheus + Grafana çš„å ´æ™¯

| å ´æ™¯ | èªªæ˜ |
|-----|------|
| **å¾®æœå‹™æ¶æ§‹** | å¤§é‡æœå‹™å¯¦ä¾‹çš„çµ±ä¸€ç›£æ§ |
| **å®¹å™¨åŒ–ç’°å¢ƒ** | K8s / Docker åŸç”Ÿæ”¯æ´ |
| **é›²åŸç”Ÿæ‡‰ç”¨** | èˆ‡ Cloud Native ç”Ÿæ…‹ç³»ç„¡ç¸«æ•´åˆ |
| **é«˜é »äº¤æ˜“ç³»çµ±** | æ¯«ç§’ç´šæŒ‡æ¨™æ”¶é›†èˆ‡å‘Šè­¦ |
| **éŠ€è¡Œæ ¸å¿ƒç³»çµ±** | 7x24 ç›£æ§ï¼Œç¬¦åˆç¨½æ ¸éœ€æ±‚ |

#### âš ï¸ éœ€è¦é¡å¤–è©•ä¼°çš„å ´æ™¯

| å ´æ™¯ | è€ƒé‡é» |
|-----|-------|
| **è¶…å¤§è¦æ¨¡å¢é›†** | éœ€è€ƒæ…® Federation / Thanos / Cortex |
| **é•·æœŸè³‡æ–™ä¿å­˜** | é è¨­ 15 å¤©ï¼Œéœ€æ­é…é ç«¯å„²å­˜ |
| **é«˜ç²¾åº¦ Metrics** | Cardinality ç®¡ç†æˆç‚ºæŒ‘æˆ° |

---

## 2. æ¶æ§‹èªªæ˜ï¼ˆArchitectureï¼‰

### 2.1 Prometheus æ¶æ§‹

```mermaid
graph TB
    subgraph "Prometheus Server"
        R[Retrieval<br/>è³‡æ–™æŠ“å–]
        TSDB[(TSDB<br/>æ™‚åºè³‡æ–™åº«)]
        HTTP[HTTP Server<br/>API ä»‹é¢]
        R --> TSDB
        TSDB --> HTTP
    end
    
    subgraph "è³‡æ–™ä¾†æº"
        E1[Node Exporter]
        E2[JVM Exporter]
        E3[Custom Exporter]
        SD[Service Discovery]
    end
    
    subgraph "å‘Šè­¦"
        AM[Alertmanager]
        HTTP --> AM
        AM --> Email[Email]
        AM --> Teams[MS Teams]
        AM --> Slack[Slack]
    end
    
    E1 -->|Pull| R
    E2 -->|Pull| R
    E3 -->|Pull| R
    SD --> R
    
    HTTP --> Grafana[Grafana]
```

#### æ ¸å¿ƒå…ƒä»¶èªªæ˜

| å…ƒä»¶ | åŠŸèƒ½ | èªªæ˜ |
|-----|------|------|
| **Retrieval** | è³‡æ–™æŠ“å– | å®šæœŸå¾ Target æ‹‰å– Metrics |
| **TSDB** | æ™‚åºå„²å­˜ | é«˜æ•ˆèƒ½æœ¬åœ°æ™‚åºè³‡æ–™åº« |
| **HTTP Server** | API ä»‹é¢ | æä¾› PromQL æŸ¥è©¢èˆ‡ç®¡ç† API |
| **Service Discovery** | æœå‹™ç™¼ç¾ | æ”¯æ´ K8sã€Consulã€DNS ç­‰ |

#### Pull Model vs Push Model

```mermaid
graph LR
    subgraph "Pull Modelï¼ˆPrometheusï¼‰"
        P1[Prometheus] -->|ä¸»å‹•æ‹‰å–| T1[Target 1]
        P1 -->|ä¸»å‹•æ‹‰å–| T2[Target 2]
    end
    
    subgraph "Push Modelï¼ˆGraphiteï¼‰"
        A1[App 1] -->|ä¸»å‹•æ¨é€| G1[Graphite]
        A2[App 2] -->|ä¸»å‹•æ¨é€| G1
    end
```

| æ¨¡å¼ | å„ªé» | ç¼ºé» |
|-----|------|------|
| **Pull** | æœå‹™æ¢æ¸¬ã€ç°¡åŒ–é…ç½®ã€é¿å…è³‡æ–™æ“å¡ | é˜²ç«ç‰†ç©¿è¶Šå•é¡Œ |
| **Push** | çŸ­ç”Ÿå‘½é€±æœŸ Job å‹å–„ | è³‡æ–™æ“å¡é¢¨éšª |

### 2.2 Exporter æ¦‚å¿µ

Exporter æ˜¯å°‡å„ç¨®ç³»çµ±æŒ‡æ¨™è½‰æ›ç‚º Prometheus æ ¼å¼çš„å…ƒä»¶ã€‚

#### å¸¸ç”¨ Exporter æ¸…å–®

| Exporter | ç›£æ§å°è±¡ | Port |
|----------|---------|------|
| **node_exporter** | Linux ä¸»æ©Ÿï¼ˆCPUã€Memoryã€Diskï¼‰ | 9100 |
| **jmx_exporter** | JVMï¼ˆHeapã€GCã€Threadï¼‰ | 9404 |
| **mysql_exporter** | MySQL è³‡æ–™åº« | 9104 |
| **postgres_exporter** | PostgreSQL è³‡æ–™åº« | 9187 |
| **redis_exporter** | Redis | 9121 |
| **blackbox_exporter** | HTTP/TCP/ICMP æ¢æ¸¬ | 9115 |
| **kafka_exporter** | Kafka | 9308 |

#### Exporter æ¶æ§‹ç¤ºæ„

```mermaid
graph LR
    subgraph "æ‡‰ç”¨å±¤"
        App[Java Application]
        JMX[JMX Exporter]
        App --> JMX
    end
    
    subgraph "ä¸»æ©Ÿå±¤"
        OS[Linux OS]
        NE[Node Exporter]
        OS --> NE
    end
    
    subgraph "è³‡æ–™åº«å±¤"
        DB[(MySQL)]
        ME[MySQL Exporter]
        DB --> ME
    end
    
    P[Prometheus] -->|:9404| JMX
    P -->|:9100| NE
    P -->|:9104| ME
```

### 2.3 Grafana æ¶æ§‹

```mermaid
graph TB
    subgraph "Grafana Server"
        FE[Frontend<br/>React UI]
        BE[Backend<br/>Go Server]
        DB[(SQLite/MySQL/PostgreSQL)]
        FE --> BE
        BE --> DB
    end
    
    subgraph "Data Sources"
        DS1[Prometheus]
        DS2[Elasticsearch]
        DS3[InfluxDB]
        DS4[MySQL]
    end
    
    BE --> DS1
    BE --> DS2
    BE --> DS3
    BE --> DS4
    
    subgraph "è¼¸å‡º"
        Dashboard[Dashboard]
        Alert[Alerting]
        Report[Reports]
    end
    
    BE --> Dashboard
    BE --> Alert
    BE --> Report
```

#### Grafana æ ¸å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | èªªæ˜ |
|-----|------|
| **Data Source** | è³‡æ–™ä¾†æºé€£æ¥ï¼ˆPrometheusã€ES ç­‰ï¼‰ |
| **Dashboard** | å„€è¡¨æ¿ï¼ŒåŒ…å«å¤šå€‹ Panel |
| **Panel** | å–®ä¸€è¦–è¦ºåŒ–å…ƒä»¶ï¼ˆåœ–è¡¨ã€è¡¨æ ¼ç­‰ï¼‰ |
| **Variable** | å‹•æ…‹è®Šæ•¸ï¼Œæ”¯æ´ä¸‹æ‹‰é¸å–®ç¯©é¸ |
| **Folder** | Dashboard åˆ†é¡èˆ‡æ¬Šé™ç®¡ç† |
| **Organization** | å¤šç§Ÿæˆ¶éš”é›¢ |

### 2.4 Prometheus èˆ‡ Grafana ä¸²æ¥æµç¨‹

```mermaid
sequenceDiagram
    participant E as Exporter
    participant P as Prometheus
    participant G as Grafana
    participant U as User
    
    loop æ¯ 15 ç§’
        P->>E: HTTP GET /metrics
        E->>P: è¿”å› Metrics æ–‡å­—
        P->>P: å„²å­˜è‡³ TSDB
    end
    
    U->>G: é–‹å•Ÿ Dashboard
    G->>P: PromQL æŸ¥è©¢
    P->>G: è¿”å›æ™‚åºè³‡æ–™
    G->>U: æ¸²æŸ“åœ–è¡¨
```

### 2.5 å–®æ©Ÿ vs HA / Federation æ¶æ§‹

#### å–®æ©Ÿæ¶æ§‹ï¼ˆé©åˆå°å‹ç’°å¢ƒï¼‰

```mermaid
graph TB
    subgraph "å–®æ©Ÿéƒ¨ç½²"
        P[Prometheus]
        G[Grafana]
        AM[Alertmanager]
    end
    
    E1[Exporter 1] --> P
    E2[Exporter 2] --> P
    E3[Exporter 3] --> P
    
    P --> G
    P --> AM
```

#### HA æ¶æ§‹ï¼ˆé©åˆç”Ÿç”¢ç’°å¢ƒï¼‰

```mermaid
graph TB
    subgraph "Prometheus HA"
        P1[Prometheus 1]
        P2[Prometheus 2]
    end
    
    subgraph "Alertmanager Cluster"
        AM1[Alertmanager 1]
        AM2[Alertmanager 2]
        AM1 <--> AM2
    end
    
    subgraph "Grafana HA"
        G1[Grafana 1]
        G2[Grafana 2]
        GDB[(Shared DB)]
        G1 --> GDB
        G2 --> GDB
    end
    
    LB[Load Balancer] --> P1
    LB --> P2
    LB --> G1
    LB --> G2
    
    P1 --> AM1
    P1 --> AM2
    P2 --> AM1
    P2 --> AM2
```

#### Federation æ¶æ§‹ï¼ˆé©åˆå¤§å‹åˆ†æ•£å¼ç’°å¢ƒï¼‰

```mermaid
graph TB
    subgraph "Global Prometheus"
        GP[Global Prometheus]
    end
    
    subgraph "Zone A"
        PA[Prometheus A]
        EA1[Exporter]
        EA2[Exporter]
        EA1 --> PA
        EA2 --> PA
    end
    
    subgraph "Zone B"
        PB[Prometheus B]
        EB1[Exporter]
        EB2[Exporter]
        EB1 --> PB
        EB2 --> PB
    end
    
    PA -->|Federation| GP
    PB -->|Federation| GP
    GP --> Grafana
```

| æ¶æ§‹ | é©ç”¨å ´æ™¯ | è¤‡é›œåº¦ |
|-----|---------|-------|
| **å–®æ©Ÿ** | é–‹ç™¼ç’°å¢ƒã€å°å‹ç³»çµ± | ä½ |
| **HA** | ç”Ÿç”¢ç’°å¢ƒã€ä¸­å‹ç³»çµ± | ä¸­ |
| **Federation** | è·¨æ©Ÿæˆ¿ã€å¤§å‹åˆ†æ•£å¼ç³»çµ± | é«˜ |
| **Thanos/Cortex** | è¶…å¤§è¦æ¨¡ã€é•·æœŸå„²å­˜ | å¾ˆé«˜ |

#### âš ï¸ å¯¦å‹™å»ºè­°
> 1. **ç”Ÿç”¢ç’°å¢ƒè‡³å°‘è¦ HA**ï¼šå–®é»æ•…éšœæœƒå°è‡´ç›£æ§ç›²å€
> 2. **Alertmanager å¿…é ˆå¢é›†åŒ–**ï¼šé¿å…å‘Šè­¦éºæ¼
> 3. **Grafana å¾Œç«¯è³‡æ–™åº«è¦å…±äº«**ï¼šç¢ºä¿ Dashboard ä¸€è‡´æ€§

---

## 3. ç³»çµ±å®‰è£ï¼ˆInstallationï¼‰

### 3.1 ç’°å¢ƒæº–å‚™

#### ç³»çµ±éœ€æ±‚

| é …ç›® | æœ€ä½éœ€æ±‚ | å»ºè­°é…ç½®ï¼ˆç”Ÿç”¢ï¼‰ |
|-----|---------|----------------|
| **OS** | CentOS 7+ / Ubuntu 18.04+ | CentOS 8+ / Ubuntu 22.04 |
| **CPU** | 2 cores | 4+ cores |
| **Memory** | 4 GB | 16+ GB |
| **Disk** | 50 GB SSD | 500+ GB SSD |
| **Network** | ç©©å®šå…§ç¶² | 10 Gbps |

#### é˜²ç«ç‰†è¨­å®š

```bash
# Prometheus
firewall-cmd --permanent --add-port=9090/tcp

# Grafana
firewall-cmd --permanent --add-port=3000/tcp

# Alertmanager
firewall-cmd --permanent --add-port=9093/tcp

# Node Exporter
firewall-cmd --permanent --add-port=9100/tcp

# é‡æ–°è¼‰å…¥
firewall-cmd --reload
```

### 3.2 Prometheus å®‰è£

#### æ–¹æ³•ä¸€ï¼šBinary å®‰è£ï¼ˆæ¨è–¦ç”¨æ–¼ VMï¼‰

```bash
# 1. å»ºç«‹ä½¿ç”¨è€…
sudo useradd --no-create-home --shell /bin/false prometheus

# 2. å»ºç«‹ç›®éŒ„
sudo mkdir -p /etc/prometheus
sudo mkdir -p /var/lib/prometheus

# 3. ä¸‹è¼‰ Prometheusï¼ˆè«‹ç¢ºèªæœ€æ–°ç‰ˆæœ¬ï¼‰
cd /tmp
wget https://github.com/prometheus/prometheus/releases/download/v2.48.0/prometheus-2.48.0.linux-amd64.tar.gz

# 4. è§£å£“ç¸®
tar xvfz prometheus-2.48.0.linux-amd64.tar.gz
cd prometheus-2.48.0.linux-amd64

# 5. è¤‡è£½åŸ·è¡Œæª”
sudo cp prometheus /usr/local/bin/
sudo cp promtool /usr/local/bin/

# 6. è¤‡è£½è¨­å®šæª”
sudo cp -r consoles /etc/prometheus
sudo cp -r console_libraries /etc/prometheus
sudo cp prometheus.yml /etc/prometheus/

# 7. è¨­å®šæ¬Šé™
sudo chown -R prometheus:prometheus /etc/prometheus
sudo chown -R prometheus:prometheus /var/lib/prometheus
sudo chown prometheus:prometheus /usr/local/bin/prometheus
sudo chown prometheus:prometheus /usr/local/bin/promtool
```

#### å»ºç«‹ Systemd Service

```bash
sudo cat > /etc/systemd/system/prometheus.service << 'EOF'
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
    --config.file=/etc/prometheus/prometheus.yml \
    --storage.tsdb.path=/var/lib/prometheus/ \
    --storage.tsdb.retention.time=15d \
    --web.console.templates=/etc/prometheus/consoles \
    --web.console.libraries=/etc/prometheus/console_libraries \
    --web.enable-lifecycle \
    --web.enable-admin-api

ExecReload=/bin/kill -HUP $MAINPID
Restart=on-failure
RestartSec=5s

[Install]
WantedBy=multi-user.target
EOF

# å•Ÿå‹•æœå‹™
sudo systemctl daemon-reload
sudo systemctl enable prometheus
sudo systemctl start prometheus
sudo systemctl status prometheus
```

#### æ–¹æ³•äºŒï¼šDocker å®‰è£

```bash
# å»ºç«‹è³‡æ–™ç›®éŒ„
mkdir -p /data/prometheus

# å»ºç«‹è¨­å®šæª”
cat > /data/prometheus/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
EOF

# åŸ·è¡Œå®¹å™¨
docker run -d \
  --name prometheus \
  --restart unless-stopped \
  -p 9090:9090 \
  -v /data/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \
  -v /data/prometheus/data:/prometheus \
  prom/prometheus:v2.48.0 \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path=/prometheus \
  --storage.tsdb.retention.time=15d \
  --web.enable-lifecycle
```

#### é©—è­‰å®‰è£

```bash
# æª¢æŸ¥æœå‹™ç‹€æ…‹
curl http://localhost:9090/-/healthy
# é æœŸå›æ‡‰: Prometheus Server is Healthy.

# æª¢æŸ¥è¨­å®š
curl http://localhost:9090/api/v1/status/config

# é–‹å•Ÿ Web UI
# http://<server-ip>:9090
```

### 3.3 Grafana å®‰è£

#### æ–¹æ³•ä¸€ï¼šBinary / Package å®‰è£

```bash
# CentOS/RHEL
cat > /etc/yum.repos.d/grafana.repo << 'EOF'
[grafana]
name=grafana
baseurl=https://rpm.grafana.com
repo_gpgcheck=1
enabled=1
gpgcheck=1
gpgkey=https://rpm.grafana.com/gpg.key
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
EOF

sudo yum install grafana -y

# Ubuntu/Debian
sudo apt-get install -y apt-transport-https software-properties-common
wget -q -O - https://apt.grafana.com/gpg.key | sudo apt-key add -
echo "deb https://apt.grafana.com stable main" | sudo tee /etc/apt/sources.list.d/grafana.list
sudo apt-get update
sudo apt-get install grafana -y

# å•Ÿå‹•æœå‹™
sudo systemctl daemon-reload
sudo systemctl enable grafana-server
sudo systemctl start grafana-server
```

#### æ–¹æ³•äºŒï¼šDocker å®‰è£

```bash
# å»ºç«‹è³‡æ–™ç›®éŒ„
mkdir -p /data/grafana

# è¨­å®šæ¬Šé™ï¼ˆGrafana å®¹å™¨ä½¿ç”¨ UID 472ï¼‰
sudo chown -R 472:472 /data/grafana

# åŸ·è¡Œå®¹å™¨
docker run -d \
  --name grafana \
  --restart unless-stopped \
  -p 3000:3000 \
  -v /data/grafana:/var/lib/grafana \
  -e "GF_SECURITY_ADMIN_PASSWORD=your_secure_password" \
  -e "GF_USERS_ALLOW_SIGN_UP=false" \
  grafana/grafana:10.2.0
```

#### é©—è­‰å®‰è£

```bash
# æª¢æŸ¥æœå‹™ç‹€æ…‹
curl http://localhost:3000/api/health
# é æœŸå›æ‡‰: {"commit":"...","database":"ok","version":"10.2.0"}

# é–‹å•Ÿ Web UI
# http://<server-ip>:3000
# é è¨­å¸³è™Ÿ: admin / admin
```

### 3.4 Node Exporter å®‰è£

```bash
# ä¸‹è¼‰
cd /tmp
wget https://github.com/prometheus/node_exporter/releases/download/v1.7.0/node_exporter-1.7.0.linux-amd64.tar.gz
tar xvfz node_exporter-1.7.0.linux-amd64.tar.gz

# å®‰è£
sudo cp node_exporter-1.7.0.linux-amd64/node_exporter /usr/local/bin/
sudo useradd --no-create-home --shell /bin/false node_exporter

# å»ºç«‹ Service
sudo cat > /etc/systemd/system/node_exporter.service << 'EOF'
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter \
    --collector.systemd \
    --collector.processes

[Install]
WantedBy=multi-user.target
EOF

# å•Ÿå‹•
sudo systemctl daemon-reload
sudo systemctl enable node_exporter
sudo systemctl start node_exporter

# é©—è­‰
curl http://localhost:9100/metrics | head -20
```

### 3.5 ç›®éŒ„çµæ§‹èªªæ˜

```
/etc/prometheus/                    # Prometheus è¨­å®šç›®éŒ„
â”œâ”€â”€ prometheus.yml                  # ä¸»è¦è¨­å®šæª”
â”œâ”€â”€ rules/                          # å‘Šè­¦è¦å‰‡ç›®éŒ„
â”‚   â”œâ”€â”€ node_alerts.yml
â”‚   â””â”€â”€ app_alerts.yml
â”œâ”€â”€ consoles/                       # Console æ¨¡æ¿
â””â”€â”€ console_libraries/              # Console å‡½å¼åº«

/var/lib/prometheus/                # Prometheus è³‡æ–™ç›®éŒ„
â”œâ”€â”€ chunks_head/                    # è¨˜æ†¶é«”è³‡æ–™
â”œâ”€â”€ wal/                            # Write-Ahead Log
â””â”€â”€ <block_id>/                     # å£“ç¸®å¾Œçš„è³‡æ–™å€å¡Š

/etc/grafana/                       # Grafana è¨­å®šç›®éŒ„
â”œâ”€â”€ grafana.ini                     # ä¸»è¦è¨­å®šæª”
â””â”€â”€ provisioning/                   # è‡ªå‹•é…ç½®ç›®éŒ„
    â”œâ”€â”€ datasources/
    â”œâ”€â”€ dashboards/
    â””â”€â”€ notifiers/

/var/lib/grafana/                   # Grafana è³‡æ–™ç›®éŒ„
â”œâ”€â”€ grafana.db                      # SQLite è³‡æ–™åº«
â”œâ”€â”€ plugins/                        # å¤–æ›ç›®éŒ„
â””â”€â”€ png/                            # åœ–ç‰‡å¿«å–
```

### 3.6 å¸¸è¦‹å®‰è£éŒ¯èª¤èˆ‡æ’é™¤

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹å¼ |
|-----|------|---------|
| `permission denied` | æ¬Šé™ä¸è¶³ | `chown -R prometheus:prometheus /var/lib/prometheus` |
| `port already in use` | Port è¢«ä½”ç”¨ | `netstat -tlnp \| grep 9090` æ‰¾å‡ºä¸¦åœæ­¢ä½”ç”¨ç¨‹å¼ |
| `TSDB lock` | ä¸Šæ¬¡æœªæ­£å¸¸é—œé–‰ | åˆªé™¤ `/var/lib/prometheus/lock` |
| `scrape error` | ç¶²è·¯ä¸é€š | æª¢æŸ¥é˜²ç«ç‰†èˆ‡ç¶²è·¯é€£é€šæ€§ |
| `Grafana 503` | å¾Œç«¯æœªå•Ÿå‹• | æª¢æŸ¥ Grafana log `/var/log/grafana/grafana.log` |

#### é™¤éŒ¯æŒ‡ä»¤

```bash
# æª¢æŸ¥ Prometheus è¨­å®šèªæ³•
promtool check config /etc/prometheus/prometheus.yml

# æª¢æŸ¥å‘Šè­¦è¦å‰‡èªæ³•
promtool check rules /etc/prometheus/rules/*.yml

# æŸ¥çœ‹ Prometheus æ—¥èªŒ
journalctl -u prometheus -f

# æŸ¥çœ‹ Grafana æ—¥èªŒ
journalctl -u grafana-server -f

# æ¸¬è©¦ Exporter é€£é€šæ€§
curl -v http://target:9100/metrics
```

---

## 4. ç³»çµ±è¨­å®šï¼ˆConfigurationï¼‰

### 4.1 Prometheus è¨­å®š

#### prometheus.yml å®Œæ•´ç¯„ä¾‹

```yaml
# å…¨åŸŸè¨­å®š
global:
  scrape_interval: 15s          # é è¨­æŠ“å–é–“éš”
  evaluation_interval: 15s      # è¦å‰‡è©•ä¼°é–“éš”
  scrape_timeout: 10s           # æŠ“å–é€¾æ™‚
  external_labels:              # å¤–éƒ¨æ¨™ç±¤ï¼ˆç”¨æ–¼ Federationï¼‰
    environment: production
    region: taiwan

# Alertmanager è¨­å®š
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager1:9093
            - alertmanager2:9093
      timeout: 10s

# è¦å‰‡æª”æ¡ˆ
rule_files:
  - "/etc/prometheus/rules/*.yml"

# æŠ“å–è¨­å®š
scrape_configs:
  # Prometheus è‡ªèº«ç›£æ§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
    
  # Node Exporter - ä¸»æ©Ÿç›£æ§
  - job_name: 'node'
    static_configs:
      - targets:
          - 'server1:9100'
          - 'server2:9100'
          - 'server3:9100'
    relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):\d+'
        target_label: instance
        replacement: '${1}'

  # JVM æ‡‰ç”¨ç¨‹å¼ç›£æ§
  - job_name: 'jvm-apps'
    metrics_path: /actuator/prometheus
    static_configs:
      - targets:
          - 'app1:8080'
          - 'app2:8080'
        labels:
          application: 'order-service'
          team: 'backend'

  # Kubernetes Service Discovery
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

# é ç«¯å¯«å…¥ï¼ˆé¸ç”¨ï¼‰
remote_write:
  - url: "http://thanos-receive:19291/api/v1/receive"
    queue_config:
      capacity: 10000
      max_shards: 30
```

#### scrape_config é€²éšè¨­å®š

```yaml
scrape_configs:
  - job_name: 'secure-endpoint'
    scheme: https
    tls_config:
      ca_file: /etc/prometheus/ca.crt
      cert_file: /etc/prometheus/client.crt
      key_file: /etc/prometheus/client.key
      insecure_skip_verify: false
    basic_auth:
      username: prometheus
      password_file: /etc/prometheus/password
    static_configs:
      - targets: ['secure-server:443']

  - job_name: 'blackbox-http'
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
          - https://api.example.com/health
          - https://web.example.com
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter:9115
```

#### Job / Target / Label è¨­è¨ˆåŸå‰‡

| è¨­è¨ˆåŸå‰‡ | èªªæ˜ | ç¯„ä¾‹ |
|---------|------|------|
| **Job æŒ‰æœå‹™é¡å‹** | åŒé¡å‹æœå‹™æ­¸ç‚ºåŒä¸€ Job | `job: order-service` |
| **Target æŒ‰å¯¦ä¾‹** | æ¯å€‹å¯¦ä¾‹ä¸€å€‹ Target | `instance: order-1:8080` |
| **Label æ¨™æº–åŒ–** | çµ±ä¸€å‘½åã€é¿å…é«˜ Cardinality | `env`, `team`, `app` |

```yaml
# âœ… å¥½çš„è¨­è¨ˆ
labels:
  env: production
  team: backend
  app: order-service

# âŒ é¿å…çš„è¨­è¨ˆ
labels:
  request_id: abc123        # é«˜ Cardinality
  timestamp: 2024-01-01     # é«˜ Cardinality
  user_id: 12345            # é«˜ Cardinality
```

#### Retention èˆ‡æ•ˆèƒ½è€ƒé‡

```yaml
# å‘½ä»¤åˆ—åƒæ•¸
--storage.tsdb.retention.time=15d       # è³‡æ–™ä¿ç•™å¤©æ•¸
--storage.tsdb.retention.size=50GB      # è³‡æ–™ä¿ç•™å¤§å°ä¸Šé™
--storage.tsdb.wal-compression          # å•Ÿç”¨ WAL å£“ç¸®
--query.max-concurrency=20              # æœ€å¤§ä¸¦è¡ŒæŸ¥è©¢æ•¸
--query.timeout=2m                      # æŸ¥è©¢é€¾æ™‚
```

| åƒæ•¸ | å»ºè­°å€¼ | èªªæ˜ |
|-----|-------|------|
| `retention.time` | 15-30d | ä¾éœ€æ±‚èª¿æ•´ï¼Œè¶Šé•·ä½”ç”¨ç©ºé–“è¶Šå¤§ |
| `retention.size` | ä¾ç£ç¢Ÿå¤§å° | é”åˆ°ä¸Šé™è‡ªå‹•åˆªé™¤èˆŠè³‡æ–™ |
| `max-concurrency` | CPU æ ¸å¿ƒæ•¸ | é¿å…éè¼‰ |

### 4.2 Grafana è¨­å®š

#### Datasource è¨­å®šï¼ˆPrometheusï¼‰

**æ–¹æ³•ä¸€ï¼šWeb UI è¨­å®š**

1. ç™»å…¥ Grafana â†’ Configuration â†’ Data Sources
2. Add data source â†’ é¸æ“‡ Prometheus
3. å¡«å…¥è¨­å®šï¼š
   - URL: `http://prometheus:9090`
   - Access: Server (default)
   - Scrape interval: 15s

**æ–¹æ³•äºŒï¼šProvisioning è‡ªå‹•è¨­å®š**

```yaml
# /etc/grafana/provisioning/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: false
    jsonData:
      timeInterval: "15s"
      httpMethod: POST
      exemplarTraceIdDestinations:
        - name: traceID
          datasourceUid: jaeger

  - name: Prometheus-DR
    type: prometheus
    access: proxy
    url: http://prometheus-dr:9090
    editable: false
```

#### Dashboard çµæ§‹è¨­è¨ˆåŸå‰‡

```mermaid
graph TB
    subgraph "Dashboard å±¤ç´šè¨­è¨ˆ"
        L1[Overview Dashboard<br/>ç®¡ç†å±¤ - å…¨å±€æ¦‚è¦½]
        L2[Service Dashboard<br/>ç¶­é‹å±¤ - æœå‹™ç‹€æ…‹]
        L3[Debug Dashboard<br/>é–‹ç™¼å±¤ - è©³ç´°æŒ‡æ¨™]
    end
    
    L1 --> L2
    L2 --> L3
```

| å±¤ç´š | å°è±¡ | å…§å®¹ | æ›´æ–°é »ç‡ |
|-----|------|------|---------|
| **Overview** | ä¸»ç®¡/å€¼ç­ | SLAã€éŒ¯èª¤ç‡ã€é—œéµå‘Šè­¦ | 5 åˆ†é˜ |
| **Service** | SRE/ç¶­é‹ | æœå‹™å¥åº·åº¦ã€è³‡æºä½¿ç”¨ | 1 åˆ†é˜ |
| **Debug** | é–‹ç™¼äººå“¡ | è©³ç´°æŒ‡æ¨™ã€Latency åˆ†å¸ƒ | å³æ™‚ |

#### Variableï¼ˆè®Šæ•¸ï¼‰ä½¿ç”¨æ–¹å¼

```json
{
  "templating": {
    "list": [
      {
        "name": "environment",
        "type": "custom",
        "options": [
          {"text": "Production", "value": "prod"},
          {"text": "Staging", "value": "stage"},
          {"text": "Development", "value": "dev"}
        ],
        "current": {"text": "Production", "value": "prod"}
      },
      {
        "name": "instance",
        "type": "query",
        "datasource": "Prometheus",
        "query": "label_values(up{job=\"node\"}, instance)",
        "refresh": 2,
        "multi": true,
        "includeAll": true
      },
      {
        "name": "interval",
        "type": "interval",
        "options": [
          {"text": "1m", "value": "1m"},
          {"text": "5m", "value": "5m"},
          {"text": "1h", "value": "1h"}
        ],
        "auto": true,
        "auto_min": "1m"
      }
    ]
  }
}
```

**åœ¨ Panel ä¸­ä½¿ç”¨è®Šæ•¸ï¼š**

```promql
# ä½¿ç”¨å–®é¸è®Šæ•¸
node_cpu_seconds_total{instance="$instance"}

# ä½¿ç”¨å¤šé¸è®Šæ•¸
node_cpu_seconds_total{instance=~"$instance"}

# ä½¿ç”¨ interval è®Šæ•¸
rate(http_requests_total[$interval])
```

#### Folder èˆ‡æ¬Šé™ç®¡ç†

```yaml
# /etc/grafana/provisioning/dashboards/default.yml
apiVersion: 1

providers:
  - name: 'Infrastructure'
    orgId: 1
    folder: 'Infrastructure'
    type: file
    disableDeletion: true
    editable: false
    options:
      path: /var/lib/grafana/dashboards/infrastructure

  - name: 'Applications'
    orgId: 1
    folder: 'Applications'
    type: file
    disableDeletion: true
    editable: false
    options:
      path: /var/lib/grafana/dashboards/applications
```

**æ¬Šé™è¨­è¨ˆå»ºè­°ï¼š**

| è§’è‰² | Folder æ¬Šé™ | èªªæ˜ |
|-----|------------|------|
| **Admin** | å…¨éƒ¨ Edit | ç³»çµ±ç®¡ç†å“¡ |
| **SRE** | Infrastructure: Edit, Apps: View | ç¶­é‹åœ˜éšŠ |
| **Developer** | Applications: Edit | é–‹ç™¼åœ˜éšŠ |
| **Viewer** | å…¨éƒ¨ View | ä¸€èˆ¬ä½¿ç”¨è€… |

---

## 5. ç³»çµ±ä½¿ç”¨ï¼ˆUsageï¼‰

### 5.1 PromQL åŸºæœ¬èˆ‡é€²éšèªæ³•

#### åŸºæœ¬èªæ³•

```promql
# å³æ™‚æŸ¥è©¢ - Instant Vector
http_requests_total

# å¸¶ Label éæ¿¾
http_requests_total{job="api", status="200"}

# ç¯„åœæŸ¥è©¢ - Range Vector
http_requests_total[5m]

# Label åŒ¹é…é‹ç®—å­
http_requests_total{status="200"}        # å®Œå…¨åŒ¹é…
http_requests_total{status!="500"}       # ä¸ç­‰æ–¼
http_requests_total{status=~"2.."}       # æ­£å‰‡åŒ¹é…
http_requests_total{status!~"5.."}       # æ­£å‰‡ä¸åŒ¹é…
```

#### å¸¸ç”¨å‡½æ•¸

```promql
# rate() - è¨ˆç®—æ¯ç§’å¢é•·ç‡ï¼ˆCounter å°ˆç”¨ï¼‰
rate(http_requests_total[5m])

# irate() - ç¬æ™‚å¢é•·ç‡ï¼ˆæ›´æ•æ„Ÿï¼‰
irate(http_requests_total[5m])

# increase() - å€é–“å…§å¢é‡
increase(http_requests_total[1h])

# sum() - åŠ ç¸½
sum(rate(http_requests_total[5m])) by (job)

# avg() - å¹³å‡
avg(node_cpu_seconds_total{mode="idle"}) by (instance)

# max() / min() - æœ€å¤§/æœ€å°å€¼
max(node_memory_MemAvailable_bytes) by (instance)

# histogram_quantile() - ç™¾åˆ†ä½æ•¸
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))
```

#### é€²éšæŸ¥è©¢ç¯„ä¾‹

```promql
# è¨ˆç®— CPU ä½¿ç”¨ç‡
100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# è¨ˆç®—è¨˜æ†¶é«”ä½¿ç”¨ç‡
(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100

# è¨ˆç®—ç£ç¢Ÿä½¿ç”¨ç‡
(1 - node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} 
    / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"}) * 100

# HTTP éŒ¯èª¤ç‡
sum(rate(http_requests_total{status=~"5.."}[5m])) 
  / sum(rate(http_requests_total[5m])) * 100

# P99 Latency
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint))

# é æ¸¬ç£ç¢Ÿç©ºé–“ï¼ˆç·šæ€§å›æ­¸ï¼‰
predict_linear(node_filesystem_avail_bytes[1h], 24*3600)
```

### 5.2 å¸¸è¦‹ Metrics ç¯„ä¾‹

#### CPU Metrics

```promql
# CPU ä½¿ç”¨ç‡ï¼ˆæŒ‰æ¨¡å¼ï¼‰
sum by (mode) (rate(node_cpu_seconds_total[5m]))

# ç³»çµ±è² è¼‰
node_load1   # 1 åˆ†é˜å¹³å‡
node_load5   # 5 åˆ†é˜å¹³å‡
node_load15  # 15 åˆ†é˜å¹³å‡

# CPU é£½å’Œåº¦ï¼ˆLoad > CPU æ•¸é‡ï¼‰
node_load1 / count without(cpu, mode) (node_cpu_seconds_total{mode="idle"})
```

#### Memory Metrics

```promql
# è¨˜æ†¶é«”å¯ç”¨é‡
node_memory_MemAvailable_bytes

# è¨˜æ†¶é«”ä½¿ç”¨é‡
node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes

# Swap ä½¿ç”¨é‡
node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes
```

#### Disk Metrics

```promql
# ç£ç¢Ÿå¯ç”¨ç©ºé–“
node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"}

# ç£ç¢Ÿ I/O é€Ÿç‡
rate(node_disk_read_bytes_total[5m])
rate(node_disk_written_bytes_total[5m])

# ç£ç¢Ÿ IOPS
rate(node_disk_reads_completed_total[5m])
rate(node_disk_writes_completed_total[5m])
```

#### JVM Metricsï¼ˆSpring Boot Actuatorï¼‰

```promql
# Heap ä½¿ç”¨é‡
jvm_memory_used_bytes{area="heap"}
jvm_memory_max_bytes{area="heap"}

# GC æ¬¡æ•¸èˆ‡æ™‚é–“
rate(jvm_gc_pause_seconds_count[5m])
rate(jvm_gc_pause_seconds_sum[5m])

# åŸ·è¡Œç·’æ•¸
jvm_threads_live_threads
jvm_threads_peak_threads
```

#### HTTP Metrics

```promql
# è«‹æ±‚é€Ÿç‡ (QPS)
sum(rate(http_server_requests_seconds_count[5m])) by (uri)

# å¹³å‡å»¶é²
rate(http_server_requests_seconds_sum[5m]) 
  / rate(http_server_requests_seconds_count[5m])

# éŒ¯èª¤ç‡
sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) 
  / sum(rate(http_server_requests_seconds_count[5m])) * 100
```

### 5.3 Dashboard è¨­è¨ˆæœ€ä½³å¯¦å‹™

#### Dashboard çµæ§‹ç¯„æœ¬

```mermaid
graph TB
    subgraph "Dashboard Layout"
        R1[Row 1: é—œéµæŒ‡æ¨™ KPI]
        R2[Row 2: è¶¨å‹¢åœ–è¡¨]
        R3[Row 3: ç´°ç¯€è¡¨æ ¼]
        R4[Row 4: å‘Šè­¦ç‹€æ…‹]
    end
    
    R1 --> |"Stat Panel"| KPI1[QPS]
    R1 --> |"Stat Panel"| KPI2[Error Rate]
    R1 --> |"Stat Panel"| KPI3[P99 Latency]
    
    R2 --> |"Time Series"| T1[æµé‡è¶¨å‹¢]
    R2 --> |"Time Series"| T2[å»¶é²åˆ†å¸ƒ]
    
    R3 --> |"Table"| TB1[Top 10 æ…¢æŸ¥è©¢]
    R4 --> |"Alert List"| AL1[å‘Šè­¦æ¸…å–®]
```

#### Panel é¡å‹é¸æ“‡æŒ‡å—

| Panel é¡å‹ | é©ç”¨å ´æ™¯ | ç¯„ä¾‹ |
|-----------|---------|------|
| **Stat** | å–®ä¸€æ•¸å€¼ KPI | QPSã€éŒ¯èª¤ç‡ã€å¯ç”¨æ€§ |
| **Gauge** | ç™¾åˆ†æ¯”ã€ä½¿ç”¨ç‡ | CPU%ã€Memory%ã€Disk% |
| **Time Series** | è¶¨å‹¢è®ŠåŒ– | æµé‡ã€å»¶é²ã€è³‡æºä½¿ç”¨ |
| **Bar Chart** | æ’åã€æ¯”è¼ƒ | Top N æœå‹™ã€éŒ¯èª¤åˆ†å¸ƒ |
| **Heatmap** | åˆ†å¸ƒåœ– | Latency åˆ†å¸ƒ |
| **Table** | æ˜ç´°è³‡æ–™ | å‘Šè­¦æ¸…å–®ã€æœå‹™åˆ—è¡¨ |
| **Logs** | æ—¥èªŒæª¢è¦– | éŒ¯èª¤æ—¥èªŒ |

### 5.4 å¯¦å‹™ç¯„ä¾‹

#### ç¯„ä¾‹ä¸€ï¼šAPI å»¶é² Dashboard

```json
{
  "panels": [
    {
      "title": "P99 Latency",
      "type": "stat",
      "targets": [
        {
          "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{job=\"api\"}[5m])) by (le))",
          "legendFormat": "P99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "thresholds": {
            "steps": [
              {"color": "green", "value": null},
              {"color": "yellow", "value": 0.5},
              {"color": "red", "value": 1}
            ]
          }
        }
      }
    },
    {
      "title": "Latency Distribution",
      "type": "heatmap",
      "targets": [
        {
          "expr": "sum(rate(http_request_duration_seconds_bucket{job=\"api\"}[5m])) by (le)",
          "format": "heatmap"
        }
      ]
    }
  ]
}
```

#### ç¯„ä¾‹äºŒï¼šBatch æˆåŠŸç‡ Dashboard

```promql
# Batch åŸ·è¡ŒæˆåŠŸç‡
sum(batch_job_completed_total{status="success"}) 
  / sum(batch_job_completed_total) * 100

# Batch åŸ·è¡Œæ™‚é–“
batch_job_duration_seconds{quantile="0.99"}

# å¤±æ•—çš„ Batch Jobs
batch_job_completed_total{status="failed"}
```

### 5.5 èˆ‡ AI æ­é…ä½¿ç”¨

#### è«‹ AI ç”¢ç”Ÿ PromQL çš„ Prompt ç¯„ä¾‹

```
ä½ æ˜¯ Prometheus å°ˆå®¶ã€‚è«‹å¹«æˆ‘å¯« PromQL æŸ¥è©¢ï¼š

éœ€æ±‚ï¼š
- è¨ˆç®—éå» 5 åˆ†é˜å…§ï¼Œæ‰€æœ‰ API endpoint çš„ P95 å»¶é²
- ä¾æ“š endpoint åˆ†çµ„
- åªé¡¯ç¤ºå»¶é²è¶…é 500ms çš„ endpoint

å¯ç”¨çš„ Metricsï¼š
- http_request_duration_seconds_bucket (Histogram)
- Labels: job, endpoint, method, status
```

#### AI å”åŠ© Dashboard è¨­è¨ˆ

```
è«‹å¹«æˆ‘è¨­è¨ˆä¸€å€‹ã€ŒJVM ç›£æ§ Dashboardã€çš„ JSON çµæ§‹ï¼š

éœ€æ±‚ï¼š
1. ç¬¬ä¸€è¡Œï¼š4 å€‹ Stat Panelï¼ˆHeap ä½¿ç”¨ç‡ã€GC æ¬¡æ•¸ã€Thread æ•¸ã€Uptimeï¼‰
2. ç¬¬äºŒè¡Œï¼šHeap ä½¿ç”¨è¶¨å‹¢åœ–ã€GC æš«åœæ™‚é–“è¶¨å‹¢åœ–
3. ç¬¬ä¸‰è¡Œï¼šThread ç‹€æ…‹åˆ†å¸ƒã€Class è¼‰å…¥æ•¸é‡

è«‹ä½¿ç”¨ Grafana Dashboard JSON æ ¼å¼è¼¸å‡ºã€‚
```

---

## 6. å‘Šè­¦èˆ‡é€šçŸ¥ï¼ˆAlertingï¼‰

### 6.1 Prometheus Alertmanager æ¶æ§‹

```mermaid
graph LR
    subgraph "Prometheus"
        P[Prometheus Server]
        AR[Alert Rules]
        P --> AR
    end
    
    subgraph "Alertmanager"
        R[Receiver]
        G[Grouping]
        I[Inhibition]
        S[Silencing]
        R --> G --> I --> S
    end
    
    subgraph "é€šçŸ¥ç®¡é“"
        Email[Email]
        Teams[MS Teams]
        Slack[Slack]
        PD[PagerDuty]
    end
    
    AR -->|è§¸ç™¼| R
    S --> Email
    S --> Teams
    S --> Slack
    S --> PD
```

#### Alertmanager è¨­å®šç¯„ä¾‹

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'alertmanager'
  smtp_auth_password: 'password'

route:
  receiver: 'default'
  group_by: ['alertname', 'env', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  routes:
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      continue: true
    - match:
        severity: critical
      receiver: 'slack-critical'
    - match:
        severity: warning
      receiver: 'slack-warning'

receivers:
  - name: 'default'
    email_configs:
      - to: 'ops-team@example.com'

  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '<your-service-key>'
        severity: critical

  - name: 'slack-critical'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/xxx'
        channel: '#alerts-critical'
        title: 'ğŸš¨ Critical Alert'
        text: '{{ .CommonAnnotations.description }}'

  - name: 'slack-warning'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/xxx'
        channel: '#alerts-warning'
        title: 'âš ï¸ Warning Alert'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
```

### 6.2 Alert Rule æ’°å¯«ç¯„ä¾‹

```yaml
# /etc/prometheus/rules/node_alerts.yml
groups:
  - name: node_alerts
    rules:
      # CPU é«˜ä½¿ç”¨ç‡å‘Šè­¦
      - alert: HighCpuUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | printf \"%.2f\" }}% on {{ $labels.instance }}"

      # CPU æ¥µé«˜ä½¿ç”¨ç‡å‘Šè­¦
      - alert: CriticalCpuUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | printf \"%.2f\" }}% on {{ $labels.instance }}"

      # è¨˜æ†¶é«”ä¸è¶³å‘Šè­¦
      - alert: LowMemory
        expr: (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low memory on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | printf \"%.2f\" }}%"

      # ç£ç¢Ÿç©ºé–“ä¸è¶³å‘Šè­¦
      - alert: LowDiskSpace
        expr: (1 - node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk usage is {{ $value | printf \"%.2f\" }}% on {{ $labels.mountpoint }}"

      # æœå‹™ Down å‘Šè­¦
      - alert: InstanceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Instance {{ $labels.instance }} is down"
          description: "{{ $labels.job }} on {{ $labels.instance }} has been down for more than 1 minute"
```

```yaml
# /etc/prometheus/rules/app_alerts.yml
groups:
  - name: application_alerts
    rules:
      # API éŒ¯èª¤ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: |
          sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) by (application)
          / sum(rate(http_server_requests_seconds_count[5m])) by (application) * 100 > 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate on {{ $labels.application }}"
          description: "Error rate is {{ $value | printf \"%.2f\" }}%"

      # API å»¶é²å‘Šè­¦
      - alert: HighLatency
        expr: |
          histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, application)) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High P99 latency on {{ $labels.application }}"
          description: "P99 latency is {{ $value | printf \"%.2f\" }}s"

      # JVM Heap å‘Šè­¦
      - alert: JvmHeapHigh
        expr: jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"} * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High JVM heap usage on {{ $labels.application }}"
          description: "Heap usage is {{ $value | printf \"%.2f\" }}%"
```

### 6.3 å‘Šè­¦åˆ†ç´š

| åš´é‡åº¦ | å®šç¾© | å›æ‡‰æ™‚é–“ | é€šçŸ¥æ–¹å¼ |
|-------|------|---------|---------|
| **Critical** | æœå‹™ä¸­æ–·ã€è³‡æ–™éºå¤±é¢¨éšª | ç«‹å³ | PagerDuty + Slack + Email |
| **Warning** | æ•ˆèƒ½ä¸‹é™ã€éœ€é—œæ³¨ | 1 å°æ™‚å…§ | Slack + Email |
| **Info** | è³‡è¨Šæ€§é€šçŸ¥ | ä¸‹å€‹å·¥ä½œæ—¥ | Email |

### 6.4 Grafana Alert èˆ‡ Prometheus Alert å·®ç•°

| é …ç›® | Prometheus Alertmanager | Grafana Alerting |
|-----|------------------------|------------------|
| **è³‡æ–™ä¾†æº** | åƒ… Prometheus | å¤šè³‡æ–™æºï¼ˆPrometheusã€ES ç­‰ï¼‰ |
| **è¦å‰‡ç®¡ç†** | YAML æª”æ¡ˆ | Web UI |
| **åŠŸèƒ½** | é€²éšè·¯ç”±ã€æŠ‘åˆ¶ã€éœé»˜ | ç°¡æ˜“è¨­å®šã€çµ±ä¸€å‘Šè­¦ |
| **é©ç”¨å ´æ™¯** | å¤§å‹è¤‡é›œç’°å¢ƒ | ä¸­å°å‹ç’°å¢ƒã€å¿«é€Ÿè¨­å®š |

#### ğŸ’¡ å»ºè­°
> - **ç”Ÿç”¢ç’°å¢ƒ**ï¼šä½¿ç”¨ Prometheus Alertmanagerï¼ˆåŠŸèƒ½å®Œæ•´ã€å¯ç‰ˆæ§ï¼‰
> - **é–‹ç™¼/æ¸¬è©¦**ï¼šå¯ç”¨ Grafana Alertingï¼ˆå¿«é€Ÿè¨­å®šï¼‰

### 6.5 èˆ‡ Teams / Slack æ•´åˆ

#### Microsoft Teams Webhook

```yaml
# alertmanager.yml
receivers:
  - name: 'teams-alerts'
    webhook_configs:
      - url: 'https://outlook.office.com/webhook/xxx'
        send_resolved: true
```

éœ€æ­é… Prometheus-MS-Teamsï¼ˆhttps://github.com/prometheus-msteams/prometheus-msteamsï¼‰

#### Slack Webhook

```yaml
receivers:
  - name: 'slack-alerts'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/T00/B00/xxx'
        channel: '#alerts'
        username: 'Prometheus'
        icon_emoji: ':prometheus:'
        title: '{{ .Status | toUpper }}{{ if eq .Status "firing" }} ğŸ”¥{{ else }} âœ…{{ end }}'
        text: >-
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}
```

---

## 7. ç³»çµ±ç¶­è­·ï¼ˆMaintenanceï¼‰

### 7.1 è³‡æ–™æˆé•·èˆ‡ç£ç¢Ÿç©ºé–“ç®¡ç†

#### é ä¼°å„²å­˜ç©ºé–“

```
å„²å­˜ç©ºé–“ = æ™‚åºæ•¸é‡ Ã— æ¯ç§’æ¨£æœ¬æ•¸ Ã— æ¯æ¨£æœ¬å¤§å° Ã— ä¿ç•™å¤©æ•¸

ç¯„ä¾‹ï¼š
- 10,000 å€‹æ™‚åº
- æ¯ 15 ç§’ä¸€å€‹æ¨£æœ¬
- æ¯æ¨£æœ¬ç´„ 2 bytes
- ä¿ç•™ 15 å¤©

= 10,000 Ã— (86400/15) Ã— 2 Ã— 15
= 10,000 Ã— 5,760 Ã— 2 Ã— 15
â‰ˆ 1.7 GBï¼ˆå£“ç¸®å¾Œç´„ 0.5 GBï¼‰
```

#### ç›£æ§å„²å­˜ç©ºé–“

```promql
# TSDB ç›®å‰å¤§å°
prometheus_tsdb_storage_blocks_bytes

# æ™‚åºæ•¸é‡
prometheus_tsdb_head_series

# æ¨£æœ¬æ•¸é‡
prometheus_tsdb_head_samples_appended_total

# WAL å¤§å°
prometheus_tsdb_wal_storage_size_bytes
```

#### ç©ºé–“æ¸…ç†ç­–ç•¥

```bash
# æ–¹æ³•ä¸€ï¼šèª¿æ•´ä¿ç•™æ™‚é–“
--storage.tsdb.retention.time=7d

# æ–¹æ³•äºŒï¼šè¨­å®šå¤§å°ä¸Šé™
--storage.tsdb.retention.size=30GB

# æ–¹æ³•ä¸‰ï¼šæ‰‹å‹•è§¸ç™¼å£“ç¸®ï¼ˆè¬¹æ…ä½¿ç”¨ï¼‰
curl -X POST http://localhost:9090/api/v1/admin/tsdb/clean_tombstones

# æ–¹æ³•å››ï¼šåˆªé™¤éæœŸè³‡æ–™ï¼ˆéœ€å•Ÿç”¨ admin APIï¼‰
curl -X POST http://localhost:9090/api/v1/admin/tsdb/delete_series \
  -d 'match[]=http_requests_total{job="old-service"}'
```

### 7.2 æ•ˆèƒ½èª¿æ ¡å»ºè­°

#### Prometheus æ•ˆèƒ½èª¿æ ¡

```yaml
# å¢åŠ æŠ“å–ä¸¦è¡Œåº¦
global:
  scrape_interval: 15s
  scrape_timeout: 10s

# åœ¨ scrape_config ä¸­é™åˆ¶æ¨£æœ¬æ•¸
scrape_configs:
  - job_name: 'high-cardinality-job'
    sample_limit: 10000  # æ¯æ¬¡æŠ“å–æœ€å¤šæ¨£æœ¬æ•¸
```

```bash
# å‘½ä»¤åˆ—èª¿æ ¡åƒæ•¸
--storage.tsdb.min-block-duration=2h
--storage.tsdb.max-block-duration=36h
--query.max-samples=50000000
--query.timeout=2m
```

#### Grafana æ•ˆèƒ½èª¿æ ¡

```ini
# /etc/grafana/grafana.ini
[server]
concurrent_render_request_limit = 30

[database]
max_idle_conn = 25
max_open_conn = 100
conn_max_lifetime = 14400

[dashboards]
min_refresh_interval = 15s

[dataproxy]
timeout = 60
```

### 7.3 å¸¸è¦‹å•é¡Œè™•ç†

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹å¼ |
|-----|------|---------|
| **æŒ‡æ¨™çˆ†é‡** | Label Cardinality éé«˜ | æª¢æŸ¥ä¸¦ç§»é™¤é«˜ Cardinality Label |
| **æŸ¥è©¢è®Šæ…¢** | æ™‚åºéå¤šã€ç¯„åœéå¤§ | ä½¿ç”¨ Recording Rulesã€ç¸®å°æŸ¥è©¢ç¯„åœ |
| **è¨˜æ†¶é«”ä¸è¶³** | å¤ªå¤š head series | å¢åŠ è¨˜æ†¶é«”æˆ–æ¸›å°‘ä¿ç•™æ™‚é–“ |
| **æŠ“å–å¤±æ•—** | ç¶²è·¯å•é¡Œæˆ– Target éè¼‰ | æª¢æŸ¥ç¶²è·¯ã€å¢åŠ  scrape_timeout |
| **WAL æå£** | éæ­£å¸¸é—œæ©Ÿ | å‚™ä»½å¾Œåˆªé™¤ WALï¼Œé‡å•Ÿæœå‹™ |

#### Recording Rules å„ªåŒ–æŸ¥è©¢

```yaml
# /etc/prometheus/rules/recording_rules.yml
groups:
  - name: recording_rules
    interval: 1m
    rules:
      # é å…ˆè¨ˆç®— CPU ä½¿ç”¨ç‡
      - record: instance:node_cpu_utilization:avg5m
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

      # é å…ˆè¨ˆç®— HTTP éŒ¯èª¤ç‡
      - record: job:http_error_rate:5m
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
          / sum(rate(http_requests_total[5m])) by (job) * 100

      # é å…ˆè¨ˆç®— P99 å»¶é²
      - record: job:http_latency_p99:5m
        expr: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job))
```

### 7.4 å‚™ä»½èˆ‡é‚„åŸç­–ç•¥

#### Prometheus å‚™ä»½

```bash
# æ–¹æ³•ä¸€ï¼šå¿«ç…§å‚™ä»½ï¼ˆæ¨è–¦ï¼‰
curl -X POST http://localhost:9090/api/v1/admin/tsdb/snapshot
# å¿«ç…§æœƒå­˜æ”¾åœ¨ /var/lib/prometheus/snapshots/

# æ–¹æ³•äºŒï¼šåœæ©Ÿå‚™ä»½
sudo systemctl stop prometheus
tar -czvf prometheus-backup-$(date +%Y%m%d).tar.gz /var/lib/prometheus/
sudo systemctl start prometheus

# æ–¹æ³•ä¸‰ï¼šé ç«¯å„²å­˜
# è¨­å®š remote_write åˆ° Thanos / Cortex
```

#### Prometheus é‚„åŸ

```bash
# å¾å¿«ç…§é‚„åŸ
sudo systemctl stop prometheus
rm -rf /var/lib/prometheus/*
cp -r /var/lib/prometheus/snapshots/<snapshot-id>/* /var/lib/prometheus/
sudo chown -R prometheus:prometheus /var/lib/prometheus
sudo systemctl start prometheus
```

#### Grafana å‚™ä»½

```bash
# å‚™ä»½è³‡æ–™åº«
cp /var/lib/grafana/grafana.db /backup/grafana-$(date +%Y%m%d).db

# å‚™ä»½ provisioning è¨­å®š
tar -czvf grafana-provisioning-$(date +%Y%m%d).tar.gz /etc/grafana/provisioning/

# ä½¿ç”¨ API åŒ¯å‡º Dashboard
curl -H "Authorization: Bearer <api-key>" \
  http://localhost:3000/api/dashboards/uid/<uid> > dashboard-backup.json
```

#### è‡ªå‹•å‚™ä»½è…³æœ¬

```bash
#!/bin/bash
# backup-monitoring.sh

BACKUP_DIR="/backup/monitoring"
DATE=$(date +%Y%m%d)

# Prometheus å¿«ç…§
curl -X POST http://localhost:9090/api/v1/admin/tsdb/snapshot

# Grafana è³‡æ–™åº«
cp /var/lib/grafana/grafana.db $BACKUP_DIR/grafana-$DATE.db

# æ¸…ç† 7 å¤©å‰çš„å‚™ä»½
find $BACKUP_DIR -type f -mtime +7 -delete

echo "Backup completed: $DATE"
```

---

## 8. ç³»çµ±å‡ç´šï¼ˆUpgradeï¼‰

### 8.1 Prometheus å‡ç´šæ³¨æ„äº‹é …

#### å‡ç´šå‰æº–å‚™

```bash
# 1. æª¢æŸ¥ç‰ˆæœ¬ç›¸å®¹æ€§
# åƒè€ƒï¼šhttps://prometheus.io/docs/prometheus/latest/migration/

# 2. å‚™ä»½è³‡æ–™
curl -X POST http://localhost:9090/api/v1/admin/tsdb/snapshot

# 3. å‚™ä»½è¨­å®š
cp -r /etc/prometheus /etc/prometheus.bak

# 4. é©—è­‰è¨­å®šæª”
promtool check config /etc/prometheus/prometheus.yml
promtool check rules /etc/prometheus/rules/*.yml
```

#### å‡ç´šæ­¥é©Ÿ

```bash
# 1. ä¸‹è¼‰æ–°ç‰ˆæœ¬
wget https://github.com/prometheus/prometheus/releases/download/v2.50.0/prometheus-2.50.0.linux-amd64.tar.gz

# 2. è§£å£“ç¸®
tar xvfz prometheus-2.50.0.linux-amd64.tar.gz

# 3. åœæ­¢æœå‹™
sudo systemctl stop prometheus

# 4. å‚™ä»½èˆŠç‰ˆæœ¬
sudo mv /usr/local/bin/prometheus /usr/local/bin/prometheus.old
sudo mv /usr/local/bin/promtool /usr/local/bin/promtool.old

# 5. å®‰è£æ–°ç‰ˆæœ¬
sudo cp prometheus-2.50.0.linux-amd64/prometheus /usr/local/bin/
sudo cp prometheus-2.50.0.linux-amd64/promtool /usr/local/bin/

# 6. å•Ÿå‹•æœå‹™
sudo systemctl start prometheus

# 7. é©—è­‰
prometheus --version
curl http://localhost:9090/-/healthy
```

### 8.2 Grafana å‡ç´šæ³¨æ„äº‹é …

#### å‡ç´šå‰æº–å‚™

```bash
# 1. å‚™ä»½è³‡æ–™åº«
cp /var/lib/grafana/grafana.db /backup/

# 2. å‚™ä»½è¨­å®š
cp /etc/grafana/grafana.ini /backup/

# 3. åŒ¯å‡ºé‡è¦ Dashboard
# ä½¿ç”¨ Web UI æˆ– API åŒ¯å‡º
```

#### å‡ç´šæ­¥é©Ÿï¼ˆPackage Managerï¼‰

```bash
# CentOS/RHEL
sudo yum update grafana

# Ubuntu/Debian
sudo apt-get update
sudo apt-get install --only-upgrade grafana

# é‡å•Ÿæœå‹™
sudo systemctl restart grafana-server
```

#### å‡ç´šæ­¥é©Ÿï¼ˆDockerï¼‰

```bash
# 1. æ‹‰å–æ–°ç‰ˆæœ¬
docker pull grafana/grafana:10.3.0

# 2. åœæ­¢èˆŠå®¹å™¨
docker stop grafana

# 3. ç§»é™¤èˆŠå®¹å™¨ï¼ˆè³‡æ–™å·ä¿ç•™ï¼‰
docker rm grafana

# 4. å•Ÿå‹•æ–°å®¹å™¨
docker run -d \
  --name grafana \
  --restart unless-stopped \
  -p 3000:3000 \
  -v /data/grafana:/var/lib/grafana \
  grafana/grafana:10.3.0
```

### 8.3 å‡ç´šå‰æª¢æŸ¥æ¸…å–®

| é …ç›® | æª¢æŸ¥å…§å®¹ | ç‹€æ…‹ |
|-----|---------|------|
| **ç‰ˆæœ¬ç›¸å®¹æ€§** | æŸ¥é–± Release Notesã€Breaking Changes | â˜ |
| **è³‡æ–™å‚™ä»½** | Prometheus å¿«ç…§ã€Grafana DB | â˜ |
| **è¨­å®šå‚™ä»½** | prometheus.ymlã€alertmanager.ymlã€grafana.ini | â˜ |
| **Dashboard å‚™ä»½** | åŒ¯å‡ºé‡è¦ Dashboard JSON | â˜ |
| **Alert Rule å‚™ä»½** | å‚™ä»½æ‰€æœ‰ Rule æª”æ¡ˆ | â˜ |
| **æ¸¬è©¦ç’°å¢ƒé©—è­‰** | åœ¨æ¸¬è©¦ç’°å¢ƒå…ˆè¡Œå‡ç´šæ¸¬è©¦ | â˜ |
| **å›æ»¾è¨ˆç•«** | æº–å‚™å›æ»¾è…³æœ¬èˆ‡æ­¥é©Ÿ | â˜ |
| **é€šçŸ¥ç›¸é—œäººå“¡** | é€šçŸ¥ç¶­é‹åœ˜éšŠå‡ç´šæ™‚é–“ | â˜ |

### 8.4 å›æ»¾ï¼ˆRollbackï¼‰ç­–ç•¥

```bash
# Prometheus å›æ»¾
sudo systemctl stop prometheus
sudo mv /usr/local/bin/prometheus /usr/local/bin/prometheus.new
sudo mv /usr/local/bin/prometheus.old /usr/local/bin/prometheus
sudo systemctl start prometheus

# Grafana å›æ»¾ï¼ˆä½¿ç”¨å‚™ä»½è³‡æ–™åº«ï¼‰
sudo systemctl stop grafana-server
cp /backup/grafana.db /var/lib/grafana/grafana.db
sudo yum downgrade grafana-<previous-version>  # æˆ–ä½¿ç”¨ apt
sudo systemctl start grafana-server
```

---

## 9. ä¼æ¥­å¯¦å‹™èˆ‡æœ€ä½³å¯¦è¸ï¼ˆBest Practicesï¼‰

### 9.1 æŒ‡æ¨™å‘½åè¦ç¯„

#### å‘½åè¦å‰‡

```
<namespace>_<subsystem>_<name>_<unit>_<suffix>

ç¯„ä¾‹ï¼š
http_server_requests_seconds_total      # HTTP è«‹æ±‚ç¸½æ•¸
http_server_requests_seconds_bucket     # HTTP è«‹æ±‚å»¶é²åˆ†å¸ƒ
jvm_memory_used_bytes                   # JVM è¨˜æ†¶é«”ä½¿ç”¨é‡
node_cpu_seconds_total                  # CPU ä½¿ç”¨æ™‚é–“
```

| çµ„æˆ | èªªæ˜ | ç¯„ä¾‹ |
|-----|------|------|
| **namespace** | æ‡‰ç”¨ç¨‹å¼æˆ–çµ„ç¹” | `myapp`, `order` |
| **subsystem** | å­ç³»çµ± | `server`, `client`, `db` |
| **name** | æŒ‡æ¨™åç¨± | `requests`, `errors`, `duration` |
| **unit** | å–®ä½ | `bytes`, `seconds`, `total` |
| **suffix** | é¡å‹å¾Œç¶´ | `_total` (Counter), `_bucket` (Histogram) |

#### âš ï¸ å‘½åç¦å¿Œ

```yaml
# âŒ éŒ¯èª¤ç¤ºç¯„
request_count          # ç¼ºå°‘å–®ä½
httpRequestDuration    # ä½¿ç”¨ camelCase
my.app.requests        # ä½¿ç”¨é»è™Ÿ
requests_2024          # åŒ…å«å¹´ä»½
```

### 9.2 Label è¨­è¨ˆåŸå‰‡

#### å¥½çš„ Label è¨­è¨ˆ

```yaml
# âœ… å¥½çš„è¨­è¨ˆ
labels:
  env: production          # ç’°å¢ƒ
  region: taiwan           # å€åŸŸ
  team: backend            # åœ˜éšŠ
  application: order-svc   # æ‡‰ç”¨ç¨‹å¼
  instance: order-1        # å¯¦ä¾‹
  method: GET              # HTTP æ–¹æ³•
  status: 200              # HTTP ç‹€æ…‹ç¢¼
  endpoint: /api/orders    # API ç«¯é»
```

#### é¿å…é«˜ Cardinality

```yaml
# âŒ é¿å…çš„è¨­è¨ˆ
labels:
  user_id: 12345           # ç”¨æˆ¶ IDï¼ˆæ•¸ç™¾è¬å€‹å€¼ï¼‰
  request_id: abc-123      # è«‹æ±‚ IDï¼ˆç„¡é™å¤šå€‹å€¼ï¼‰
  timestamp: 2024-01-01    # æ™‚é–“æˆ³
  email: user@example.com  # å€‹è³‡
  trace_id: xxxx           # è¿½è¹¤ ID
```

#### Cardinality ç›£æ§

```promql
# æŸ¥è©¢é«˜ Cardinality æŒ‡æ¨™
topk(10, count by (__name__)({__name__=~".+"}))

# æŸ¥è©¢ç‰¹å®šæŒ‡æ¨™çš„ Label æ•¸é‡
count(count by (user_id) (http_requests_total))
```

### 9.3 å¤šç’°å¢ƒè¨­è¨ˆï¼ˆDEV / SIT / UAT / PRODï¼‰

```mermaid
graph TB
    subgraph "Production"
        PP[Prometheus Prod]
        GP[Grafana Prod]
        PP --> GP
    end
    
    subgraph "Non-Production"
        PNP[Prometheus Non-Prod]
        GNP[Grafana Non-Prod]
        PNP --> GNP
    end
    
    subgraph "DEV"
        ED[Exporters DEV]
    end
    
    subgraph "SIT"
        ES[Exporters SIT]
    end
    
    subgraph "UAT"
        EU[Exporters UAT]
    end
    
    subgraph "PROD"
        EP[Exporters PROD]
    end
    
    ED --> PNP
    ES --> PNP
    EU --> PNP
    EP --> PP
```

#### è¨­å®šç¯„ä¾‹

```yaml
# prometheus-prod.yml
global:
  external_labels:
    env: production
    datacenter: primary

# prometheus-nonprod.yml
global:
  external_labels:
    env: non-production

scrape_configs:
  - job_name: 'dev-apps'
    static_configs:
      - targets: ['dev-app:8080']
        labels:
          env: dev

  - job_name: 'sit-apps'
    static_configs:
      - targets: ['sit-app:8080']
        labels:
          env: sit
```

### 9.4 èˆ‡ CI/CDã€Batchã€å¾®æœå‹™æ•´åˆ

#### CI/CD æ•´åˆ

```yaml
# GitLab CI ç¯„ä¾‹
deploy:
  stage: deploy
  script:
    - kubectl apply -f k8s/
  after_script:
    # é©—è­‰ Prometheus å·²æŠ“å–æ–°æœå‹™
    - |
      for i in {1..30}; do
        if curl -s "http://prometheus:9090/api/v1/targets" | grep -q "new-service"; then
          echo "Service registered in Prometheus"
          exit 0
        fi
        sleep 10
      done
      echo "Warning: Service not found in Prometheus"
```

#### Batch Job ç›£æ§

```java
// Spring Batch + Micrometer
@Component
public class BatchMetrics {
    private final MeterRegistry registry;
    
    public void recordJobExecution(String jobName, String status, Duration duration) {
        registry.counter("batch_job_executions_total", 
            "job", jobName, 
            "status", status).increment();
        
        registry.timer("batch_job_duration_seconds", 
            "job", jobName)
            .record(duration);
    }
}
```

```promql
# Batch ç›£æ§æŒ‡æ¨™
batch_job_executions_total{status="COMPLETED"}
batch_job_executions_total{status="FAILED"}
batch_job_duration_seconds
```

#### å¾®æœå‹™æ•´åˆï¼ˆService Meshï¼‰

```yaml
# Istio Prometheus æ•´åˆ
scrape_configs:
  - job_name: 'istio-mesh'
    kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
            - istio-system
    relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-telemetry;prometheus
```

### 9.5 éŠ€è¡Œèˆ‡é«˜ç©©å®šç³»çµ±å°å…¥å»ºè­°

#### æ¶æ§‹å»ºè­°

| é …ç›® | å»ºè­° |
|-----|------|
| **é«˜å¯ç”¨** | Prometheus HA + Alertmanager Cluster |
| **è³‡æ–™ä¿ç•™** | æ­é… Thanos / Cortex é•·æœŸå„²å­˜ |
| **å‚™ä»½** | æ¯æ—¥å¿«ç…§ + ç•°åœ°å‚™ä»½ |
| **å­˜å–æ§åˆ¶** | æ•´åˆ AD/LDAPã€å•Ÿç”¨ HTTPS |
| **ç¨½æ ¸** | å•Ÿç”¨ Grafana Audit Log |

#### å®‰å…¨æ€§å»ºè­°

```yaml
# Prometheus å•Ÿç”¨åŸºæœ¬èªè­‰
# éœ€æ­é…åå‘ä»£ç†ï¼ˆå¦‚ Nginxï¼‰

# Grafana å®‰å…¨è¨­å®š
[security]
admin_password = <strong-password>
secret_key = <random-key>
disable_gravatar = true
cookie_secure = true
cookie_samesite = strict

[auth]
disable_login_form = false
oauth_auto_login = true

[auth.ldap]
enabled = true
config_file = /etc/grafana/ldap.toml
```

#### ç¨½æ ¸éœ€æ±‚

```ini
# Grafana Audit Log
[log]
mode = file
level = info

[auditing]
enabled = true
log_file = /var/log/grafana/audit.log
```

---

## 10. é™„éŒ„ï¼ˆAppendixï¼‰

### 10.1 å¸¸ç”¨ PromQL Cheat Sheet

| ç”¨é€” | PromQL |
|-----|--------|
| **CPU ä½¿ç”¨ç‡** | `100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)` |
| **è¨˜æ†¶é«”ä½¿ç”¨ç‡** | `(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100` |
| **ç£ç¢Ÿä½¿ç”¨ç‡** | `(1 - node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100` |
| **HTTP QPS** | `sum(rate(http_requests_total[5m])) by (job)` |
| **HTTP éŒ¯èª¤ç‡** | `sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) * 100` |
| **P99 å»¶é²** | `histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))` |
| **JVM Heap** | `jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"} * 100` |
| **GC é »ç‡** | `rate(jvm_gc_pause_seconds_count[5m])` |
| **ç¶²è·¯æµé‡** | `rate(node_network_receive_bytes_total[5m])` |
| **ç£ç¢Ÿ IOPS** | `rate(node_disk_reads_completed_total[5m]) + rate(node_disk_writes_completed_total[5m])` |

### 10.2 æ¨è–¦ Exporter æ¸…å–®

| Exporter | ç›£æ§å°è±¡ | é è¨­ Port | GitHub |
|----------|---------|----------|--------|
| node_exporter | Linux ä¸»æ©Ÿ | 9100 | prometheus/node_exporter |
| windows_exporter | Windows ä¸»æ©Ÿ | 9182 | prometheus-community/windows_exporter |
| jmx_exporter | JVM æ‡‰ç”¨ | 9404 | prometheus/jmx_exporter |
| mysql_exporter | MySQL | 9104 | prometheus/mysqld_exporter |
| postgres_exporter | PostgreSQL | 9187 | prometheus-community/postgres_exporter |
| redis_exporter | Redis | 9121 | oliver006/redis_exporter |
| kafka_exporter | Kafka | 9308 | danielqsj/kafka_exporter |
| mongodb_exporter | MongoDB | 9216 | percona/mongodb_exporter |
| elasticsearch_exporter | Elasticsearch | 9114 | prometheus-community/elasticsearch_exporter |
| blackbox_exporter | HTTP/TCP/DNS æ¢æ¸¬ | 9115 | prometheus/blackbox_exporter |
| nginx_exporter | Nginx | 9113 | nginxinc/nginx-prometheus-exporter |

### 10.3 Dashboard ç¯„æœ¬å»ºè­°

| ç”¨é€” | Dashboard ID | åç¨± |
|-----|-------------|------|
| **ä¸»æ©Ÿç›£æ§** | 1860 | Node Exporter Full |
| **Docker** | 893 | Docker and system monitoring |
| **K8s Cluster** | 315 | Kubernetes cluster monitoring |
| **JVM** | 4701 | JVM (Micrometer) |
| **Spring Boot** | 12900 | Spring Boot Statistics |
| **MySQL** | 7362 | MySQL Overview |
| **PostgreSQL** | 9628 | PostgreSQL Database |
| **Redis** | 763 | Redis Dashboard |
| **Nginx** | 12708 | Nginx Prometheus |
| **Kafka** | 7589 | Kafka Exporter Overview |

åŒ¯å…¥æ–¹å¼ï¼šGrafana â†’ Dashboards â†’ Import â†’ è¼¸å…¥ ID

### 10.4 å¸¸è¦‹éŒ¯èª¤èˆ‡ FAQ

#### Q1: Prometheus è¨˜æ†¶é«”ä½¿ç”¨éé«˜ï¼Ÿ

```bash
# æª¢æŸ¥æ™‚åºæ•¸é‡
curl http://localhost:9090/api/v1/status/tsdb | jq '.data.headStats'

# è§£æ±ºæ–¹æ¡ˆï¼š
# 1. æ¸›å°‘ scrape é »ç‡
# 2. ç§»é™¤ä¸å¿…è¦çš„ metrics
# 3. é™ä½ retention æ™‚é–“
# 4. ä½¿ç”¨ sample_limit é™åˆ¶
```

#### Q2: Grafana æŸ¥è©¢é€¾æ™‚ï¼Ÿ

```ini
# èª¿æ•´ Grafana é€¾æ™‚è¨­å®š
[dataproxy]
timeout = 120
keep_alive_seconds = 60
```

```promql
# å„ªåŒ–æŸ¥è©¢ï¼šä½¿ç”¨ Recording Rules é å…ˆè¨ˆç®—
```

#### Q3: Alertmanager æ²’æœ‰ç™¼é€å‘Šè­¦ï¼Ÿ

```bash
# æª¢æŸ¥ Alertmanager ç‹€æ…‹
curl http://localhost:9093/api/v1/status

# æª¢æŸ¥ Prometheus å‘Šè­¦ç‹€æ…‹
curl http://localhost:9090/api/v1/alerts

# å¸¸è¦‹åŸå› ï¼š
# 1. è·¯ç”±è¨­å®šéŒ¯èª¤
# 2. éœé»˜ï¼ˆSilenceï¼‰ç”Ÿæ•ˆä¸­
# 3. é€šçŸ¥ç®¡é“è¨­å®šéŒ¯èª¤
```

#### Q4: Target é¡¯ç¤º Downï¼Ÿ

```bash
# æª¢æŸ¥ç¶²è·¯é€£é€šæ€§
curl -v http://target:9100/metrics

# å¸¸è¦‹åŸå› ï¼š
# 1. é˜²ç«ç‰†é˜»æ“‹
# 2. Exporter æœªå•Ÿå‹•
# 3. éŒ¯èª¤çš„ Port
# 4. èªè­‰å¤±æ•—
```

#### Q5: å¦‚ä½•è™•ç†é«˜ Cardinalityï¼Ÿ

```promql
# æ‰¾å‡ºé«˜ Cardinality æŒ‡æ¨™
topk(10, count by (__name__)({__name__=~".+"}))

# æ‰¾å‡ºé«˜ Cardinality Label
count by (job) (count by (job, instance) (up))

# è§£æ±ºæ–¹æ¡ˆï¼š
# 1. ç§»é™¤ä¸å¿…è¦çš„ Label
# 2. ä½¿ç”¨ relabel_configs éæ¿¾
# 3. é™åˆ¶ sample_limit
```

---

## 11. æª¢æŸ¥æ¸…å–®ï¼ˆChecklistï¼‰

### 11.1 å®‰è£æª¢æŸ¥æ¸…å–®

| é …ç›® | æª¢æŸ¥å…§å®¹ | ç‹€æ…‹ |
|-----|---------|------|
| â˜ | ç³»çµ±éœ€æ±‚ç¢ºèªï¼ˆCPU / Memory / Diskï¼‰ | |
| â˜ | é˜²ç«ç‰† Port é–‹é€šï¼ˆ9090 / 3000 / 9100 / 9093ï¼‰ | |
| â˜ | Prometheus å®‰è£å®Œæˆ | |
| â˜ | Grafana å®‰è£å®Œæˆ | |
| â˜ | Node Exporter å®‰è£å®Œæˆ | |
| â˜ | Alertmanager å®‰è£å®Œæˆï¼ˆé¸ç”¨ï¼‰ | |
| â˜ | æœå‹™è¨­ç‚ºé–‹æ©Ÿè‡ªå‹•å•Ÿå‹• | |
| â˜ | å¥åº·æª¢æŸ¥é€šé | |

### 11.2 è¨­å®šæª¢æŸ¥æ¸…å–®

| é …ç›® | æª¢æŸ¥å…§å®¹ | ç‹€æ…‹ |
|-----|---------|------|
| â˜ | prometheus.yml èªæ³•é©—è­‰é€šé | |
| â˜ | Alert Rules èªæ³•é©—è­‰é€šé | |
| â˜ | scrape_config è¨­å®šæ­£ç¢º | |
| â˜ | Grafana Datasource é€£ç·šæˆåŠŸ | |
| â˜ | åŸºæœ¬ Dashboard åŒ¯å…¥ | |
| â˜ | å‘Šè­¦é€šçŸ¥æ¸¬è©¦æˆåŠŸ | |
| â˜ | æ¬Šé™è¨­å®šå®Œæˆ | |

### 11.3 ç”Ÿç”¢ç’°å¢ƒæª¢æŸ¥æ¸…å–®

| é …ç›® | æª¢æŸ¥å…§å®¹ | ç‹€æ…‹ |
|-----|---------|------|
| â˜ | HA æ¶æ§‹éƒ¨ç½² | |
| â˜ | å‚™ä»½ç­–ç•¥è¨­å®š | |
| â˜ | ç›£æ§è‡ªèº«çš„ç›£æ§ï¼ˆMeta-monitoringï¼‰ | |
| â˜ | HTTPS å•Ÿç”¨ | |
| â˜ | èªè­‰æ©Ÿåˆ¶å•Ÿç”¨ | |
| â˜ | ç¨½æ ¸æ—¥èªŒå•Ÿç”¨ | |
| â˜ | Retention è¨­å®šåˆç† | |
| â˜ | å‘Šè­¦æ¸¬è©¦å®Œæˆ | |
| â˜ | Runbook æ–‡ä»¶æº–å‚™ | |
| â˜ | åœ˜éšŠæ•™è‚²è¨“ç·´å®Œæˆ | |

### 11.4 æ—¥å¸¸ç¶­é‹æª¢æŸ¥æ¸…å–®

| é …ç›® | é »ç‡ | ç‹€æ…‹ |
|-----|------|------|
| â˜ | æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹ | æ¯æ—¥ |
| â˜ | æª¢æŸ¥ç£ç¢Ÿç©ºé–“ä½¿ç”¨ | æ¯æ—¥ |
| â˜ | æª¢æŸ¥å‘Šè­¦ç‹€æ…‹ | æ¯æ—¥ |
| â˜ | æª¢æŸ¥ Target ç‹€æ…‹ | æ¯æ—¥ |
| â˜ | å‚™ä»½é©—è­‰ | æ¯é€± |
| â˜ | æ•ˆèƒ½æŒ‡æ¨™æª¢è¦– | æ¯é€± |
| â˜ | Dashboard ä½¿ç”¨ç‹€æ³æª¢è¦– | æ¯æœˆ |
| â˜ | ç‰ˆæœ¬æ›´æ–°è©•ä¼° | æ¯æœˆ |
| â˜ | å®‰å…¨æ€§æ›´æ–°æª¢æŸ¥ | æ¯æœˆ |

---

## åƒè€ƒè³‡æº

- [Prometheus å®˜æ–¹æ–‡ä»¶](https://prometheus.io/docs/)
- [Grafana å®˜æ–¹æ–‡ä»¶](https://grafana.com/docs/)
- [PromQL æ•™å­¸](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Alertmanager è¨­å®š](https://prometheus.io/docs/alerting/latest/configuration/)
- [Grafana Dashboard ç¯„æœ¬](https://grafana.com/grafana/dashboards/)
- [Awesome Prometheus](https://github.com/roaldnefs/awesome-prometheus)


